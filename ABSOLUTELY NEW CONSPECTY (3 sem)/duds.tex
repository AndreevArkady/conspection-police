\documentclass[a4paper]{article}

\usepackage[12pt]{extsizes}
\usepackage[utf8]{inputenc}
\usepackage[unicode, pdftex]{hyperref}
\usepackage{cmap}
\usepackage{mathtext}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools}
\usepackage{icomma}
\usepackage{euscript}
\usepackage{mathrsfs}
\usepackage[dvipsnames]{xcolor}
\usepackage[left=2cm,right=2cm,
    top=2cm,bottom=2cm,bindingoffset=0cm]{geometry}
\usepackage[normalem]{ulem}
\usepackage{graphicx}
\usepackage{makeidx}
\makeindex
\graphicspath{{pictures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
%\usepackage[usenames]{color}
\hypersetup{
     colorlinks=true,
     linkcolor=magenta,
     filecolor=magenta,
     citecolor=black,      
     urlcolor=magenta,
     }
\usepackage{fancyhdr}
\pagestyle{fancy} 
\fancyhead{} 
\fancyhead[LE,RO]{\thepage} 
\fancyhead[CO]{\hyperlink{uk}{к списку объектов}}
\fancyhead[LO]{\hyperlink{sod}{к содержанию}} 
\fancyfoot{}
\newtheoremstyle{indented}{0 pt}{0 pt}{\itshape}{}{\bfseries}{. }{0 em}{ }

\renewcommand\thesection{}
\renewcommand\thesubsection{}

%\geometry{verbose,a4paper,tmargin=2cm,bmargin=2cm,lmargin=2.5cm,rmargin=1.5cm}

\title{Дифференциальные уравнения \\ 
и динамические системы}
\author{Алешин Артем \\ 
    на основе лекций Пилюгина С. Ю. \\
    под редакцией @keba4ok}
\date{5 сентября 2021.}


%envirnoments
    \theoremstyle{indented}
    \newtheorem*{theorem}{Теорема}
    \newtheorem*{lemma}{Лемма}
    \newtheorem*{alg}{Алгоритм}

    \theoremstyle{definition} 
    \newtheorem*{defn}{Определение}
    \newtheorem*{exl}{Пример(ы)}
    \newtheorem*{prob}{Задача}

    \theoremstyle{remark} 
    \newtheorem*{remark}{Примечание}
    \newtheorem*{cons}{Следствие}
    \newtheorem*{exer}{Упражнение}
    \newtheorem*{stat}{Утверждение}
%esli ne hochetsa numeracii - nuzhno prisunut' zvezdochku-pezsochku

\definecolor{brilliantrose}{rgb}{1.0, 0.33, 0.64}

%declarations
        %arrows_shorten
            \DeclareMathOperator{\la}{\leftarrow}
            \DeclareMathOperator{\ra}{\rightarrow}
            \DeclareMathOperator{\lra}{\leftrightarrow}
            \DeclareMathOperator{\llra}{\longleftrightarrow}
            \DeclareMathOperator{\La}{\Leftarrow}
            \DeclareMathOperator{\Ra}{\Rightarrow}
            \DeclareMathOperator{\Lra}{\Leftrightarrow}
            \DeclareMathOperator{\Llra}{\Longleftrightarrow}

        %letters_different
            \DeclareMathOperator{\CC}{\mathbb{C}}
            \DeclareMathOperator{\ZZ}{\mathbb{Z}}
            \DeclareMathOperator{\RR}{\mathbb{R}}
            \DeclareMathOperator{\NN}{\mathbb{N}}
            \DeclareMathOperator{\HH}{\mathbb{H}}
            \DeclareMathOperator{\LL}{\mathscr{L}}
            \DeclareMathOperator{\KK}{\mathscr{K}}
            \DeclareMathOperator{\GA}{\mathfrak{A}}
            \DeclareMathOperator{\GB}{\mathfrak{B}}
            \DeclareMathOperator{\GC}{\mathfrak{C}}
            \DeclareMathOperator{\GD}{\mathfrak{D}}
            \DeclareMathOperator{\GN}{\mathfrak{N}}
            \DeclareMathOperator{\Rho}{\mathcal{P}}
            \DeclareMathOperator{\FF}{\mathcal{F}}

        %common_shit
            \DeclareMathOperator{\Ker}{Ker}
            \DeclareMathOperator{\Frac}{Frac}
            \DeclareMathOperator{\Imf}{Im}
            \DeclareMathOperator{\cont}{cont}
            \DeclareMathOperator{\id}{id}
            \DeclareMathOperator{\ev}{ev}
            \DeclareMathOperator{\lcm}{lcm}
            \DeclareMathOperator{\chard}{char}
            \DeclareMathOperator{\codim}{codim}
            \DeclareMathOperator{\rank}{rank}
            \DeclareMathOperator{\ord}{ord}
            \DeclareMathOperator{\End}{End}
            \DeclareMathOperator{\Ann}{Ann}
            \DeclareMathOperator{\Real}{Re}
            \DeclareMathOperator{\Res}{Res}
            \DeclareMathOperator{\Rad}{Rad}
            \DeclareMathOperator{\disc}{disc}
            \DeclareMathOperator{\rk}{rk}
            \DeclareMathOperator{\const}{const}
            \DeclareMathOperator{\grad}{grad}
            \DeclareMathOperator{\Aff}{Aff}
            \DeclareMathOperator{\Lin}{Lin}
            \DeclareMathOperator{\Prf}{Pr}
            \DeclareMathOperator{\Iso}{Iso}
	    \DeclareMathOperator{\Lip}{Lip}
            \DeclareMathOperator{\loc}{loc}

        %specific_shit
            \DeclareMathOperator{\Tors}{Tors}
            \DeclareMathOperator{\form}{Form}
            \DeclareMathOperator{\Pred}{Pred}
            \DeclareMathOperator{\Func}{Func}
            \DeclareMathOperator{\Const}{Const}
            \DeclareMathOperator{\arity}{arity}
            \DeclareMathOperator{\Aut}{Aut}
            \DeclareMathOperator{\Var}{Var}
            \DeclareMathOperator{\Term}{Term}
            \DeclareMathOperator{\sub}{sub}
            \DeclareMathOperator{\Sub}{Sub}
            \DeclareMathOperator{\Atom}{Atom}
            \DeclareMathOperator{\FV}{FV}
            \DeclareMathOperator{\Sent}{Sent}
            \DeclareMathOperator{\Th}{Th}
            \DeclareMathOperator{\supp}{supp}
            \DeclareMathOperator{\Eq}{Eq}
            \DeclareMathOperator{\Prop}{Prop}


%env_shortens_from_hirsh            
    \newcommand{\bex}{\begin{example}\rm}
    \newcommand{\eex}{\end{example}}
    \newcommand{\ba}{\begin{algorithm}\rm}
    \newcommand{\ea}{\end{algorithm}}
    \newcommand{\bea}{\begin{eqnarray*}}
    \newcommand{\eea}{\end{eqnarray*}}
    \newcommand{\be}{\begin{eqnarray}}
    \newcommand{\ee}{\end{eqnarray}}
    \newcommand{\abs}[1]{\lvert#1\rvert}
        \newcommand{\bp}{\begin{prob}}
        \newcommand{\ep}{\end{prob}}
    
\begin{document}
%ya_ebanutyi
\newcommand{\resetexlcounters}{%
  \setcounter{exl}{0}%
} 
\newcommand{\resetremarkcounters}{%
  \setcounter{remark}{0}%
} 
\newcommand{\reseconscounters}{%
  \setcounter{cons}{0}%
} 
\newcommand{\resetall}{%
    \resetexlcounters
    \resetremarkcounters
    \reseconscounters%
}
\newcommand{\cursed}[1]{\textit{\textcolor{brilliantrose}{#1}}}
\newcommand{\de}[3][2]{\index{#2}{\textbf{\textcolor{brilliantrose}{#3}}}}
\newcommand{\re}[3][2]{\hypertarget{#2}{\textbf{\textcolor{brilliantrose}{#3}}}}
\newcommand{\se}[3][2]{\index{#2}{\textit{\textcolor{brilliantrose}{#3}}}}
\maketitle 
\newpage
\hypertarget{sod}
\tableofcontents
\newpage

\subsection{Литература}
\begin{itemize}
    \item В. И. Арнольд Обыкновенные дифференциальные уравнения
    
    \item Ю. Н. Бибиков Общий курс дифференциальных уравнения
    \item С. Ю. Пилюгин Пространства динамических систем
\end{itemize}   
\begin{defn}
  \se{Дифференциальное уравнение}{Дифференциальное уравнение} -- уравнение от неизвествной фукции $y(x)$, где $x \in \RR $ -- независимая переменная, вида
    \[f(x,y,y',\ldots,y^{(n)}) = 0\]
\end{defn}
\section{Дифференциальные уравнения 1-го порядка, разрешенные относительно производной}
\begin{defn}
  \se{Дифференциальное уравнение!1-го порядка}{Дифференциальное уравнение 1-го порядка}, разрешенное относительно производной -- уравнение вида $y' = f(x,y), f \in C(G)$, где $G$ -- область (открытое связное множество) в $\RR_{x,y}^2$
\end{defn}
\begin{defn}
  $y : (a,b) \to \RR$ -- \se{Решение дифференциального уравнения}{решение} на $(a,b)$, если  
  \begin{itemize}
    \item $y$ -- дифференцируема;
    \item $(x,(y(x)) \in G, x \in (a,b)$;
    \item $y'(x) \equiv f(x,y(x))$ на $(a,b)$.
  \end{itemize} 
\end{defn}
\begin{exl} \ 
  \begin{itemize}
    \item $y' = ky, k > 0, \  G = \RR^2$;
    \item $\forall c \in \RR \  y(x) = ce^{kx}$ -- решение на $\RR$.
  \end{itemize}
\end{exl}
\begin{defn}
  \se{Интегральная кривая}{Интегральная кривая} -- график решения.
\end{defn}
\subsection{Задача Коши}
\begin{defn}
$y(x)$ -- решение \se{Задача Коши}{задачи Коши} с начальным условем $(x_0,y_0)$, если
\begin{itemize}
    \item $y(x)$ -- решение дифференциального уравнения на $(a,b)$;
    \item $y(x_0) = y_0$.
\end{itemize}
\end{defn}
\subsection{Единственность}
\begin{defn}
  $(x_0,y_0)$ -- \se{Точка единственности}{точка единственности} для задачи Коши, если $\forall y_1, y_2$ -- решения $\exists (\alpha, \beta) \ni x_0: y_1|_{(\alpha,\beta)} = y_2|_{(\alpha,\beta)}$.
\end{defn}
\begin{exl}
  \[y' = 3 \sqrt[3]{y^2}\]
  Если $(x_0,y_0) = 0$, то возможны следующие решения:
  \begin{itemize}
  \item \[y_1 = 0\]
  \item \[y_2 = \begin{cases}
        0 & x \leqslant 0 \\
        x^3 & x > 0
      \end{cases}\]
  \item \[y_3 = \begin{cases}
        x^3 & x \leqslant 0 \\
        0 & x > 0
      \end{cases}\]
  \end{itemize}
  Точка $(0,0)$ не является точкой единственности, но при этом $(1,1)$ уже будет точкой единственности
\end{exl}
\subsection{Поле направлений}
\begin{defn}
  Из уравнения $y' = f(x,y)$ мы можем вычислить \se{Коэффициент наклона}{коэффициент наклона} в каждой точке $(x,y)$
  \[k = y'(x) = f(x,y)\]
  Если в каждой точке $(x,y)$ области $G$ провести отрезок с угловым коэффициентом равным $f(x,y)$, то получится \se{Поле направлений}{поле направлений}. Любая интегральная кривая в каждой своей точке касается соответствующего отрезка.
\end{defn}
\subsection{Основные теоремы}
\begin{theorem}[\cursed{О существовании}]
  Если $y' = f(x,y), \ f \in C(G)$, то $\forall (x_0,y_0) \in G \ \exists $ решение задачи Коши с начальными данными $(x_0,y_0)$
  $G$ называется \se{Область!существования}{областью существования}.
\end{theorem} \ 
\begin{theorem}[\cursed{О единственности}]
  Если $y' = f(x,y), \ f, \frac{\partial f}{\partial y} \in C(G)$, то $\forall (x_0,y_0) \in G \ \exists $ единственное решение задачи Коши с начальными данными $(x_0,y_0)$
  $G$ называется \se{Область!единственности}{областью единственности}.
\end{theorem}
\section{Интегрируемые типы дифференциальных уравнений 1-го порядка}
\begin{exl}
  $y' = f(x)$ -- из анализа знаем, что единнственным решение при данном условии $(x_0,y_0)$ будет \[y(x) = y_0 + \int_{x_0}^xf(t)dt\]
\end{exl}
\subsection{Интеграл}
Пусть $H \subset G$ -- область
\begin{defn}
  Функция $U \in C^1(H,\mathbb{R})$ называется \se{Интеграл уравнения}{интегралом уравнения} $y' = f(x,y)$ в $H$, если выполнены следующие условия:
  \begin{itemize}
  \item $\frac{\partial U}{\partial y} \not = 0$;
  \item если $y(x), x \in (a,b)$ -- решение с $(x,y(x)) \in H$, то $U(x,y(x)) = \const$.
  \end{itemize}
\end{defn}
\begin{theorem}[Напоминание \cursed{теоремы о неявной функции}]
  \[F : H \subset \mathbb{R}^2 \to \mathbb{R}, F \in C^1  \]
  Если
  \begin{itemize}
    \item
      \[F(x_0,y_0) = 0\]
    \item
      \[ \frac{\partial F}{\partial y}\bigg|_{(x_0,y_0)} \not  = 0\]
  \end{itemize}
  тогда $\exists I, J$ -- открытые интервалы $x_0 \in I, y_0 \in J$, $\exists z(x) \in C^1(I)$ такая, что
  \begin{itemize}
  \item $z(x_0) = y_0$;
  \item $F(x,y) = 0 \leftrightarrow y = z(x)$ при $(x,y) \in I \times J$.
  \end{itemize}
\end{theorem} \ 
\begin{theorem}[\se{Теорема!об интеграле для дифференциальных уравнений первого порядка}{Об интеграле для дифференциальных уравнений первого порядка}]
  Пусть $U$ -- интеграл $y' = f(x,y)$ в $H \subset G$. Тогда $\forall (x_0,y_0) \in H \ \exists H_0 \subset H, H_0 = I \times J \ni (x_0,y_0)$ и $\exists y(x) \in C^1(I)$ такая что:
  \begin{itemize}
    \item $y(x)$ -- решение задачи Коши с начальными данными $(x_0,y_0)$
    \item $(x,y) \in  H$ и $U(x,y) = U(x_0,y_0) \Rightarrow y = y(x)$
  \end{itemize}
\end{theorem}
\begin{proof} \ 
  Фиксируем произвольную точку $(x_0,y_0)$. Рассмотрим $F(x,y) = U(x,y) - U(x_0,y_0)$.
  $F$ удовлетворяет условию теоремы о неявной функции, так как $\frac{\partial F}{\partial y} = \frac{\partial U}{\partial y} \not  = 0$, поэтому существуют $I_0, J_0 \ I_0 \times J_0 \subset H$ и $\exists y(x) \in  C^1(I_0), \ y(x_0) = y_0$.
  По теореме существования $\exists $ решение $z(x)$ задачи Коши с начальными условиями $(x_0,y_0)$ на некотором промежутке $I \ni x_0$ такое что $(x,z(x)) \in I_0 \times J_0$.
  Тогда по определению интеграла $U(x,z(x)) = \const$ $\Rightarrow F(x,z(x)) = 0 \Rightarrow z(x) = y(x)$.
\end{proof}
\subsection{Дифференциальные уравнения с разделяющимися переменными}
\begin{equation*}
  \begin{aligned}
    & y' = m(x) \cdot n(y) \\
    & m \in C((a,b)), n \in C((\alpha, \beta)) \\
    & G = (a,b) \times (\alpha, \beta)
  \end{aligned}
\end{equation*}

\begin{itemize}
\item $y_0 \in (\alpha, \beta) n(y_0) = 0 \Rightarrow y \equiv y_0$
  
  Проверяется подставнкой
\item $I \subset (\alpha, \beta), n(y) \not  = 0$ при $y \in  I$
  Подсказка:
  Рассмотрим $y(x) : (x,y(x)) \in (a,b) \times I$ и отличную от $0$
  $y' = m(x) n(y)$, на $n(y)$ можно поделить
  \[\frac{y'}{n(y(x))} = m(x), \:
  \int\limits_{x_0}^x\frac{y'(t)dt}{n(y(t))} = \int\limits_{x_0}^x m(t) dt. \]
    Замена $z = y(t)$
  \[\int\limits_{y(x_0)}^{y(x)}\frac{dz}{n(z)} = \int\limits_{x_0}^x m(t) dt,
  \]
 
  Обозначим за $N(y)$ и $M(x)$ некоторые первообразные $\frac{1}{n(y)}$ и $m(x)$ соответственно
  \begin{equation*}
    \begin{aligned}
      N(y(x)) - N(y(x_0)) & = M(x) - M(x_0)\\
      U(x,y) :& = N(y) - M(x).
    \end{aligned}
  \end{equation*}
  Если $y(x)$ -- решение, то $U(x,y(x)) = N(y(x_0)) - M(x_0)$
  \[\frac{\partial U}{\partial y} = \frac{1}{n(y)} \not  = 0. \]
  
\end{itemize}
Это была некоторая эвристика для того, чтобы найти формулу для интеграла.
  
Сформулируем некоторое утверждение, которое позволит нам проверять, является ли  $U$ интегралом.

\begin{stat}
  (\cursed{Критерий интеграла})

  $U$ -- интеграл для уравнения $y' = f(x,y)$ $\Longleftrightarrow$
  \begin{itemize}
  \item \[\frac{\partial U}{\partial y} \not = 0\]
  \item \[\frac{\partial U}{\partial x} + \frac{\partial U}{\partial y} \cdot f \equiv 0\]
  \end{itemize}
\end{stat}

\begin{proof}
  Если $y(x)$ -- решение, то $U(x,y(x)) = \const$

  \[\frac{dU}{dx} \equiv 0
  \]

  \[\frac{d}{dx} U(x,y(x)) = \frac{\partial U}{\partial x}(x, y(x))  + \frac{\partial U}{\partial y} \cdot y'(x) =  \frac{\partial U}{\partial x} + \frac{\partial U}{\partial y} \cdot f \equiv 0
  \]
\end{proof}


Применяя это утверждение к нашему уравнению $y' = m(x)n(y)$ и $U = N(y) - M(x)$ имеем:

\begin{equation}
  \begin{gathered}
    \frac{d}{dx} U = \frac{d}{dx} (N(y) - M(x)) = -m(x) + \frac{1}{n(y)} \cdot m(x)n(y) \equiv 0
  \end{gathered}
\end{equation}

\section{Замена переменных}

\begin{exl}
  \begin{enumerate}
  \item $y' = f(ax +by)$
    
    Новая независимая переменная -- $x$

    Новая искомая функция -- $v = ax+by$

    \[\frac{dv}{dx} = a+by' = a + bf(v)\]

  \item $y' = m(x) n(y)$,  Пусть $n(y) \neq 0 $

    Новая переменная -- $x$

    Новая функция -- $v = N(y)$

    \[\frac{dv}{dx} = \frac{1}{n(y(x))} \cdot y'(x) = m(x)\]
    
    Все сводится к уравнению, решение которого мы уже умеем находить
    \[\frac{dv}{dx} = m(x)\]
    


  \end{enumerate}
\end{exl}


\subsection{Линейное дифференциальное уравнение первого порядка}

\[y' = p(x) y + q(x), \ p,q \in C((a,b))\]

$f(x,y)$ определена на $G = (a,b) \times \mathbb{R} $, $f$ и $\frac{\partial f}{\partial y}$ непрерывны на $G$, поэтому $G$ -- область существования и единственности.


\begin{enumerate}
\item Для начала научимся решать \se{Однородное линейное уравнени}{однородное линенйное уравнение} ($q \equiv 0$)

  \[y' = p(x) y\]

  Есть решение $y \equiv 0, x \in (a,b)$


  Если $y > 0$, то

  \[U = \int \frac{dy}{y} - \int p(x) dx = \log (y) - \int p(x) dx = \log(C)
  \]

  \[y = c e^{\int p(x) dx}\]

  Для $y < 0$ то же самое


\item \se{Метод вариации произвольной переменной}{Метод вариации произвольной переменной} (Лагранж)

  Воспользуемся заменой переменной:

  Новая независимая переменная -- $x$

  Новая функция -- $v(x)$

  Будем искать решение $y(x)$ в виде $y(x) = v(x) e^{\int_{}^{}p(x) dx}$
  \begin{equation*}
    \begin{aligned}
      y'  & = v' e^{\int_{}^{}p(x) dx} + v \cdot p(x) e^{\int_{}^{}p(x) dx} \\
      p(x)y + q(x) & =  p(x) v(x) e^{\int_{}^{}p(x) dx} + q(x) \\
      v' \cdot e^{\int p(x) dx} & = q(x) \\
      v'& = q(x) \cdot e^{-\int p(x) dx} \\
      v  &= \int q(x) e^{-\int p(x) dx} dx \\
      y & = e^{\int p(x) dx} \left( \int q(x) e^{-\int p(x) dx} dx \right)
  \end{aligned}
\end{equation*}

Заметим, что первообразная для $p(x)$ берется одна и та же

Для задачи Коши с начальным условием $(x_0,y_0)$ имеем


\[y  = e^{\int_{x_0}^x p(t) dt} \left( y_0 + \int\limits_{x_0}^x q(s) e^{-\int_{x_0}^s p(t) dt} ds \right)\]

\end{enumerate}

\subsection{Уравнения, сводящиеся к линейным}

\se{Уравнение Бернулли}{Уравнение Бернулли} $y' = p(x)y + q(x) y^m, m = \const$

Исключения -- $m = 0, m = 1$, так как тогда это будет обычное линейное уравнение

Если $m > 0$, то есть решение $y \equiv 0$

Если $y \neq 0$, то возпользуемся заменой переменных
$v = y^{1-m}$

\begin{equation*}
  \begin{aligned}
    \frac{y'}{y^m}& = p(x) y^{1-m} + q(x)\\
    v'& = (1-m) y' y^{-m} \\
    \frac{v'}{(1-m)} & = p(x) v + q(x)
  \end{aligned}
\end{equation*}

Получилось линейное уравнение, которое мы уже умеем решать.

\se{Уравнение Рикатти}{Уравнение Рикатти}
\[y' = ay^2 + bx^{\alpha}, ab \neq 0 \]

Бернулли показал, что при $\alpha = \frac{4k}{2k-1}, k \in \mathbb{Z}$ это уравнение имеет решения.

Луивилль(1841) доказал, что если $\alpha$ -- не число Бернулли и $\alpha \neq 2$, то уравнение Рикатти не интегрируемо.

\subsection{Дифференциальные уравнения первого порядка в симметричной форме}

\se{Уравнение Пфаффа}{Уравнение Пфаффа}
\[m(x,y) dx + n(x,y) dy = 0\]

\begin{defn}
  \se{Дифференциальная 1-форма}{Дифференциальная 1-форма}

  \[F = m(x,y) dx + n(x,y) dy, m,n \in C^1(G), m^2 + n^2 \neq 0\]

\end{defn}

\begin{defn}
  \se{Интегральная кривая дифференциальной формы}{Интегральная кривая дифференциальной формы} $F$ -- гладкая кривая $\gamma(t) = (\gamma_1(t), \gamma_2(t)), t \in (a,b)$

  \[m(\gamma(t)) \dot \gamma_1(t) + n(\gamma(t)) \dot \gamma_2(t) = 0 \text{ на } (a,b)
  \]
\end{defn}

\begin{remark}
  Кривая называется гладкой, если $\exists $ непрерывные $\dot \gamma_1, \dot \gamma_2$ и $(\dot \gamma_1, \dot \gamma_2) \neq 0$
\end{remark}


\cursed{Связь уравнения Пфаффа с обыкновенным дифференциальным уравнением}

Пусть $\gamma(t) = (\gamma_1(t), \gamma_2(t))$ -- интегральная кривая $F$

Выберем $t_0 \in (a,b)$, пусть $\dot \gamma_1(t_0) \neq 0$

Тогда $\exists (\alpha, \beta) \ni t_0: \dot \gamma_1(t)|_{(\alpha, \beta)} \neq 0$

Положим $x = \gamma_1(t)$

Так как $\dot \gamma_1$ -- непрерывна и не обращается в ноль на $(\alpha, \beta)$,  то существует обратная функция.

Тогда $x = \gamma_1(t) \Longleftrightarrow t = \gamma_1^{-1}(x)$

Положим $y = \gamma_2(\gamma_1^{-1})$

Дифференциальное уравнение для $y$:

\[\frac{dy}{dx} = \dot \gamma_2(t) \cdot \frac{d}{dx} (\gamma_1^{-1}(x)) = \frac{\dot \gamma_2(t)}{\dot \gamma_1(\gamma_1^{-1}(x))} = \frac{\dot \gamma_2(t)}{\dot \gamma_1(t)}
\]

$\gamma$ была интегральной кривой формы $F$, то есть выполнялось равенство:

\[m(\gamma(t)) \dot \gamma_1(t) + n(\gamma(t)) \dot \gamma_2(t) = 0\]

Тогда понятно, что
\[\frac{dy}{dx} = \frac{\dot \gamma_2(t)}{\dot \gamma_1(t)}  = - \frac{m(\gamma(t))}{n(\gamma(t))} = - \frac{m(x,y)}{n(x,y)}\]

Мы получили, что если у нас есть интегральная кривая $\gamma$ уравнения $F = 0$, то в локальных координатах они решают уравнение $y' = \frac{m(x,y)}{n(x,y)}$

Значит  интегральные кривые уравнения Пфаффа $m dx + n dy = 0$ локально совпадают с интегральными кривыми уравнения $y' = \frac{m(x,y)}{n(x,y)}$

Верно и обратное: пусть $y(x)$ -- решение уравнения $y' = - \frac{m}{n}, n(x,y(x)) \neq 0$

Как тогда получить из этого уравнения интегральную кривую уравнения Пфаффа?

Берем $\gamma_1(t) = x, \gamma_2(t) = y(x)$

\[ \dot \gamma_1(t) = 1, \dot \gamma_2(t) = \frac{dy}{dt} = \frac{dy}{dx} = - \frac{m(x,y)}{n(x,y)} = - \frac{m(\gamma(t))}{n(\gamma(t))}\]

Мы получили интегральную кривую уравнения Пфаффа.

Вывод: $F = m dx + n dy = 0$  -- запись совокупности двух обыкновенных дифференциальных уравнений:

\begin{equation*}
  \left[
    \begin{gathered}
      \frac{dy}{dx} = - \frac{m}{n}\\
      \frac{dx}{dy} = - \frac{n}{m}
    \end{gathered}
  \right.
\end{equation*}
  
  
\section{Уравнение в полных дифференциалах}

\begin{defn}
  Форма $F$ -- \se{Точная форма}{точная}, если $\exists U \in C^2(\mathbb{R}_{x,y}^2)$
  \[F = \frac{\partial U}{\partial x} dx + \frac{\partial U}{\partial y} dy  \]

  Если $F$ -- точная, то $F = 0$ называется \se{Уравнение полных дифференциалов}{уравнением полных дифференциалов}
\end{defn}

\begin{theorem}
  Если $F$ -- точная, то в окрестности произвольной точки $(x_0,y_0) \in G$ $U$ -- интеграл одного из уравнений:
  \[\frac{dy}{dx} = - \frac{m}{n} \text{ или } \frac{dx}{dx} = - \frac{n}{m}  \]
\end{theorem}
\begin{proof}
  $(x_0,y_0) \in  G$ можно считать, что $n(x_0,y_0) \neq 0$, тогда $n(x,y) \neq 0$ в некоторой окрестности

  Рассмотрим уравнение $y' =- \frac{m}{n}$

  Пусть $y(x)$ -- решение

  \[\frac{d}{dx}U(x,y(x)) = \frac{\partial U}{\partial x} + \frac{\partial U}{\partial y} \frac{dy}{dx}  = m + n \cdot(- \frac{m}{n}) \equiv 0  \]

  \[\frac{\partial U}{\partial y} = n \neq 0\]

  Получаем, что $U$ -- интеграл
  
\end{proof}

\subsection{Условие точности 1-формы}

\[U \in C^2 \Rightarrow \frac{\partial U}{\partial x}, \frac{\partial U}{\partial y} \in C^1\]

\[\frac{\partial m}{\partial y} = \frac{\partial^2 U}{\partial x \partial y}\]
\[\frac{\partial n}{\partial x} = \frac{\partial^2 U}{\partial y\partial x}\]
Из курса матанализа знаем, что если производные непрерывны, то они совпадают

\[F \text{ точна } \Rightarrow \frac{\partial m}{\partial y} = \frac{\partial n}{\partial x}\]

\begin{stat}
  \[G = (a,b) \times (\alpha, \beta)\]
  Тогда из равенства частных производных $m$ и $n$ следует, что $F$ -- точна
\end{stat}
\begin{proof}
  Фиксируем $(x_0,y_0) \in G$

  Хотим построить $U$
  \[\frac{\partial U}{\partial x} = m, \frac{\partial U}{\partial y} = n \]

  \[U = \int_{x_0}^{x}m(s,y)ds + \varphi (y) \text{ удовлетворяет первому уравнению}\]
  Нужно только найти $\varphi $

  \begin{equation*}
    \begin{gathered}
      \frac{\partial U}{\partial y} = \int_{x_0}^{x}\frac{\partial m}{\partial y}(s,y) ds + \varphi' (y) =
      \\
     =  \int_{x_0}^{x} \frac{\partial n}{\partial x}(s,y) ds + \varphi'(y) = n(x,y) - n(x_0,y) + \varphi'(y)
    \end{gathered}
  \end{equation*}
  Хотим
  \[n(x,y) = n(x,y) - n(x_0,y) + \varphi'(y)\]
  Тогда можно взять в качестве $\varphi(y) = \int_{y_0}^{y}n(x_0,t)dt$
  \[U(x,y) = \int_{x_0}^{x}m(s,y)ds + \int_{y_0}^{y}n(x_0,t)dt\]
\end{proof}
\begin{remark}
  Это утверждение верно не для любой области $G$, хотя верно, если $G$ -- звездчатое множество
\end{remark}


\subsection{Интегрирующий множитель}
\begin{defn}
  $\mu \in C^1, \mu \neq 0$ называется \se{Интегрирующий множитель}{интегрирующим множителем}, если $\mu F$ -- точная форма
\end{defn}

\begin{exl}
  Уравнение с разделяющимися переменными:

  \[m(x)n(y) dx + dy = 0\]
  Интегрирующий множитель -- $\frac{1}{n(y)}$
  \[m(x)dx + \frac{1}{n(y)} dy = 0\]

  \[ \frac{\partial m}{\partial y} = 0 = \frac{\partial }{\partial x}(\frac{1}{n(y)})\]

  И как мы уже видели интегралом будет

  \[U(x,y) = \int_{}^{}m(x) dx + \int_{}^{}\frac{1}{n(y)} dy \]
\end{exl}
  
\section{Системы дифференциальных уравнений}

Отныне независимая переменная будет обозначаться $t$ и искать мы будем функции $x(t)$

\begin{defn}
  \se{Система дифференциальных уравнений общего вида}{Системы дифференциальных уравенний общего вида} (системы разрешимые относительно старших производных)

  $n$ и $m_1, \ldots , m_n$ -- фиксированные натуральные числа

  Для каждого $i = 1,\ldots, n$ имеем уравнение

  \[\frac{d^mx}{dt^m} = f_i(t,x_1, \dot x_1, \ldots, \frac{d^{m_1-1}}{dt^{m_1-1}}, \ldots , x_n, \dot x_n, \ldots, \frac{d^{m_n-1}}{dt^{m_n-1}})  \]
  $m = \sum_{}^{}m_i$ называется \se{Порядок системы}{порядком системы}
\end{defn}

\subsection{Частные случаи}

\begin{itemize}
\item \se{Нормальная система}{Нормальная система}
  Ищем $x_1(t), \ldots, x_n(t)$, все $m_i = 1$
  \begin{equation*}
      \dot x_i(t) = f_i(t,x_1, \ldots ,x_n)
  \end{equation*}


\item \se{Дифференциальное уравнение порядка $m$}{Дифференциальное уравнение порядка $m$}
  $x(t)$ -- искомая функция

  \[\frac{d^mx}{dt^m} = f(t,x, \dot x, \ldots, \frac{d^{m-1}x}{dt^{m-1}})\]
\end{itemize}

Системы общего вида всегда сводятся к нормальным системам

Покажем, что дифференциальное уравнение сводится к нормальной системе

\begin{equation*}
  \begin{aligned}
    \begin{cases}
      \dot y_1 = y_2 &\\  
      \dot y_2 = y_3 & \\ 
      \vdots & \Longleftrightarrow  \frac{d^mx}{dt^m} = f(t,x, \dot x, \ldots, \frac{d^{m-1}x}{dt^{m-1}}) \\        
      \dot y_{m-1} = y_m & \\ 
      y_m = f(t,y_1,\ldots, y_{m-1}) & 
    \end{cases}
  \end{aligned}
\end{equation*}

Если $x$ решение уравнения, то очевидно, что $y_1 = x, y_2 = \dot x, \ldots y_m =  \frac{d^{m-1}x}{dt^{m-1}}$ решения системы и наоборот, если $y_1, y_2, \ldots y_m$ решения системы, то $x = y_1$ решение уравнения.

\subsection{Векторная запись нормальных систем}

Сейчас мы введем некоторые обозначения и соглашения, с которыми будем работать в дальнейшем

\begin{equation*}
  \begin{cases}
    \dot x_1 = f_1(t,x_1, \ldots, x_n)\\
    \vdots \\
    \dot x_n = f_n(t,x_1, \ldots, x_n)
  \end{cases}
\end{equation*}

\begin{equation*}
  \text{Вектор } x = 
  \begin{pmatrix}
    x_1 \\
    \vdots \\
    x_n 
  \end{pmatrix}
  \in \mathbb{R}^n, \
  \dot x = 
  \begin{pmatrix}
    \dot x_1 \\
    \vdots \\
    \dot x_n
  \end{pmatrix}
\end{equation*}

\begin{equation*}
  \text{Векторная функция } f(t,x) = 
  \begin{pmatrix}
    f_1(t,x) \\
    \vdots \\
    f_n(t,x) 
  \end{pmatrix}
\end{equation*}



Тогда исходная система принимает вид
\[\dot x = f(t,x)\]

\[ \text{Для функции $f(t)$ под записью } \int_{}^{}f(t) dt \text{ будем подразумевать }
  \begin{pmatrix}
    \int_{}^{}f_1(t)dt \\
    \vdots \\
    \int_{}^{}f_n(t) dt
  \end{pmatrix}\]


В качестве нормы на $\mathbb{R}^n$ зафиксируем $||x|| = \max\limits_{1 \leqslant i \leqslant n}^{}|x_i|$

\begin{defn}
  Для уравнения $\dot x = f(t,x), x \in \mathbb{R}^n$ ($f \in C(G) G \subset \mathbb{R}^{n+1}_{t,x}$) функция $x : (a,b) \to \mathbb{R}^n$ называется \cursed{решением}, если
  \begin{itemize}
  \item $\exists \dot x $ на $(a,b)$
  \item $(t,x(t)) \in G$
  \item $\dot x(t) = f(t,x(t)), t \in (a,b)$
  \end{itemize}
\end{defn}

\begin{defn}
  $x : (a,b) \to \mathbb{R}^n $ называется решением задачи Коши с начальным условием $(t_0,x_0)$, если
  \begin{itemize}
  \item $x$ -- решение
  \item $x(t_0) = x_0$
  \end{itemize}
\end{defn}

\section{Теоремы существования}
\begin{theorem}
  \cursed{существования} (Пеано)
  \[\dot x = f(t,x)\]
  $f \in C(G) \Rightarrow \forall (t_0,x_0) \in G \ \exists $ решение задачи Коши
\end{theorem}
\begin{proof}
  Рассмотрим $(t_0,x_0) \in G$
  \[\exists \alpha, \beta > 0 : G \supset R = \{ (t,x) \in G \ | \ |t - t_0| \leqslant \alpha, |x-x_0| \leqslant \beta\} \text{ -- компакт}\] 

  \[\exists M : |(t,x)| \leqslant M \ \forall  (t,x) \in R\] 

  \[h: = \min(\alpha, \frac{\beta}{M})\]

  Будем доказываеть, что существует решение на промежутке $(t_0 - h, t_0 + h)$

  \se{Эквивалентное интегральное уравнение}{Эквивалентное интегральное уравнение}

  \[x(t) = x_0 +  \int_{t_0}^{t}f(s,x(s)) ds\]
  \begin{defn}
	 $x : (a,b) \to \mathbb{R} $ --
     \se{Решение интегрального уравнения}{решение интегрального уравнения}, если
     \begin{enumerate}
     \item $x \in C((a,b))$
     \item $(t,x(t)) \in G$
     \item $x(t)$ удоавлетворяет интегральному уравнению
     \end{enumerate}
  \end{defn}

  \begin{lemma}
    $x$ -- решение интегрального уравнения $x(t) = x_0 +  \int_{t_0}^{t}f(s,x(s)) ds$
    $\Leftrightarrow$
    $x$ -- решение задачи Коши с начальным условием $t_0,x_0$
  \end{lemma}
  Доказательство леммы очевидно.

  Мы будем доказывать разрешимость эквивалентного интегрального уравнения на $[t_0-h, t_0 + h]$

  Сузимся на отрезок $[t_0,t_0+h]$ (для $[t_0-h, t_0]$ все аналогично)  

  \subsection{Ломаные Эйлера}
  Зафиксируем $N \in \mathbb{N}$ и разобьем отрезок $[t_0,t_0+h]$ на $N$ равных частей $[t_k,t_{k+1}]$, $t_k = t_0 + \frac{kh}{N}$

  Определим функцию $g(t)$

  \[g(t) = x_0 + f(t_0,x_0)(t-t_0),  t \in [t_0,t_1]\]
  \[g(t) = g(t_k) + f(t_k,g(t_k))(t-t_k), t \in [t_k,t_{k+1}]\]

  Введем $\dot g(t)$ (точечка сверху это просто символ, так как $g$ не дифференцируема в некоторых точках)

  \[\dot g(t) = f(t_k,g(t_k)), t \in [t_k,t_{k+1}]\]

  \begin{lemma}
    $\forall k = 0,1, \ldots, n$
    \begin{enumerate}
    \item $g$ определена на $[t_k, t_{k+1}]$
    \item $|g(t)- x_0| \leqslant M(t-t_0), t \in [t_0,t_k]$
    \item $g(t) =  x_0 + \int_{t_0}^{t}\dot g(s)ds$
    \end{enumerate}
  \end{lemma}
  \begin{proof}
    Индукция по $k$

    \textit{База:} $k = 1$ Очевидно
    \textit{Переход:}
    \begin{enumerate}
    \item Достаточно показать, что $f(t_k,g(t_k))$ определено, для этого достаточно показать, что $(t_k,g(t_k)) \in R \Leftrightarrow |t-t_0|\leqslant \alpha, |g(t_k)-x_0 | \leqslant \beta$

      Это верно, так как $|g(t_k) - x_0| \leqslant M |t_k - t_0| \leqslant Mh \leqslant \beta$
    \item $|g(t) - x_0| \leqslant |g(t) - g(t_k)| + |g(t_k) - x_0| \leqslant |f(t_k,g(t_k))|(t-t_k) + M(t_0 - t_0) \leqslant M(t-t_0)$
    \item $g(t) = g(t_k) + \int_{t_k}^{t}\dot g(s)ds =  x_0 + \int_{t_0}^{t_k}\dot g(s)ds + \int_{t_k}^{t}g(s)ds = x_0 + \int_{t_0}^{t}g(s)ds$
    \end{enumerate}
  \end{proof}

  \begin{lemma}
    (\se{Лемма Арцела-Аскори}{Арцела-Аскори})
    \[G = \{g_k : I \to \mathbb{R}^n, k \geqslant 0\}\]

    \begin{defn}
      $G$ равномерно ограничено, если существет $N: \ |g_k(t)| \leqslant N \ \forall k \in  \mathbb{N}, \ \forall t \in  I$
    \end{defn}
    \begin{defn}
      $G$ рваностепенно непрерывно, если $\forall \varepsilon > 0 \exists \delta > 0:$

      $\forall k \geqslant 0 \ \forall t_1, t_2 \in I \ |t_1 - t_2| < \delta \rightarrow |g_k(t_1)- g_k(t_2)| < \varepsilon $
    \end{defn}

    Если $G$ - равномерно ограничена и равностепенно непрерывна, тогда из $G$ можно выделить равномерно сходящуюся подпоследовательность
  \end{lemma}
  
  Рассмотрим последоватьельность ломаных Эйлера $g_N, N > 0$ и докажем, что она равномерно ограничена и равностепенно непрерынва

  \[|g_N(t) - x_0| \leqslant M(t-t_0) \leqslant Mh \Rightarrow |g_n(t)| \leqslant |x_0| + Mh \]
  \[|g_N(t_1) - g_N(t_2)| = \bigg|\int_{t_1}^{t_2}\dot g_N(s)ds \bigg| \leqslant M|t_1 - t_2|  \leqslant M\delta\]
  В качестве $\delta(\varepsilon)$ можно взять $\delta(\varepsilon ) = \frac{\varepsilon}{M}$

  Отсюда получаем, что последовательность $g_N$ действительно равномерно ограничена и равностепенно непрерывна, тогда по лемме Арцела-Аскори из нее можно выделить подпоследовательность равномерно сходящуюся к $g$

  Для удобства можем считать, что вся последовательность $g_N$ равномерно сходится к $g$

  Мы хотим доказать, что $g$ будет решением интегрального уравнения, для этого нужно проверить следующие свойства $g$
  \begin{enumerate}
  \item 
    $g_N \rightrightarrows g$ на $[t_0,t_0+h]$, $g$ -- непрерывна

  \item   $(t,g_N(t)) \in R \Rightarrow (t,g(t)) \in R$

  \item $g(t) = x_0 + \int_{t_0}^{t}f(s,g(s))ds$?
    \[g_n(t) = x_0 + \int_{t_0}^{t}\dot g_N(s) ds = x_0 + \int_{t_0}^{t}f(s,g_n(s))ds + \int_{t_0}^{t}\dot g_N(s) - f(s,g_n(s)) ds\]

    \begin{equation*}
      \begin{gathered}
        g_N \rightrightarrows g, (t,g_n(t)) \in R, f \in C(R)\\
        \Downarrow \\
        f(t,g_N(t)) \rightrightarrows f(t,g(t)) \text{ на } [t_0,t_0 + h] \\
        \Downarrow \\
        \int_{t_0}^{t}f(s,g_N(s)) ds \rightarrow \int_{t_0}^{t}f(s,g(s))ds
      \end{gathered}
    \end{equation*}

    \[\text{Теперь нужно проверить, что } \int_{t_0}^{t}\dot g_N(s) - f(s,g_n(s)) ds \to 0\]

    Так как $R$ -- компакт и $f$ непрерывна на нем, то $f$ равномерно непрерывна на $R$

    \[\forall \varepsilon > 0\ \exists \delta > 0 : |t_1 - t_2| < \delta \wedge |g_N(t_1) - g_N(t_2)| < \delta \to |f(t_1,g(t_1)) - f(t_2,g(t_2))| < \varepsilon     \]

    Если $t \in [t_k, t_{k+1}]$, то $t - t_k < \frac{h}{N} < \delta$ при больших $N$

    $\dot g_N(t) = f(t_k,g_N(t_k))$, поэтому $|\dot g_N(t) - f(t,g_N(t))| = |f(t_k,g_N(t_k)) - f(t,g_N(t))|$

    Поэтому, если $N$ достаточно велико

    \[\int_{t_k}^{t}|\dot g_N(s) - f(s,g_N(s)) | ds \leqslant \varepsilon (t-t_k)\]

    \[\text{Тогда }\bigg| \int_{t_0}^{t}\dot g_N(s) - f(s,g_N(s))ds \bigg| \leqslant  \bigg|\int_{t_0}^{t_1}\bigg| + \ldots + \bigg|\int_{t_k}^{t}\bigg| \leqslant \]
    \[\leqslant \varepsilon (t_1-t_0) +\ldots + \varepsilon(t- t_k) = \varepsilon (t - t_0)  \leqslant \varepsilon h\]

    Отсюда получаем, что $\int_{t_0}^{t}\dot g_N(s) - f(s,g_N(s))ds \to 0$, следовательно $g(t) = x_0 + \int_{t_0}^{t}f(s,g(s))ds$

   
  \end{enumerate}

  Таким образом, мы нашли решение $g$ для исходного уравнения, и доказали теорему.
  
\end{proof}

\subsection{Напоминание из анализа}


\begin{defn}
  $f$  удовлетворяет \se{Условие Липшица}{условию Липшица} по $x$ в $G \subset \mathbb{R}_{t,x}^{n+1}$ $(f \in \Lip_x(G))$

  Если $\exists L > 0$ такое, что $\forall (t,x), (t,x') \in G$
  $$|f(t,x) - f(t,x')| \leqslant L|x - x'|$$

  

\end{defn}

\begin{defn}
  $f$ удовлетворяет \se{Локальное условие Липшица}{локальномум условию Липшица} по $x$ в $G$, если $\forall (t_0,x_0) in G$ $\exists U$ -- окрестность, такая что $f \in \Lip_x(U)$

  \[f \in \Lip_{x, \loc}(G)\]

\end{defn}


\[\text{Пусть } f = \begin{pmatrix}
    f_1 \\
    \vdots \\
    f_n
  \end{pmatrix} \text{ и } \exists \frac{\partial f_i}{\partial x_j} \ \forall i,j = 1,\ldots,n\]

\begin{defn}
  \se{Матрица Якоби}{Матрица Якоби}

  \[\frac{\partial f}{\partial x} = \begin{pmatrix}
      \frac{\partial f_1}{\partial x_1} \ldots \frac{\partial f_1}{\partial x_n} \\
      \vdots \ddots \vdots \\
      \frac{\partial f_n}{\partial x_1} \ldots \frac{\partial f_n}{\partial x_n}
    \end{pmatrix}
  \]
\end{defn}

\begin{defn}
  $A$ -- матрица, тогда норма $||A|| = \max\limits_{|x| = 1} |Ax|$
\end{defn}
\[\forall x\ |x| \leqslant ||A|| \cdot |x|\]

\begin{lemma}
  \[\frac{\partial f}{\partial x} \in C(G) \Rightarrow f \in \Lip_{x,\loc}(G)  \]
\end{lemma}
\begin{proof}
  Фиксируем $(t_0,x_0)$

  \[\exists \alpha, \beta > 0 : G \supset R = \{(t,x) \ | \ |t-t_0| \leqslant \alpha, |x-x_0| \leqslant \beta\} \]

  \[\exists L > 0: \ ||\frac{\partial f}{\partial x}|| \text{ в } R  \]

  Рассмотрим $(t,x), (t,x') \in R, \ g(s) = f(t, sx + (1-s)x')$

  \begin{equation*}
    \begin{gathered}
      f(t,x) - f(t,x') = g(1) - g(0) = \int_{0}^{1}\frac{\partial g}{\partial s}ds  = \int_{0}^{1}\frac{\partial f}{\partial x}(t,sx + (1-s)x')ds \\
      |f(t,x) - f(t,x')| \leqslant |\int_{0}^{1}| \leqslant \int_{0}^{1}|\ldots| \leqslant \int_{0}^{1}L|x-x'|ds = L|x - x'|
    \end{gathered}
  \end{equation*}
  
\end{proof}

\begin{lemma}
  \[f \in C(G), \Lip_{x,\loc}(G), K \text{ -- компакт в } G\]
  \[\Downarrow \]
  \[f \in \Lip_x(K)\]
\end{lemma}
\begin{proof}
  Предположим противное:

  \[\forall L_n \to \infty \ \exists (t_n,x_n), (t_n, x_n') \in K:\]
  \[|f(t_n,x_n) - f(t_n,x_n') | > L_n |x_n - x_n'|\]

  Так как $K$ -- компакт, то из $(t_n,x_n)$ можно выбрать сходящуюся подпоследовательность $(t_{n_k},x_{n_k}) \to (t_0, x_0)$

  После этого можно выбрать сходящуюся подпоследовательность из $t_{n_k}, x_{n_k}'$, сходяющуюся к $(t_0,x_0')$

  Для удобства будем считать, что $(t_n,x_n) \to (t_0,x_0), \ (t_n,x_n') \to (t_0,x_0)$
  \begin{description}
  \item[Случай 1] $x_0 = x_0'$
    Так как $f$ -- локально-липшицева по $x$, то $\exists U \ni (t_0,x_0)$ и $L$, такие, что
    \[(t,x), (t,x') \in U  \to |f(t,x) - f(t,x')| \leqslant L|x - x'|\]

    При достатчно больших $n$ $(t_n,x_n), \ (t_n,x_n') \in U$ и мы получаем противоречие
  \end{description}
\item[Случай 2] $x_0 \neq x_0'$

  Рассмотрим $g(t,x,y) = \frac{|f(t,x) - f(t,y)|}{|x-y|} $, $f \in C(G) \Rightarrow $ $g$ непрервывна в окрестности $U$ точки $(t_0,x_0,x_0')$

  \[\Rightarrow \exists L : |g(t,x,y)| \leqslant L \Rightarrow |f(t,x) - f(t,y)| \leqslant L|x-y|\]
  
  Тогда для достаточно больших $n$ $(t_n,x_n,x_n') \in U$ и мы снова получаем противоречие.
  
\end{proof}

\subsection{Лемма Гронуолла}

\begin{lemma}
  (\se{Лемма Гронуолла}{Лемма Гронуолла})

  Пусть $\varphi(t) \geqslant 0$ при $t \in (a,b)$ и  $\exists t_0 \in (a,b), \lambda, \mu \geqslant 0$, такие что
  \[\varphi (t) \leqslant \lambda + \mu \bigg|\int_{t_0}^{t}\varphi (s) ds \bigg| , \ t \in (a,b)\]

  \[\text{Тогда } \varphi (t) \leqslant \lambda e^{\mu(t - t_0)}\]

\end{lemma}
\begin{proof}
  Разберем случай, когда $t \leqslant t_0$ (случай $t < t_0$ оставим на проверку любопытному читателю)

  \[\Phi(t) := \lambda + \mu \bigg|\int_{t_0}^{t}\varphi (s) ds \bigg| \geqslant \varphi (t)\]

  \[\dot \Phi(t) = \mu \varphi (t) \leqslant \mu \Phi(t)\]
  \[\Downarrow \]
  \[e^{-\mu(t-t_0)} \dot \Phi - \mu e^{\mu(t-t_0)}\Phi \leqslant 0\]
  \[\frac{d}{dt} (\Phi e^{-\mu(t-t_0)}) \leqslant 0 \]
  \[\Downarrow \]
  \[\Phi e^{-\mu(t-t_0)} \leqslant \Phi(t_0) = \lambda\]
  
\end{proof}


Частный случай:

\[\varphi(t) \leqslant  \mu \bigg|\int_{t_0}^{t}\varphi (s) ds \bigg| \Rightarrow \varphi (t) = 0\]

\subsection{Метод приближений Пикара}

\begin{theorem}
  (\se{Теорема Пикара}{Теорема Пикара})
  \[\dot x = f(t,x), x \in \mathbb{R}^n   \]
  \[f \in  C, \Lip_{x,\loc}(G) \subset \mathbb{R}^{n+1}  \]
  \[\Rightarrow \text{ $G$ -- область существования и единственности}\]
\end{theorem}
\begin{proof}
  \begin{description}
  \item [Существование]
    Зафиксируем $(t_0,x_0) \in G$
    Возьмем $\alpha, \beta > 0 $, что $R = \{(t,x) \ | \ |t - t_0| \leqslant \alpha, |x - x_0| \leqslant \beta\} \subset G$

    \[\exists M > 0: \ |f(t,x)| \leqslant M, \ (t,x) \in R\]

    \[h = \min(\alpha, \frac{\beta}{M})\]
    $L > 0$ -- константа Липшица по $x$ в $R$

    \se{Последовательные приближения Пикара}{Последовательные приближения Пикара} $\varphi_k(t)$
    
    \[\varphi_0(t) \equiv x_0\]

    \[\varphi_{k+1} = x_0 + \int\limits_{t_0}^{t}f(s,\varphi_k(s)) ds, \ k \leqslant  0\]
    

    \begin{lemma}
      $\forall k$ $\varphi_k$ определены на $[t_0 - h, t_0 + h]$ и их графики лежат в $R$
      
    \end{lemma}
    \begin{proof}
      Идукция по $k$
      \begin{description}
      \item[База] $\varphi_0 \equiv x_0$ для всех $t$, график очевидно лежит в $R$
      \item[Переход] \[\varphi_{k+1} = x_0 + \int_{t_0}^{t}f(s,\varphi_k(s))ds\]

        \[(s,\varphi_k(s)) \in R \Rightarrow \text{ $f$ -- определена}\]

        \[|\varphi_{k+1}(t) - x_0| = \bigg|\int_{t_0}^{t}f(s,\varphi_k(s)ds\bigg| \leqslant M|t - t_0| \leqslant Mh \leqslant \beta\]

      \end{description}
    \end{proof}

    Докажем теперь, что $\varphi_k$ -- равномерно сходятся на $[t_0 - h, t_0 + h]$

    Введем $\psi_0(t) = \phi_0(t), \ \psi_k(t) = \varphi_k(t) - \varphi_{k-1}(t)$ при $k \geqslant 0$

    Рассмотрим теперь ряд
    \[\sum_{k = 0}^{\infty}\psi_k(t)\]

    Частинчые суммы этого ряда равны $\varphi_k(t)$

    Поэтому сходимость ряда $\Longleftrightarrow$ сходимость $\varphi_k(t)$
    \begin{lemma}
      $k \geqslant 1 \Rightarrow |\psi_k(t)| \leqslant \frac{M}{L}\frac{|L(t-t_0)|^k}{k!}$
    \end{lemma}
    \begin{proof}
      Рассмотрим только случай $t \geqslant t_0$
      \begin{description}
      \item[$k = 1$]       \[|\psi_1(t)| = |\varphi_1(t) - \varphi_0(t)| = \bigg|\int_{t_0}^{t}f(s,\varphi_0(s))ds\bigg| \leqslant  \int_{t_0}^{t}|f(s,\varphi_0(s))|ds \leqslant M|t-t_0|\]
      \item [$k \to k+1$] \[|\psi_{k+1}| =| \varphi_{k+1} - \varphi_{k}| = \bigg| \int_{t_0}^{t}f(s,\varphi_{k}(s))  - f(s,\varphi_{k-1}(s))ds\bigg| \leqslant  \]
        \[\leqslant \int_{t_0}^{t}|f(s,\varphi_k(s)) - f(s,\varphi_{k-1}(s))| ds \leqslant \int_{t_0}^{t}L |\psi_k(s)|ds \leqslant \int_{t_0}^{t}L \frac{M}{L} \frac{|L(s - t_0)|^k}{k!} ds = \frac{M}{L} \frac{|L(t-t_0)|^{k+1}}{(k+1)!} \]
      \end{description}
    \end{proof}

    \begin{equation*}
      \begin{gathered}
        \sum_{}^{}|\psi_k(t)| \leqslant \sum_{}^{}\frac{M}{L}\frac{|L(t-t_0)|^k}{k!} \leqslant \frac{M}{L} \frac{(Lh)^k}{k!} = \frac{M}{L} e^{Lh}
        \\
        \Downarrow
        \\
        \sum_{}^{}\psi_k \text{ -- сходистя равномерно на } [ t_0 - h, t_0 + h]
      \end{gathered}
    \end{equation*}

    \[\varphi_k \rightrightarrows g\]
    Проверим, тчо $g$ является решением нашего уравнения, для этого достаточно проверить, что $g$ --  решение эквивалентного интегрального уравнения
    \begin{equation*}
      \begin{gathered}
        \varphi_k \text{ непрерывна } \Rightarrow g \text{ непрерывна }
        \\
        (t,\varphi_k(t)) \in R \Rightarrow (t,g(t)) \in R
        \\
        \varphi_{k+1} = x_0 + \int_{t_0}^{t}f(s,\varphi_k(s))ds
        \\
        f \text{ равномерно непрерывна на } R \Rightarrow f(s,\varphi_k(s)) \rightrightarrows f(s,g(s)) \text{ на } R
        \\
        \Downarrow
        \\
        \int_{t_0}^{t}f(s,\varphi_k(s))ds \to \int_{t_0}^{t}f(s,g(s))ds
        \\
        \Downarrow
        \\
        g(t) = x_0 
      \end{gathered}
    \end{equation*}
  \item[Единственность]
    Предположим, что существуют два различных решения $x_1(t), x_2(t)$ задачи Коши с начальным условиям $(t_0,x_0)$

    \[(t,x_1(t)), (t,x_2(t)) \in R\]

    \begin{equation*}
      \begin{gathered}
        x_1(t) = x_0 + \int_{t_0}^{t}f(s,x_1(s))ds \\
        x_2(t) = x_0 + \int_{t_0}^{t}f(s,x_2(s))ds \\
        |x_1(t) - x_2(t)| \leqslant \bigg| \int_{t_0}^{t}|f(s,x_1(s))ds f(s,x_2(s))|ds \bigg| \leqslant \bigg| \int_{t_0}^{t}L |x_1(s) - x_2(s)| ds \bigg| \\
        |x_1 - x_2| \geqslant 0 \Rightarrow \text{ по лемме Гронуолла } x_1 = x_2
      \end{gathered}
    \end{equation*}
  \end{description}
\end{proof}


\begin{theorem}
  $G$ -- область единственности, тогда если существует два решения $x_1, x_2$ на промежутках $(a_1,b_1)$ и $(a_2,b_2)$ соответственно и $\exists \ t_0 \in (a,b) = (a_1,b_1) \cap (a_2,b_2): \ x_1(t_0) = x_2(t_0)$
  \[\Downarrow \]
  \[x_1 \equiv x_2 \text{ на }(a,b)\]
\end{theorem}
\begin{proof}
  Докажем, что они совпадают на $[t_0,b)$, остальное аналогично
  \[T :=  \{t' \ | \ t' \geqslant t_0, x_1 |_{[t_0,t']} = x_2 |_{[t_0,t']}\} \]
  \[T' = \sup T\]
  Предположим, что $T' < b$

  Тогда по непрерывности $x_1(T') = x_2(T') = x'$

  Так как $(T',x') \in G$, а $G$ -- область единственности, то $x_1(t) = x_2(t)$ на $[T', T' + \varepsilon)$ $\Rightarrow T' + \varepsilon  \in T $, получаем противоречие с тем, что $T'$ -- $\sup$
\end{proof}

\subsection{Метод сжимающих отображений}

\[\dot x = f(t,x), \ f \in C,\Lip_{x,\loc}(G)\]
\[(t_0,x_0) \in G, \ (t,_0,x_0) \in R \subset G, \ L \text{ -- константа Липшица}\]

\[h_0 \leqslant h \text{ такое что } Lh_0 < 1\]

\[X := \{x \text{ -- непрерывные функции на }[t_0 - h_0,t_0 + h_0], (t,x(t)) \in R\}\]
\[\text{Метрика на $X$: } \rho(x,y) = \max\limits_{t \in [t_0 - h_0,t_0 + h_0]} |x(t) - y(t)|\]
\begin{center}
  $(X, \rho)$ -- полное метрическое пространство
\end{center}

Введем оператор $\mathcal{L} : X \to X$

\[\mathcal{L}(\varphi) = \psi(t) =  x_0 \int_{t_0}^{t}f(s,\varphi(s))ds \]

\begin{description}
\item[Корректность]
  Очевидно, $\psi$ непрерывна, нам нужно только показать, что $(t,\psi(t)) \in R$
  \[|\psi(t) - x_0| = \bigg|\int_{t_0}^{t}f(s,\varphi(s))ds \bigg| \leqslant M|t -t_0| \leqslant Mh \leqslant \beta\]
  \[\Downarrow \]
  \[(t,\psi(t)) \in R\]
\item[Сжимаемость]
  \[\varphi_1, \varphi_2 \in X\]
  \begin{equation*}
    \begin{gathered}
      \rho(\mathcal{L}(\varphi_1),\mathcal{L}(\varphi_2)) = \max\limits_t \bigg| \int_{t_0}^{t}f(s,\varphi_1(s)) - f(s,\varphi_2(s))ds \bigg| \leqslant  \\
      \leqslant \max\limits_t \int_{t_0}^{t}L |\varphi_1(s) - \varphi_2(s)| ds \leqslant \max\limits_t \bigg|\int_{t_0}^{t}L\rho(\varphi_1,\varphi_2)ds \bigg|\leqslant \\
      \leqslant \max\limits_t |t-t_0| L \rho(\varphi_1,\varphi_2) \leqslant Lh_0 \rho(\varphi_1,\varphi_2)\\
      Lh_0 < 1
    \end{gathered}
  \end{equation*}
\end{description}

По теореме о сжимающем отображении существует единственная неподвижная точка
\[\varphi(t) = x_0 + \int_{t_0}^{t}f(s,\varphi(s))ds\]

Отсюда мы получаем существование и единственность решения для задачи Коши.

\section{Продолжимость решений}

\[\dot x = f(t,x), x \in \mathbb{R}^n, f \in C(G), \ G \text{ -- область единственности}\]

\begin{defn}
  $x(t)$ -- решение на $(a,b)$

  Решение $y(t)$ -- \se{Продолжение решения}{продолжение вправо} $x(t)$, если $y$ решение на $(a,b_1), \ b_1 > b$ и $x|_{(a,b)} = y|_{(a,b)}$ 
\end{defn}

\begin{theorem}
  \se{Теорема о продолжимости вправо}{Теорема о продолжимости вправо}
  Решение $x$ на $(a,b)$ продолжимо вправо за $b$ $\Longleftrightarrow$ $\exists x' = \lim\limits_{t \to b-0}x(t), (b,x') \in G$
\end{theorem}

\begin{proof}
  
  \begin{description}
    
  \item[$"\Rightarrow"$] Очевидно
  \item[$"\Leftarrow"$]  По теореме существования $\exists z(t)$ на промежутке $(b - h, b+h): z(b) = x'$

    \[Рассмотрим  \ y(t) = \begin{cases}
      x(t), t \in (a,b) \\
      z(t), t \in [b,b+h)
    \end{cases}\]

  \[y'(b) = z'(b) = f(b,x')\]
  \[y(b) = z(b)\]
    $y(t)$ -- продолжение $x$ вправо за $b$
  \end{description}
\end{proof}


\begin{defn}
  $x(t)$ -- \se{Полное решение}{полное решение} на $(a,b)$, если оно не продолжимо вправо за $b$ и влево за $a$
\end{defn}

\begin{theorem}
  \se{Существование и единственность полного решения}{Существование и единственность полного решения}

  $\forall (t_0,x_0) \in G \ \exists !$ полное решения задачи Коши с н.д. $(t_0,x_0)$
\end{theorem}

\begin{proof}
  Фиксируем $(t_0,x_0)$
  
  Рассмотрим
  \[T = \{(a,b) \ni t_0 \ | \ \exists \text{ решение задачи Коши } x(t) \text{ на } (a,b)\}\]
  \[T \neq \emptyset\]

  \[A = \inf a, B = \sup b : (a,b) \in T\]

  Докажем, что $\exists ! $ полное решение на $(A,B)$

  Будем рассматривать только $[t_0,B)$ (влево аналогично). Для начала определим решение на этом промежутке.

  Фиксируем $\tau \in (t_0,B)$

  Так как $B = \sup\{b\} \Rightarrow \exists b \in (\tau,B), \ \exists x_b$ -- решение на $[t_0,b)$

  Положим $x(\tau) = x_b(\tau)$

  \begin{description}
  \item[Корректность] 

    Рассмотрим $b' \in (\tau,b)$

    По теореме об области единственности $ x_b(t) = x_{b'}(t)$ на $[t_0,b) \cap [t_0,b') \Rightarrow x_b(\tau) = x_{b'}(\tau)$

    Получаем, что $x(t)$ -- корректно определенная функция, очевидно, что она является решением.

    \item[Единственность]

      Пусть есть $x_1(t)$ -- полное решение  на $(A_1,B_1)$ и  $x_2(t)$ -- полное решение на $(A_2,B_2)$, по  теореме единственности они совпадают на пересечении

    Если $(A_1,B_1) \cap (A_2,B_2) \neq (A_1,b_1)$, то (без ограничения общности можно считать, что $B_2 > B_1$) тогда $x_2$ -- продолжение $x_1$ вправо, но $x_1$ было полным, получаем противоречие.
   \end{description}
\end{proof}


\begin{theorem}
  \se{Теорема о полном решении и компакте}{Теорема о полном решении и компакте}

  Пусть $K$ -- компактное подмножество в $G$

  $x(t)$ -- полное решение на  конечном промежутке $(a,b)$

  $\Rightarrow \exists \Delta = \Delta(K) > 0: (t,x(t)) \not \in K, t \in (a,a + \Delta) \cup (b - \Delta, b)$
\end{theorem}
\begin{proof}
  \[\exists \alpha, \beta > 0 : \ \forall (t_0,x_0) \in K : H(t_0,x_0) = \{|t - t_0| \leqslant \alpha, |x - x_0 | \leqslant \beta \} \subset G\]

  \[\Rightarrow H' = \bigcup\limits_{(t_0,x_0) \in K} H(t_0,x_0) \text{ -- компакт в }G\]

  \[\Rightarrow \ \exists M > 0 \ |f(t,x)| \leqslant M \text{ в } H'\] 
  \[\Rightarrow \forall (t_0,x_0) \in K \text{ берем } R = H(t_0,x_0)\]
  \[\exists h \ \forall (t_0,x_0) \in K: \ [t_0-h,t_0+h] \text{ -- промежуток Пеано}\]
  \[h = \min( \alpha, \frac{\beta}{M})\]
  \[\Delta := \frac{h}{2}\]

  Рассмотрим полное решение $x(t) $ на  $(a,b)$

  Предположим, что $\exists \tau \in (b - \Delta,b) : (\tau,x(\tau)) \in K$

  Тогда $\exists$ решение $x(t)$ задачи Коши с н.д. $ (\tau,x(\tau))$ на $[\tau - h,\tau + h]$

  Рассмотрим \[y(t) = \begin{cases}
      x(t) , t \in (a,\tau)\\
      z(t) ,  t \in [\tau, \tau + h)
    \end{cases}\]
  Определено на $(a,\tau + h), \tau + h = \tau + 2 \Delta > b$

  $\Rightarrow  y$ -- продолжение $x(t)$ за $b$ вправо.
\end{proof}

\[y' = f(y), y \in \mathbb{R} f \in C[0,1], f(y) > 0, y \in (0,1], f(0) = 0\]



\begin{defn}
  Система $\dot x = f(t,x)$ называется \se{Сравнимая с линейной система}{сравнимой с линейной}, если

  \begin{enumerate}
  \item $G = (a,b) \times \mathbb{R}^n$
  \item $\exists$ непрерывные $m(t)$ и $n(t)$ на $(a,b): m(t), n(t) \leqslant 0$

    \[|f(t,x)| \leqslant m(t)|x| + n(t)\]
  \end{enumerate}
\end{defn}


\begin{theorem}
  Если система сравнима с линейной, то любое полное решение определено на промежутке $(a,b)$
\end{theorem}
\begin{proof}
  Пусть $x(t)$ -- полное решенеие на $(a',b')$

  Предположим, что $b' < b$, выберем $t_0 \in (a',b'), \ x_0 = x(t_0)$


  Рассмотрим $[t_0,b'] \subset (a,b) \Rightarrow \exists M,N > 0: \ m(t) \leqslant M, n(t) \leqslant N$ на $[t_0,b']$

  Запишем интегральное уравнение для $x$

  \[x(t) = x_0 + \int_{t_0}^{t}f(s,x(s))ds\]

  \[t \in [t_0,b'): \ |x(t)| \leqslant |x_0| = \bigg| \int_{t_0}^{t}f(s,x(s))ds \bigg| \leqslant \]
  \[\leqslant |x_0| + \bigg| \int_{t_0}^{t} m(s)|x(s)| + n(s) ds \leqslant |x_0| + \int_{t_0}^{t}M|x(s)| + N ds\]
  \[\Downarrow \]

  \[|x(t)| \leqslant |x_0| + N |b' - t_0| + M \int_{t_0}^{t}|x(s)|ds\]
  \[\Downarrow \text{ (лемма Гронуолла)}\]
  \[|x(t)| \leqslant (|x_0+ N|b - t_0|) e^{M(t-t_0)}\leqslant(|x_0|+ N|b - t_0|)e^{M(b'-t_0)} =: N_1 \]

  \[(t,x(t)) \in K, \ t \in [t_0,b'), \ K = [t_0,b'] \times \{|x| \leqslant N1\}\]

  Получаем противоречие с теоремой о полном решении и компакте, так как для любого сколь угодно близкого слева к $b'$ числа $t$ $(t,x(t))$ содержится в компакте $K$
\end{proof}

\section{Линейные системы дифференциальных уравнений}

\[\dot x = P(t)x + q(t), x \in \mathbb{R}^n, \ P(t) \text{ непрерывная на $(a,b) \ n \times n $-матрица  } q(t) \text{ непрерывный на $(a,b)$ вектор}\]
\begin{center}
  Что мы знаем про нашу систему?
\end{center}
\[f(t,x) = P(t)x + q(t)\]

\[f \in C(G), G = (a,b) \times \mathbb{R}^n\]

Матрица Якоби $\frac{\partial f}{\partial x} = P(t)$ -- непрерывна в $G$

\[f \in \Lip_{x,\loc}(G)\]

\begin{center}
  $G$ -- область существования и единственности
  
\end{center}

\[|f(t,x)| \leqslant ||P(t)|| \cdot |x| + |q(t)|\]

\[||P(t)||, |q(t)| \leqslant 0 \text{ и непрерывны в $G$}\]

Любое полное решение $x(t)$ определено на $(a,b)$


Далее мы будем рассматирвать только полные решения.

\begin{center}
  Свойство существования и единственности
\end{center}

\begin{enumerate}
\item $\forall (t_0,x_0) \in G \ \exists$ решение задачи Коши с начальными данными $(t_0,x_0)$, определенное на $(a,b)$
\item Если $x_1(t)$ и $x_2(t)$ -- решения на $(a,b)$ и $\exists t_0 \in  (a,b): \ x_1(t_0) = x_2(t_0)$, то $x_1|_{(a,b)} = x_2|_{(a,b)}$
\end{enumerate}

\subsection{Однородные линейные системы}

\[\dot x = P(t)x, x \in \mathbb{R}^n, P(t) \in C((a,b))\]

\begin{theorem}
  Множество решений ЛОС -- линейное пространство над $\mathbb{R}$
\end{theorem}
\begin{proof}
  Очевидно.
\end{proof}


Рассмотрим $n$ решений $x_1(t), \ldots x_n(t)$

Сопоставим им $n\times n$ матрицу
\[\Phi(t) = (x_1(t), \ldots, x_n(t))\]

Обозначим $W(t) = \det \Phi(t)$ -- \se{Определитель Вронского (вронскиан)}{Определитель Вронского (вронскиан)}

\begin{lemma}
  $\exists t_0 : W(t_0) = 0 \Rightarrow W(t) \equiv 0 $
\end{lemma}
\begin{proof}
  Рассмотрим линейную алгебраическую систему
  \[\Phi(t_0) c = 0\]

  Так как $\det = 0 \Rightarrow \exists c \neq 0$ -- решение

  \[c = \begin{pmatrix}
      c_1\\
      \vdots\\
      c_n
    \end{pmatrix}\]

  Тогда $x(t) = \Phi(t) c = c_1 x_1(t) + \ldots + c_n x_n(t)$ -- решение

  \[x(t_0) = \Phi(t_0) c = 0\]

  \[Есть решение \ y(t) \equiv 0\]

  \[x(t_0) = y(t_0) \Rightarrow x(t) \equiv 0\]

  \[\Phi(t) c \equiv 0, \ c \neq 0 \Rightarrow \det \Phi(t) \equiv 0\]
\end{proof}

Главная задача -- описать структуру множества решений линейной однородной системы


\begin{defn}
  $\Phi(t) = (x_1(t), \ldots , x_n(t))$  --  \se{фундаментальная матрица}{фундаментальная матрица}, если существует $t_0 \in (a,b)$, в которой $W(t_0) \neq 0$ (тогда по предыдущей лемме $W(t) \neq 0$ на $(a,b)$)
\end{defn}

\begin{theorem}
  $\forall $ ЛОС $\exists$ фундаментальная матрица
\end{theorem}
\begin{proof}
  Фиксируем $t_0 \in (a,b)$, $a_1\ldots a_n \in \mathbb{R}^n$ -- линейно независимы.

  Тогда $\forall i$ существует решение $x_i(t), x_i(t_0) = a_i$

  Возьмем в качестве фундаментальной матрицы $\Phi(x_1, \ldots , x_n), \ \Phi(t_0) = (a_1, \ldots a_n) $,
  
  $W(t_0) \neq 0 \Rightarrow W(t) \neq 0$ на всем интервале.

\end{proof}
\begin{remark}
  $a_i = e_i$ -- базисные векторы тогда $\Phi(t_0) = E$

  $\Phi(t)$ -- \se{фундаментальная матрица, нормированная к единичной}{фундаментальная матрица, нормированная к единичной} при $t = t_0$
\end{remark}

\begin{theorem}
  \se{Теорема об общем решениии ЛОС}{об общем решениии ЛОС}

  $\Phi(t)$ -- фундаментальная матрица $\Rightarrow \forall  x(t)$ -- решение ЛОС $\exists! \ c \in \mathbb{R}^n: x(t) = \Phi(t) c$
\end{theorem}
\begin{proof}
  $\Phi(t)$, рассмотрим решение $x(t)$, фиксируем точку $t_0 \in (a,b)$

  Рассмотрим линейную алгебраическую систему

  \[\Phi(t_0) c = x(t_0)\]

  Поскольку $\Phi$ -- фундаментальная матрица, ее определитель отличен от нуля и эта система имеет единственное решение.

  Рассмотрим $y(t) = \Phi(t)c$ -- линейная комбинация столбцов $\Phi(t)$, поэтому это тоже  решение ЛОС

  \[y(t_0) = \Phi(t_0) c = x(t_0)\]

  По единственности решений ЛОС $y(t) = x(t)$ на $(a,b)$

  Единственность $c$ следует из единственности решения алгебраической системы.
\end{proof}

Таким образом, мы установили линейный изоморфизм:

\[\{\text{решения ЛОС} \}\simeq \mathbb{R}^n\]
\[x(t) = \Phi(t)c\]

Выбор фундаментальной матрицы -- выбор базиса пространства решений.

\begin{theorem}
  \se{Теорема о множестве фундаментальных матриц}{о множестве фундаментальных матриц}

  $\Phi$ -- ф.м. $\Rightarrow \{ \text{ф.м. ЛОС}\} = \{\Phi(t) C: C $ -- матрица $n \times n, \det C \neq 0\}$
\end{theorem}

\begin{proof}
  \begin{description}
  \item[$"\supset"$] Рассмотрим $\Psi = \Phi C$

    Столбцы $\Psi$ -- линейные комбинации столбцов $\Phi$, значит они решения. $\det \Psi = \det \Phi \cdot\det C \neq 0$
  \item [$"\subset"s$] $\Psi$ -- ф.м. $\Psi = (\psi_1, \ldots \psi_n)$

    $\forall i \ \psi_i =  \Phi c_i \Rightarrow \Psi = (\Phi c_1, \ldots , \Phi c_n) = \Phi C, \ C = (c_1, \ldots , c_n)$

    $0 \neq \det \Psi \det \Phi \det C \Rightarrow \det C \neq 0$
  \end{description}
\end{proof}

\begin{theorem}
  Пусть $\Phi(t) = (x_1(t) , \ldots , x_n(t))$, $x_i$ -- решения ЛОС

  $\Rightarrow \frac{d \Phi(t)}{dt} = P(t) \Phi(t)$
\end{theorem}
\begin{proof}
  \[\frac{dx_i}{dt} = Px_i\]
  \[\frac{d \Phi}{dt} = (Px_1, \ldots , Px_n) = P (x_1, \ldots , x_n) = P\Phi\]
\end{proof}

\subsection{Задача нахождения фундаментальной матрицы}

\begin{itemize}
\item 
Тривиальна в случае $n = 1$

\[\dot x = p(t), \ \Phi(t) = e^{\int_{}^{}p(t)dt}\]

\item 
$n = 2$ Построение ф.м. по $P(t)$ --  неразрешимая задача:

\begin{proof}
Рассмотрим уравнение $\ddot y + t^{\alpha}y = 0 \Leftrightarrow  \begin{cases}\dot y = z \\ \dot z = -t^{\alpha}y \end{cases}$

Предположим $y(t) \not \equiv 0$

\[ \text{Рассмотрим }x(t) = \frac{\dot y}{y}\]

\[\text{Тогда } \dot x = - \frac{1}{y^2}(\dot y)^2 + \frac{1}{y} \dot \dot y = -x^2 - t^{\alpha}\] -- уравнение Рикатти, для которого ни одно решение не представимо в элементарных функциях.

А если $x$ не представим в элементарных функция, то и $y$ не представим в элементарных функциях.
\end{proof}

\end{itemize}
\subsection{Комплексные Решения ЛОС}

\[\dot x = P(t) x, x \in \mathbb{R}^n, P \in C(a,b)\]

\[z = x + iy, \ x,y \in \mathbb{R}^n\]

\begin{lemma}
  $P(t)$ -- вещественная матрица, $z = x + iy$ -- комплексное решение $  \Leftrightarrow x,y$ -- вещественное решения
  
\end{lemma}

\begin{lemma}
  \se{Лемма об овеществлении}{об овеществлении}

  $\Psi(t) = (y_1, \ldots, y_2)$ -- комплексная фундаментальная матрица, у котрой $y_1 = \overline{y_2}$ 

  $\Phi(t) = (\Real y_1, \Imf y_1, y_3, \ldots, y_n)$ -- ф.м

  
\end{lemma}
\begin{proof}
  \[\Phi = \Psi \begin{pmatrix}
    \frac{1}{2} & \frac{1}{2i} & 0 & \ldots & 0 \\
    \frac{1}{2} & \frac{1}{2i} & 0 & \ldots &0 \\
    0 & 0 &1 &\ldots& 0 \\
    \vdots & \vdots &\vdots  & \ddots &\\
    0 & 0 & 0 & \ldots & 1
    
  \end{pmatrix}\]

  \[\det \neq 0\]
\end{proof}


\section{Системы с постоянными коэффициентами}

\[\dot x = Ax, x \in \mathbb{R}^n\]

\subsection{Метод Эйлера}

Ищем решения в виде $x(t) = \gamma e^{\lambda t},\  \gamma \neq 0$

\[\dot x = \lambda \gamma e^{\lambda t} = A \gamma e^{\lambda t} \]
\[\Updownarrow\]
\[A \gamma = \lambda \gamma\]


Простой частный случай: $\lambda_1, \ldots, \lambda_n \in \mathbb{R} $ и простые(кратность каждого 1)

Тогда есть $n$ решений $\gamma_1 e^{\lambda_1 t}, \ldots, \gamma_n e^{\lambda_n t}$

\[\Phi(t) = \gamma_1 e^{\lambda_1 t}, \ldots, \gamma_n e^{\lambda_n t} \text{ -- фудаментальна}\]




$\{ A \ n\times n \text{ комплексные матрицы}\}$

$||A||$ -- операторная норма $A$

\[||AB|| \leqslant ||A|| \cdot ||B||\]

\begin{defn}
  \se{Матричная экспонента}{Матричная экспонента}
  \[e^A = \sum_{k = 0}^{\infty} \frac{A^K}{k!}\]
\end{defn}

\begin{theorem}
  Этот ряд сходистя
\end{theorem}
\begin{proof}
  $\Sigma_m = \sum_{k = 0}^{M}\frac{A^k}{k!}$

  \[||\Sigma_m - \Sigma_{m+l}|| = || \sum_{k= m+1}^{m+l}\frac{A^k}{k!} ||\leqslant \sum_{k = m+1}^{m+l}\frac{||A||^k}{k!} \to 0\]
  
\end{proof}

\begin{theorem}
  $B = S^{-1} AS \Rightarrow e^B = s^{-1} e^A S$
\end{theorem}

Для матриц, вообще говоря, неверно равенство $e^{A+B} = e^A e^B$
\begin{theorem}
  \[AB = BA \Rightarrow e^{A+B} = e^A e^B\]
\end{theorem}
\begin{proof}
  \begin{equation*}
    \begin{gathered}
      \sum_{k = 0}^{m} \frac{1}{k!}(A+B)^k = \sum_{k = 0}^{m}\frac{1}{k!}(A+B) \ldots (A+B) =\\ = \sum_{k = 0}^{m} \frac{1}{k!} \sum_{l = 0}^{k } \frac{k!}{l!(k-l)!}A^l B^{k-l} = \sum_{k = 0}^{m} \sum_{l = 0}^{k}\frac{A^l}{l!}  \frac{B^{k - l}}{(k-l)!} \to e^A e^B
    \end{gathered}
  \end{equation*}


  
\end{proof}

\[e^{At} = \sum_{k = 0}^{\infty}\frac{A^kt^k}{k!}, \ t \in \mathbb{R}\]
\begin{theorem}
  \[\frac{d}{dt}e^{At} = A e^{At}\]
\end{theorem}

\begin{proof}
  \[\frac{d}{dt}\sum_{k =0 }^{m}\frac{1}{k!}A^kt^k = \frac{d}{dt}\left(E + At + \ldots \frac{1}{m!}A^m t^m \right) = A + A^2 t+ \ldots \frac{1}{(m-1)!}A^m t^{m-1} = A\left(\sum_{k = 0}^{m-1}\frac{A^kt^k}{k!}\right)\]
\end{proof}

\begin{cons} $e^{At}$ -- фундаментальная матрица $\dot x = Ax$

\[\frac{d}{dt}e^{At} = Ae^{At} \Rightarrow \text{ столбцы } e^{At} \text{ -- решения}\]


\[t = 0, e^{A \cdot 0} = E\]
\end{cons}

\[\text{Если }A = \diag(\lambda_1, \lambda_n)\]
\[A^k = \diag (\lambda_1^k, \ldots, \lambda_n^k)\]
\[e^{At} = \diag (e^{\lambda_1}, \ldots, e^{\lambda_n})\]

\newpage
\hypertarget{dex}
    \printindex  

\end{document}
