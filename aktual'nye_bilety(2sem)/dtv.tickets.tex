\documentclass[a4paper,100pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[unicode, pdftex]{hyperref}
\usepackage{cmap}
\usepackage{mathtext}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools}
\usepackage{icomma}
\usepackage{euscript}
\usepackage{mathrsfs}
\usepackage{geometry}
\usepackage[usenames]{color}
\hypersetup{
     colorlinks=true,
     linkcolor=magenta,
     filecolor=magenta,
     citecolor=black,      
     urlcolor=magenta,
     }
\usepackage{fancyhdr}
\pagestyle{fancy} 
\fancyhead{} 
\fancyhead[LE,RO]{\thepage} 
\fancyhead[CO]{\hyperlink{t2}{к указателю}}
\fancyhead[LO]{\hyperlink{t1}{к содержанию}} 
\fancyhead[CE]{текст-центр-четные} 
\fancyfoot{}
\newtheoremstyle{indented}{0 pt}{0 pt}{\itshape}{}{\bfseries}{. }{0 em}{ }

%\geometry{verbose,a4paper,tmargin=2cm,bmargin=2cm,lmargin=2.5cm,rmargin=1.5cm}

\title{ДТВ.билеты 2 семестр}
\author{Кабашный Иван (@keba4ok) \\ Горбунов Леонид, Савельев Артём \\ на основе лекций Ю. А. Давыдова \\ и других материалов}
\date{28 мая 2021 г.}

\theoremstyle{indented}
\newtheorem{theorem}{Теорема}
\newtheorem{lemma}{Лемма}

\theoremstyle{definition} 
\newtheorem{defn}{Определение}
\newtheorem{exl}{Пример(ы)}

\theoremstyle{remark} 
\newtheorem{remark}{Примечание}
\newtheorem{cons}{Следствие}
\newtheorem{exer}{Упражнение}
\newtheorem{stat}{Утверждение}

\DeclareMathOperator{\la}{\leftarrow}
\DeclareMathOperator{\ra}{\rightarrow}
\DeclareMathOperator{\lra}{\leftrightarrow}
\DeclareMathOperator{\La}{\Leftarrow}
\DeclareMathOperator{\Ra}{\Rightarrow}
\DeclareMathOperator{\Lra}{\Leftrightarrow}
\DeclareMathOperator{\Llra}{\Longleftrightarrow}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Imf}{Im}
\DeclareMathOperator{\cont}{cont}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\ev}{ev}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\chard}{char}
\DeclareMathOperator{\CC}{\mathbb{C}}
\DeclareMathOperator{\ZZ}{\mathbb{Z}}
\DeclareMathOperator{\RR}{\mathbb{R}}
\DeclareMathOperator{\NN}{\mathbb{N}}
\DeclareMathOperator{\QQ}{\mathbb{Q}}
\DeclareMathOperator{\PP}{\mathbb{P}}
\DeclareMathOperator{\DD}{\mathbb{D}}
\DeclareMathOperator{\EE}{\mathbb{E}}
\DeclareMathOperator{\codim}{codim}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\Prop}{Prop}
\DeclareMathOperator{\LL}{\mathscr{L}}
\DeclareMathOperator{\KK}{\mathscr{K}}
\DeclareMathOperator{\form}{Form}
\DeclareMathOperator{\Pred}{Pred}
\DeclareMathOperator{\Func}{Func}
\DeclareMathOperator{\Const}{Const}
\DeclareMathOperator{\arity}{arity}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Term}{Term}
\DeclareMathOperator{\sub}{sub}
\DeclareMathOperator{\Sub}{Sub}
\DeclareMathOperator{\Atom}{Atom}
\DeclareMathOperator{\FV}{FV}
\DeclareMathOperator{\Sent}{Sent}
\DeclareMathOperator{\Th}{Th}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\Eq}{Eq}
\DeclareMathOperator{\GA}{\mathfrak{A}}
\DeclareMathOperator{\GB}{\mathfrak{B}}
\DeclareMathOperator{\GC}{\mathfrak{C}}
\DeclareMathOperator{\GD}{\mathfrak{D}}
\DeclareMathOperator{\GN}{\mathfrak{N}}
\DeclareMathOperator{\FF}{\mathcal{F}}
\DeclareMathOperator{\Rho}{\mathcal{P}}

\begin{document}

\newcommand{\resetexlcounters}{%
  \setcounter{exl}{0}%
} 

\newcommand{\resetremarkcounters}{%
  \setcounter{remark}{0}%
} 

\newcommand{\reseconscounters}{%
  \setcounter{cons}{0}%
} 

\newcommand{\resetall}{%
    \resetexlcounters
    \resetremarkcounters
    \reseconscounters%
}

\maketitle 

\newpage

\hypertarget{t1}{Они самые}. 
\tableofcontents

\newpage

\section{Билеты}

\subsection{Вероятностное пространство. Аксиомы вероятности. Дискретное вероятностное пространство. Схема равновозможных исходов.}

\begin{defn}
  $\Omega$ - \textit{пространство элементарных событий} или \textit{множество элементарных исходов}, есть множество, состоящее из $\omega_i$, \textit{элементарных событий}. Нам важно лишь, чтобы это множество было непустым. $\FF\subseteq \Rho(\Omega)$ - некоторая совокупность подмножеств $\Omega$, есть \textit{множество событий}, элементы которого есть $A_i$ - события.
\end{defn}

\begin{defn}
  $\PP$ - вероятность $A\Rightarrow \PP(A)$ - вероятность события $A$.
\end{defn}

\begin{defn}
  Вся же тройка $(\Omega, \FF, \PP)$ называется \hypertarget{n1}{\textcolor{magenta}{\textit{вероятностным пространством}}}.
\end{defn}

Для вероятностей существует несколько аксиом: 

\begin{itemize}
  \item $0\leq \PP(a\leq 1)$ для любого события, 
  \item $\PP(\Omega)=1$, 
  \item для любого счётного набора попарно непересекающихся события $\{A_i\}_{i\in N}\subseteq\FF$ выполнена \textit{счётная аддитивность}:
  \[
      \PP\biggl( \bigsqcup_{n\in N} A_n\biggr)=\sum_{n\in N}\PP(A_n).
  \]
\end{itemize}

Некоторые свойства вероятностей:

\begin{itemize}
  \item $A\subset B \Rightarrow \PP(A)\leq \PP(B)$;
  \item $\PP(A)=1-\PP(A^c)$;
  \item $\forall A, B \Rightarrow \PP(A\cup B)=\PP(A)+\PP(B)-\PP(A\cap B)$;
  \item $\PP(\bigcup_n A_n)\leq \sum_n \PP(A_n)$.
\end{itemize}

Теперь перейдём к некоторым примерам вероятностных пространств:

\begin{exl}

  Пространство $(\Omega, \FF, \PP)$ \hypertarget{n2}{\textcolor{magenta}{\textit{дискретно}}}, если $\Omega$ не более, чем счётно. $\FF=\Rho(\Omega)$, элементы $\{\omega\}$ также считаем событиями.
  \begin{stat}
      Несколько предложений:

      \begin{itemize}
          \item Пусть $\PP$ - вероятность в $(\Omega, \FF, \PP)$. Тогда $\PP(A)=\sum_{\omega\in A}p_\omega$, где $p_\omega=\PP\{\omega\}$. При этом $p_\omega\geq 0$, $\sum_\omega p_\omega = 1$. 
          \item Предположим, что $\{p_\omega\}_{\omega\in\Omega}$ такие, что выполнено последнее предложение предыдущего пункта, тогда $\PP(A)=\sum_{\omega\in A}p_\omega$ - вероятность.
      \end{itemize}
  \end{stat}
\end{exl}

Также, можно упомянуть про \hypertarget{n3}{\textcolor{magenta}{\textit{равновероятные исходы}}}, из названия понятно, что это. Если $\vert \Omega\vert <\infty$ и $p_\omega=p$ для любого $\omega$, тогда $\PP(A)=\frac{\vert A\vert}{\vert \omega \vert}$. \ 



\subsection{Условная вероятность. Формула полной вероятности. Формула Байеса.} 



\begin{defn}
  \hypertarget{n4}{\textcolor{magenta}{\textit{Условная вероятность}}}: $\PP_B(A)=\frac{\PP(A\cap B)}{\PP(B)}$ (при $\PP(B)>0$).
\end{defn}

\begin{stat}
  Для условной вероятности выполнены аксиомы вероятности.
\end{stat}

А  теперь - несколько утверждений, которые касаютсся условной вероятности.

\begin{stat}
  $(B_n)$ - \textit{разбиение} $\Omega$ (дизъюнктный набор, который в объединении даёт всё множество). Тогда для любого $A$, $\PP(A)=\sum_k\PP(B_k)\PP_{B_k}(A)$. 
\end{stat}

\begin{proof}
  \[
      \PP(A)=\PP(A\cap \Omega)=\sum_n \PP(A\cap (\bigcup_n B_n)) = \PP(\bigcup_n (A\cap B_n))=\sum_n \PP(A\cap B_n)=\PP(B_n)\cdot \PP_{B_n}(A).
  \]
\end{proof}

\begin{stat}
  \hypertarget{n5}{\textcolor{magenta}{\textit{Формула Байеса}}}. Пусть мы знаем событие $A$, имеется разбиение $(B_n)$, тогда 
  \[
  \PP_A(B_k)=\frac{\PP(A\cap B_k)}{\PP(A)}=\frac{\PP(B_k)\PP_{B_k}(A)}{\sum_n\PP(B_n)\PP_{B_n}(A)}
  \]
\end{stat}

\begin{proof}
  Из определения условной вероятности, 

  \[
    \PP(B \cap A) = \PP(A \cap B) = \PP_B(A) \PP(B), 
  \]

  Тогда просто применим формулу полной вероятности, и заменим $\PP(A)$ на сумму.
\end{proof}

\subsection{Независимость событий.}

\begin{remark}
  На всякий случай допвопросов, я вставил некоторые рассуждения с лекции.
\end{remark}

Перейдём к \textit{независимости событий}. Начнём рассуждения с двух событий: $A$ и $B$. Если $\PP(B)=\PP_A(B)$, $\PP(A)=\PP_B(A)$, или, что равносильно им обоим $\PP(A\cap B)=\PP(A)\PP(B)$, то события называются \textit{независимыми}.\ 

Пусть теперь имеется не два, а больше событий $\{A_q, \ldots, A_n\}$. Нельзя сказать, что нам хватает попарной независимости для независимости совокупной.

\begin{exl}
    (Пирамида Бернштейна). Рассмотрим тетраедр, у которого стороны покрашены таким образом: белый, синий, красный и флаг России. Рассматриваем события: $A_1$ - на выпавшем основании есть белый цвет, и так далее $A_2$ и $A_3$. Эти события попарно независмы, но не независимы в совокупности.
    \[
        \PP(A_i)=\frac{1}{2}, \: \PP(A_1\cap A_2)=\frac14=\frac12\cdot\frac12=\PP(A_1)\PP(A_2), 
    \]
    но тогда 
    \[
        \PP((A_1\cap A_2)\cap A_3)=\frac14\neq\frac18.
    \]
\end{exl}

Таким образом, нужно ввести корректное определение.

\begin{defn}
    События $A_1, \dots, A_n$ \hypertarget{n7}{\textcolor{magenta}{\textit{независимы}}}, если выполнено:
    \begin{align*}
        \PP(A_i\cap A_j)&=\PP(A_i)\PP(A_j), \: \forall i\neq j,  \\ 
        \PP(A_i\cap A_j\cap A_k)&=\PP(A_i)\PP(A_j)\PP(A_k), \: \forall i\neq j\neq k,  \\
        &\dots \\
        \PP(\bigcup_1^n A_i)&=\prod_1^n \PP(A_i).
    \end{align*}
\end{defn}

\begin{theorem}
    Пусть имеется $T_1, \ldots, T_m$ - разбиение $\{1, \ldots, n\}$, независимые события $A_1, \ldots, A_n$, $\{B_j\}_m$ - комбинация (всякие действия между элементами) событий $\{A_s, s\in T_j\}$. Тогда $\{B_j\}$ - независимы.
\end{theorem}

\begin{proof}
    По индукции.
\end{proof}

\subsection{Дискретные случайные величины. Их распределения. Примеры распределений: Бернулли, биномиальное, геометрическое, распределение Пуассона. Независимость случайных величин.} 

\begin{defn}
  \hypertarget{n8}{\textcolor{magenta}{\textit{Случайная величина}}} - это функция $X:\Omega\rightarrow R$. 
\end{defn}

\begin{exl}
  Число выпавших решек на $n$ бросках.
\end{exl}

Теперь немного о \textit{распределении случайной величины}. Пусть имеется вероятностное пространство и случайная величина $X$. Нас интересует $\{\omega\vert X(\omega)\in B\subseteq \RR \}$, то есть, мы хотим исследовать попадания случайной величины в те или иные зоны на прямой. Такую вероятность можно рассматривать как вероятность от множества $B$, но это слишком сложно, поэтому продолжим на таких двух пунктах:

\begin{itemize}
  \item значения $X$, $X(\Omega)=\{a_1, \ldots\}$, $\{a_k\}$ - значение $X$, 
  \item $A_k=\{\omega\vert X(\omega)=a_k\}$; $p_k=\PP(A_k)$, причём каждая $p_k\geq0$, а их сумма равна единице.
\end{itemize}

Тогда мы можем сделать вывод, что $\PP\{X\in B\}=\sum_{k\vert a_k\in B}p_k$, так как левая часть есть $\PP\{\bigcup_{k\vert a_k\in B}\}$, что равно $\PP\{\bigcup_{k\vert a_k\in B}\{x=a_k\}\}=\sum_{k\vert a_k\in B}\PP\{x=a_k\}$, что уже и равно левой части.\

\begin{defn}
  Таки образом, совокупность последовательностей $\frac{\{a_k\}}{\{p_k\}}$ и называется \hypertarget{n9}{\textcolor{magenta}{\textit{распеределением случайной величины}}}. 
\end{defn}

\begin{exl}
  Приведём примеры распределений:

  \begin{itemize}
      \item \textit{вырожденное}: $X(\omega)=a$ для любого $\omega$.
      \item \textit{распределение Бернулли}: $B(1, p)$, $p\in[0,1]$, причём единица принимается с вероятностью $p$, $0$ - иначе.
      \item \textit{биномиальное}: $B(n, p)$, $p\in[0,1]$, $X\sim B(n, p)$, если принимаются значения от $0$ до $n$, причём $\PP\{X=k\}=\PP_n(k)$ (просто обозначение), и равно $C_n^kp^k(1-p)^{n-k}$.
      \item \textit{геометрическое} $X = 1, 2, \ldots$, $p\in[0,1]$. $P\{X=k\}=(1-p)^{k-1}p$.
      \item \textit{пуассоновское} $X\sim \Rho(\alpha), \alpha>0$, $X=0, 1, \ldots$, $P\{X=k\}=\frac{\alpha^k}{k!}e^{-\alpha}$. 
  \end{itemize}
\end{exl}

Независимость случайных величин.

\begin{defn}
  $X$ и $Y$ - \hypertarget{n10}{\textcolor{magenta}{\textit{независимые случайные величины}}}, если $\forall A, B\subset \RR^1$ события $\{X\in A\}$, $\{Y\in B\}$ независимы.
\end{defn}

Чуть позже бужет критерий независимости, потому что по определению проверить зачастую слишком проблематично. 

\begin{defn}
  $X_1, X_2, \ldots, X_n$ - назависимые случайные величины, если $\forall A_1, \ldots, A_n \subset \RR^1$, $\{X_i\in A_i\}$ независимы.
\end{defn}

\begin{theorem}
  (\hypertarget{n11}{\textcolor{magenta}{\textit{Критерий независимости случайных величин}}}). Предположим, что $X_k$ имеет распределение $(a_{kj})_j$, $(p_{kj})$, $k=1, \ldots, n$. Тогда $X_i$ назависимы тогда и только тогда, когда 
  \[
      \PP\{X_1=a_{1j_1}, X_2=a_{2j_2}, \ldots, X_n=a_{nj_n} = \prod_{k=1}^n p_{kj_k}
  \]
\end{theorem}

\begin{proof}
  Из первого во второе - очевидно. В обратную сторону для начала докажем такой факт: если $A_1, \ldots, A_n \subset \RR^1$, то тогда
  \[
      \PP\{X_1\in A_1, X_2\in A_2, \ldots, X_n \in A_n = \prod_{k=1}^n \PP \{X_k \in A_k\}. 
  \]
  Докажем все факты для двух, обобщается это всё не сложно. 
  \[
      \PP\{X_1\in A_1, X_2\in A_2\}=\PP\biggl( \bigcup_{j, s|a_{1j}\in A_1, a_{2s}\in A_2} \bigcap \{X_1=a_{1j}, X_2=a_{2s} \biggr), 
  \]
  Но вероятность объединения можно заменить на сумму вероятностей: 
  \[
      \sum_{-//-}\PP\{X_1=a_{1j}, X_2=a_{2s}\} = \sum_{-//-}p_{1j}p_{2s} = \biggl( \sum_{j|a_{1j}\in A_1} p_{1j}\biggr)\biggl( \sum_{s|a_{2s}\in A_2} p_{2s}\biggr), 
  \]
  что равно 
  \[
      \PP\{X_1\in A_1\} \PP\{X_2 \in A_2\}. 
  \]
  Это как раз и даёт нам независимость через немного хитрую вещь. Нам же нужна независимость для любого количества элементов, но казалось бы, у нас есть только для всех $X_i$. Однако, в лемме можно заменить некоторые $A_l$ на $\RR^1$, и тогда выражение как раз показывает нам необходимые соотношения на оставшиеся величины. 
\end{proof}

\subsection{Испытания Бернулли. Вероятность для числа успехов в схеме Бернулли. Пуассоновское приближение в схеме Бернулли.}

\begin{defn}
  Рассмотрим последовательность $\varepsilon_k$ - независимых бернуллиевских величин (два исхода), $\varepsilon_k\sim B(1, p)$, 
  \begin{equation*}
      \varepsilon_k=
      \begin{cases}
          1, \: p \\ 
          0, \: q=1-p
      \end{cases}
  \end{equation*}
  $\{\varepsilon_k=1\}$ означает успех в каком-то испытании. То есть, \hypertarget{n12}{\textcolor{magenta}{\textit{испытание Бернулли}}} - последовательность из однотипных испытаний.
\end{defn}

$\nu_n$ - число успехов в $n$ испытаниях., что равно $\sum_{k=1}^n\varepsilon_k$. Покажем, что распределение биномиально. $\nu_n=0, 1, \ldots, n$.

\begin{equation*} 
  \begin{aligned}
      C_n^kp^kq^{n-k} & =^?\PP\{\nu_n=l\}=\PP\{\omega\vert \text{ в цепочке }\varepsilon_1(\omega), \ldots, \varepsilon_n(\omega)\text{ в точности } k \text{единиц}\}= \\ 
      & = \PP\{\sum_1^n\varepsilon_j=k\}=\sum_{\{i_1, \ldots, i_n\}| \text{ в } \bar{i} \: k \text{ единиц }}\PP\{\varepsilon_1= i_1, \ldots, \varepsilon_n=i_n\}= \\ 
      & = \sum_{-//-}p^kq^{n-k}=C_n^k p^kq^{n-k}.
  \end{aligned}
\end{equation*} 

Теперь встаёт вопрос: существуют ли независимые бернуллиевские случайные величины. Пусть $\Omega=\{(i_1, i_2, \ldots, i_n)|i_k=0 \text{ или }1\}$; $|\Omega|=2^k$. $p_{\omega}= p^k(1-p)^{n-k}$ для $\omega=(i_1, \ldots, i_n)$, в которой ровно $k$ единиц. $\sum p_n=1$, $\varepsilon_k(\omega)=\varepsilon_k(i_1, \ldots, i_n)=i_k$ .\

$P_n(k)=\PP\{\nu_n=k\}=C_n^kp^kq^{n-k}$ - можем ли мы как-то упростить это? \\

\begin{theorem}
  $n$ испынаний $\text{Б}$ с веростностями успеха $p=p_n$, $n\cdot p_n\rightarrow_{n\rightarrow \infty} \alpha$, тогда $\forall k\in \NN$ $P_n(k)\rightarrow \pi_k=\frac{\alpha^k}{k!}e^{-\alpha}$. 
\end{theorem}

\begin{proof}
  \begin{equation*}
      \begin{split}
          P_n(k)=\frac{n!}{k!(n-k)!}p^kq^{n-k}=\frac{1}{k!}\frac{n(n-1)\ldots(n-k+1)}{n^k}(np^k)q^{n-k}= \\ 
          = \frac{1}{k!}{(1-\frac{1}{n})\ldots(1-\frac{k-1}{n})}(np)^kq^{n-k}\sim\frac{\alpha^k}{k!}q^{n-k}
      \end{split}
  \end{equation*}

  Если что, $k$ - константа. 

  \begin{equation*}
      \begin{split}
          q^{n-k}=(1-p)^{n-k}=(1-\frac{n p_n}{n})^n(1-\frac{n p_n}{n})^{-k} \\ 
          \sim (1-\frac{n p_n}{n})^n \sim e^{-n p_n} = e^{-\alpha}. 
      \end{split}
  \end{equation*}

  В итоге, $P_n(k)\sim\frac{\alpha^k}{k!}e^{-\alpha}$. 

\end{proof}

А теперь - несколько слов о точности аппроксимации. Оценим $|P_n(k)-\pi_k|$. $\pi_k=\frac{(np)^k}{k!}e^{-np}$. \\

\begin{theorem}
  $\sum_{k=0}^\infty|P_n(k)-\pi_n|\leq 2np^2$.
\end{theorem}

\subsection{Математическое ожидание и его свойства. Формула перемножения математических ожиданий для независимых величин. Примеры вычисления математического ожидания для \ldots} 

\begin{defn}
  Пусть $X$ - случайная величина, тогда \hypertarget{n13}{\textcolor{magenta}{\textit{математическое ожидание}}} - $EX = \sum_{\omega \in \Omega} X(\omega)p_\omega$, если ряд абсолютно сходится в бесконечном случае.
\end{defn}

Свойства: \\ 

\begin{itemize}
  \item Существование математического ожидания эквивалентно существованию математического ожидания $|X|$ (для краткости пишут $E|X|<\infty$). 
  \item Математическое ожидание линейно.
  \item Если $X\geq 0$, то $EX\geq 0$. 
  \item $X\leq Y$, тогда $EX\leq EY$. 
  \item $|EX|\leq E|X|$ (из $-|X|\leq X \leq |X|$). 
\end{itemize}

А вот это уже можно обобщить до неравенства Йенсена: \\

\begin{theorem}
    Если $\varphi$ - выпуклая функция, тогда $\varphi(EX)\leq E\varphi(x)$. 
\end{theorem} \

Однако доказывать мы это не будем, а просто перейдём к следующей теореме: \\

\begin{theorem}
    Пусть $X$ - случайная величина $(a_k); (p_k)$, $f:\RR^\rightarrow \RR^1$. Тогда $Ef(x)=\sum_k f(a_k)p_k$ (существуют или не существуют они одновременно). 
\end{theorem}

\begin{proof}
    Скажем для начала, что $f\geq 0$ (просто возьмём модуль, если что). Тогда $E f(X)=\sum_{\omega \in \Omega} f(X(\omega))p_\omega = \sum_k \biggl( \sum_{\omega|X(\omega) = a_k} f(X(\omega)) p_\omega\biggr) = \sum_k f(a_k) \sum_{\omega | X(\omega)=a_k}p_\omega = \sum_k f(a_k)p_k$. 
\end{proof}

Отсюда есть несколько следствий:

\begin{itemize}
    \item $EX=\sum_k a_k p_k$, $f(x)=x$. 
    \item Если $X$ и $Y$ имеют одинаковые распределения, то $EX=EY$. 
    \item $EX$ - центр масс.
\end{itemize}

\begin{theorem}
    Пусть $\bar{X}$ - случайный вектор; $(\bar{a}_k); (p_k)$; $f:\RR^n \rightarrow \RR^1$. Тогда $Ef(\bar{X}) = \sum_k f(\bar{a}_k)p_k$. 
\end{theorem} \

\begin{theorem}
    Если $X$ и $Y$ независимы, и их математические ожидания существуют, то у их произведения также существует матожидание, притом равно произведению матожиданий.
\end{theorem}

\begin{proof}
    Применим в предыдущей теореме $f: \RR^2 \rightarrow \RR$ по правилу $f(x, y)=xy$ и распишем $E(XY)$. 
\end{proof}

\begin{exl}
  Пусть $X \sim B(n, p)$ имеет биномиальное распределение. Тогда $EX=\sum_0^n k\cdot C_n^kp^k(1-p)^{n-k}=np$. \ 

  К такому выводу можно прийти и другим способом. Мы знаем, что случайная величина $X$ имеет такое же распределение, как сумма бернуллиевских величин, одинаково распределённых: $X=^D\varepsilon_1+\ldots+\varepsilon_n$, $(\varepsilon_k)$ независимы, $\varepsilon_k\sim B(1, p)$. $EX=\sum_1^n E\varepsilon_k=n E\varepsilon_k = np$. 
\end{exl}

\begin{exl}
  Пусть $X\sim \Rho(\alpha)$, тогда 
  \[
      EX = \sum_0^\infty k\frac{\alpha^k}{k!}e^{-\alpha} = e^{-\alpha}\sum_0^\infty \frac{\alpha^k}{(k-1)!} = \alpha e^{-\alpha}\sum_1^\infty \frac{\alpha^{k-1}}{(k-1)!}=\alpha.
  \] 
\end{exl}

\subsection{Дисперсия и ее свойства. Формула сложения дисперсий для независимых величин. Примеры вычисления дисперсии для стандартных распределений \ldots} 

\begin{defn}
  \hypertarget{n14}{\textcolor{magenta}{\textit{Дисперсия}}} - $DX = E[(X-EX)^2]$. Нужно, чтобы $E(X^2)$ было меньше бесконечности, тогда $DX$ определена.
\end{defn}

\begin{remark}
  Дисперсия характеризует меру разброса случайной величины от математического ожидания.
\end{remark}

И рассмотрим её свойства:

\begin{itemize}
  \item Дисперсия неотрицательная.
  \item $D(X+c)=DX$.
  \item $D(X\cdot c)=c^2 DX$.
  \item $DX = E(X^2) - (EX)^2$.
  \item $DX=\sum_k(a_k- EX)^2p_k$, где $(a_k), (p_k)$ - распределение $X$. 
\end{itemize}

\begin{theorem}
  Если $X$, $Y$ - независимые случайные величины, то $D(X+Y)=DX+DY$. 
\end{theorem}

\begin{proof}
  Для начала рассмотрим случай $EX=EY=0$, он достаточно очевиден, а теперь начнём сводить все остальные случаи к этому. Введём $\tilde{X}=X-EX$; $\tilde{Y}=Y-EY$. Тогда $D(X+Y)=D(\tilde{X}+\tilde{Y})=DX+DY$, что и требовалось.
\end{proof}

Рассмотрим теперь несколько примеров дисперсий.

\begin{exl}
  Пусть $X\sim B(n, p)$, тогда $DX=np(1-p)$. 
\end{exl}

\begin{exl}
  Пусть $X\sim \Rho(\alpha)$, тогда $DX = \alpha$. 
\end{exl}

\begin{theorem}  
  (\hypertarget{n15}{\textcolor{magenta}{\textit{Неравенство Маркова}}}). Пусть $X\geq 0$. Тогда $\forall t>0$, $\PP\{X \geq t\}\leq \frac{EX}{t}$.
\end{theorem}

\begin{proof}
  Введём понятие \textit{индикатора}, то есть, функции $\mathbb{I}_A(\omega)$, которяа равна 1, если $\omega \in A$, и 0 иначе (в нашем случае собыние $A$ - $\geq t$). Эта случайная величина имеет Бернуллиевское распределение, 1 с вероятностью $p=\PP(A)$, и 0 с вероятностью $1-p$. Ясно, что левую часть можно записать как $E\mathbb{I}_A$. Посмотрим теперь на $\frac{X}{t}$. Эта вещь не меньше 1 при $\omega \in A$, тогда $\mathbb{I}_A\leq \frac{X}{t}$, а значит, $E \mathbb{I}_A\leq E\biggl(\frac{X}{t}\biggr)=\frac{EX}{t}$. 
\end{proof}

Это неравенство имеет кучу следствий, рассмотрим некоторые из них.

\begin{cons}
  Пусть $f\uparrow$, $f(x)\geq 0$. Тогда $\PP\{X\geq t\}=\PP\{f(X)\geq f(t)\}\leq \frac{Ef(X)}{f(t)}$. 
\end{cons}

\begin{cons}
  Если $E(X^2)\leq \infty$, и $f(x)=x^2$, то, как следствие, получим $\PP\{|X|\geq t\}\leq \frac{E(X^2)}{t^2}$, тогда при $t\rightarrow \infty$ получим более сильную оценку (на месте $X^2$ можно брать ещё большие степени). Также можно рассмотреть $f(x)=e^{ax}$, $a>0$, тогда получим $\PP\{x\geq t\}\leq \frac{E(e^{aX})}{e^{at}}$. 
\end{cons}

\begin{theorem}
  (\hypertarget{n16}{\textcolor{magenta}{\textit{Неравенство Чебышёва}}}). Пусть $X$ - случайная величина, $EX^2<\infty$ ($DX$ определена). Тогда $\forall t >0$, 
  \[
      \PP\{|Y|\geq t\}\leq \frac{E(Y^2)}{t^2}
  \]
\end{theorem}

\begin{proof}
  Из следствия 2, при подстановке $(X-EX)$. 
\end{proof}

\begin{defn}
  \hypertarget{n17}{\textcolor{magenta}{\textit{Моменты}}} - матожидания следующего вида. Пусть $X$ - случайная величина. Мы можем рассмотреть $E(X^n)$, $E(X-EX)^n$, $n\in \NN$, $E|X|^p$, $E|X-EX|^p$, $p\in \RR$. Все эти матожидания называются моментами, первые два называются моментами моментами $n$-го порядка, вторые два - \textit{абсолютными моментами}, моменты с разностями называются \textit{центрированными}.  
\end{defn}

\begin{defn}
  Если случайных величин несколько, то вводятся \textit{смешанные моменты}, моменты вида $E(X^n\cdot Y^m)$, или $E[(X-EX)(Y-EY)]=\text{cov}(X, Y)$ - частный случай, \textit{ковариация}. Можем также через него определить \textit{коэффициент корреляции} - $\rho(X, Y)=\frac{\text{cov}(X, Y)}{\sqrt{DX\cdot DY}}$, который является мерой линейной зависимости между $X$ и $Y$. 
\end{defn}

\subsection{Случайные векторы. Ковариация. Коэффициент корреляции.} 

\begin{defn}
  \hypertarget{n18}{\textcolor{magenta}{\textit{Случайный вектор}}} - вектор, который состоит из случайных величин?
\end{defn}

\begin{defn}
  Если случайных величин несколько, то вводятся \textit{смешанные моменты}, моменты вида $E(X^n\cdot Y^m)$, или $E[(X-EX)(Y-EY)]=\text{cov}(X, Y)$ - частный случай, \hypertarget{n19}{\textcolor{magenta}{\textit{ковариация}}}. Можем также через него определить \hypertarget{n20}{\textcolor{magenta}{\textit{коэффициент корреляции}}} - $\rho(X, Y)=\frac{\text{cov}(X, Y)}{\sqrt{DX\cdot DY}}$, который является мерой линейной зависимости между $X$ и $Y$. 
\end{defn}

\subsection{Закон больших чисел (ЗБЧ). Пример применения ЗБЧ: теорема Вейерштрасса.} 

\begin{theorem}
  (\hypertarget{n21}{\textcolor{magenta}{\textit{ЗБЧ Чебышева}}}). Пусть $\{X_j\}_{j\geq 1}$ - последовательность некорреллированных с. в. с равномерно ограниченными дисперсиями:

  \[
    \sigma^2 : = \sup_j \DD X_j < \infty. 
  \]

  Тогда случайные величины 

  \[
    Z_n:= \frac{\sum_{j=1}^n X_j}{n} - \frac{\sum_{j=1}^n \EE X_j}{n}
  \]

  удовлетворяют соотношению

  \[
    \lim_{n \ra \infty} \PP \{|Z_n|\geq r\} = 0, \: \: \forall r > 0. 
  \]
\end{theorem}

\begin{proof}
  Имеем $\EE Z_n = 0$ и 

  \[
    \DD Z_n = \DD \frac{\sum_{j=1}^n X_j}{n} = \frac{\sum_{j=1}^n \DD X_j}{n^2} \leq \frac{\sigma^2}{n}. 
  \]

  В соответствии с неравенством Чебышева,

  \[
    \PP\{|Z_n|\geq r\} \leq \frac{\DD Z_n}{r^2}\leq \frac{\sigma^2}{nr^2} \ra 0, 
  \]

  при $n \ra \infty$.
\end{proof}

\begin{cons}
  $\{X_j\}_{j\geq 1}$ - последовательность одинаково распределённых независимых с.в. с конечной дисперсией. Пусть $a$ - их общее математическое ожидание. Тогда 

  \[
    \lim_{n \ra \infty} \PP \biggl( \bigg| \frac{\sum_{j=1}^n X_j}{n} - a \bigg| \geq 0 \biggr) = 0, \: \: \forall r > 0. 
  \]

\end{cons}

\begin{theorem}
  (\hypertarget{n22}{\textcolor{magenta}{\textit{ЗБЧ Бернулли}}}). Пусть $S_n$ - число успехова в схеме Бернулли из $n$ испытаний с вероятностью успеха $p$. Тогда 

  \[
    \lim_{n \ra \infty} \PP \biggl( \bigg| \frac{S_n}{n} - p \bigg| \geq 0 \biggr) = 0, \: \: \forall r >0. 
  \]
\end{theorem}

\begin{proof}
  Рассмотрим случайные величины $X_j$, такие, что они принимают значение 1, если был успех на $j$ испытании, и 0 иначе. Тогда $X_j$ независимы, имеют конечную дисперсию $p(1-p)$ и математическое ожидание $p$. Поэтому ЗБЧ Бернулли вытекает из следствия к теореме Чебышева.
\end{proof}

\begin{theorem}
  (\hypertarget{n23}{\textcolor{magenta}{\textit{Теорема Вейерштрасса}}}). Любая непрерывная функция не интервале может быть равномерно приближена полиномами.
\end{theorem}

\begin{proof}
  Итак, пусть $f: [0, 1] \ra \RR^1$ - непрерывная функция. Обозначим

  \[
    w_f(r) := \max_{|s-t|<r} |f(s) - f(t)| 
  \]

  её модуль равномерной непрерывности. Как известно, $\lim_{r \ra 0} w_f(r) = 0$. Пусть $S_n$ - число успехов в схеме Бернулил с вероятностью успеха $p$. Тогда выражение 

  \[
    B_{n, f}(p) := \EE f \biggl(\frac{S_n}{n} \biggr) = \sum_{k=0}^n f \biggl( \frac{k}{n} \biggr) C_n^k p^k (1-p)^{n-k}
  \]

  является полиномом степени $n$ по переменной $p$. Тогда полагая $Z_n = \frac{S_n}{n}$, получим из [строчка из доказательства какой-то хуйни, следствия ЗБЧ, можно написать] для любых $r, n$ 

  \begin{equation*}
    \begin{aligned}
      |B_{n, f}(p)-f(p)| & \leq \max_{|z-a|<r}|f(z)-f(a)|+2\max_{[0, 1]}|f(\cdot) \PP(|\frac{S_n}{n}-p|\geq r)| \leq \\
      & \leq w_f(r)+ 2\max |f(\cdot)| \frac{p(1-p)}{nr^2} \leq \\
      & \leq w_f(r)+\max |f(\cdot)| \frac{1}{2nr^2}. 
    \end{aligned}
  \end{equation*}

  Наконец, выбирая $r=n^{-1/3}$, найдём

  \[
    |B_{n, f}(p)-f(p)|\leq w_f(n^{-1/3})+\max_{[0, 1]}|f(\cdot)| \frac{1}{2n^{1/3}}, 
  \]

  причём эта оценка стремится к нулю с ростом $n$ и не зависит от $p$. 

\end{proof}

\subsection{Локальная и интегральная предельная теорема Муавра в схеме Бернулли.} 

\begin{theorem}
  (\hypertarget{n24}{\textcolor{magenta}{\textit{Локальная теорема Муавра-Лапласа}}}). Пусть $S_n$ - число успехов в схеме Бернулли из $n$ испытаний с вероятностью успеха $p\in(0, 1)$. Тогда для любой последовательности $\varepsilon_n \ra 0$ верно, что 

  \[
    \PP (S_n = k) = \frac{1}{\sqrt{2 \pi n p (1-p)}} \exp \{\frac{-(k - np)^2}{2np(1-p)}\} (1+o(1))
  \]

  равномерно по $k \in [np-\varepsilon_n n^{2/3}, np+\varepsilon_n n^{2/3}]$. 
\end{theorem}

\begin{proof}
  По формуле Стирлинга

  \begin{equation*}
    \begin{aligned}
      \PP(S_n = k) & = C_n^k p^k (1-p)^{n-k} = \frac{n!}{k!(n-k)!}p^k (1-p)^{n-k} \sim \\ 
      & \sim \frac{\sqrt{2 \pi n}}{\sqrt{2\pi k}\sqrt{2 \pi (n-k)}}\frac{n^n e^k e^{n-k}}{e^n k^k (n-k)^{n-k}}p^k (1-p)^{n-k} \sim \\ 
      & \sim \frac{1}{\sqrt{2 \pi p (1-p)n}} \frac{n^n}{k^k (n-k)^{n-k}} p^k (1-p)^{n-k} = \\ 
      & = \frac{1}{\sqrt{1 \pi p (1-p) n }} \frac{(np)^k}{k^k} \frac{[n(1-p)]^{n-k}}{(n-k)^{n-k}}. 
    \end{aligned}
  \end{equation*}

  Определим параметр $v = v(n, k)$ соотношением $k = np+v$. Тогда имеем $n-k = n(1-p) - v$, причём $v = o(n^{2/3})$. Анализируя логарифмы, получим, что 

  \begin{equation*}
    \begin{aligned}
      \ln \biggl( \frac{k^k}{(np)^k} \biggr) & = k \ln \biggl( 1+ \frac{v}{np} \biggr) = (np+v) \biggl( \frac{v}{np} - \frac{v^2}{2(np)^2} + o \biggl( \frac{v^3}{n^3} \biggr) \biggr) = \\ 
      & = v+ \frac{v^2}{2np} + 0(1), 
    \end{aligned}
  \end{equation*}

  и аналогично,

  \[
    \ln \biggl( \frac{(n-k)^{n-k}}{(n(1-p))^{n-k}} = -v+ \frac{v^2}{2n(1-p)}+ o(1). 
  \]

  Складывая оценки логарифмов, получим (старшие члены сокращаются!) 

  \begin{equation*}
    \begin{aligned}
      \ln \biggl( \frac{(np)^k}{k^k} \frac{(n(1-p))^{n-k}}{(n-k)^{n-k}} & = - \frac{v^2}{2np} - \frac{v^2}{2n(1-p)} + o(1) = \\ 
      & = \frac{-v^2}{2np(1-p)} + o(1). 
    \end{aligned}
  \end{equation*}

  по определению, $\frac{v^2}{2np(1-p)} = \frac{(k - np)^2}{2np(1-p)}$, так что теорема доказана.
\end{proof}

\begin{theorem}
  (\hypertarget{n25}{\textcolor{magenta}{\textit{Интегральная теорема Муавра-Лапласа}}}). Пусть $S_n$ - число успехов в схеме Бернулли из $n$ испытаний с вероятностью успеха $p\in (0, 1)$. Положим $Z_n = \frac{S_n - np}{\sqrt{p(1-p)n}}$. Тогда для любых вещественных $a<b$ и $n \ra \infty$ верно

  \[
    \lim_{n \ra \infty} \PP \{a \leq Z_n \leq b\} = \frac{1}{\sqrt{2\pi }} \int_a^b e^{-u^2/2}du. 
  \]
\end{theorem}

\begin{proof}
  Утверждение теоремы получается простым суммированием асимптотик из локальной теоремы.
\end{proof}

\subsection{Производящие функции. Связь с математическим ожиданием и дисперсией. Производящая функция суммы независимых величин. Производящая функция суммы случайного числа независимых одинаково распределенных величин.} 

\begin{defn}
  \hypertarget{n26}{\textcolor{magenta}{\textit{Производящая функция}}}: 
   $X \in Z_{+}; p_k = \mathbb{P}\{X = k\}; \varphi(z) = E(z^x) = \Sigma_{k=0}^{\infty}{p_k z^k}, |z| < 1$
\end{defn}   
   
Свойства:

\begin{itemize}
     \item Если $X,Y$ - сл.нез.величины, то $\varphi_{X+Y}(z) = \varphi_X(z) \varphi_Y(z)$, так как $\varphi_{X+Y}(z) = E(z^{X+Y})=E(z^X z^Y)=E(z^X) E(z^Y)=\varphi_X(z)\varphi_Y(z)$.
     
     \item (Следствие) Если $X_1,X_2,...X_n$ - н.о.р. сл.величины, то $\varphi_{S_n}(z) = [\varphi(z)]^n$, где $S_n = X_1 + X_2 + ... + X_n, \varphi$ - производящая функция $X_1$.
     
     \item $\varphi^{'}(1) = EX, \varphi^{''}(1) = E[X(X-1)]$, откуда $DX = \varphi^{''}(1) + \varphi^{'}(1) - [\varphi^{'}(1)]^2$.
     
     \begin{proof}
         $\lim\frac{\varphi(1)-\varphi(t)}{1-t}=\Sigma_{k=0}^{\infty}\frac{1-t^k}{1-t}p_k=\Sigma_{k=0}^{\infty}p_k k t_k^{k-1},t \leq t_k \leq 1, \Sigma_{k=1}^{\infty}p_k k t^{k-1} \leq \Sigma_{k=1}^{\infty}p_k k t_k^{k-1} \leq \Sigma_{k=1}^{\infty}p_k k = EX$, значит $\varphi^{'}(1) = EX$, повторив аналогичное рассуждение еще раз, получим соотношение на $\varphi^{''}(1)$.
     \end{proof}
     
     \item Пусть $\tau$ и $(X_k)$ - н.о.р.сл.величины, $S_n = X_1 + X_2 + ... + X_n, U = S_{\tau}, \varphi$ - общая производящая функция, тогда $\varphi_{U}(z) = \varphi_{\tau}(\varphi(z))$
     
     \begin{proof}
     \begin{equation*}
     \begin{aligned}
        \varphi_U(z) &= \Sigma_{k=0}^{\infty}\mathbb P \{U = k\} z^k = \Sigma_{k=0}^{\infty}[\Sigma_{n=0}^{\infty}\mathbb{P}\{U=k|\tau=n\}]z^k &= \\
        &= \Sigma_{k=0}^{\infty}[\Sigma_{n=0}^{\infty}\mathbb{P}\{\tau=n|S_n = k\}]z^k=\Sigma_{k=0}^{\infty}[\Sigma_{n=0}^{\infty}\mathbb{P}\{\tau=n\}\mathbb{P}\{S_n = 
            k\}]z^k &= \\
        &= \Sigma_{n=0}^{\infty}[\Sigma_{k=0}^{\infty}\mathbb{P}\{\tau=n\}\mathbb{P}\{S_n = k\}z^k]=\Sigma_{n=0}^{\infty}\mathbb{P}\{\tau=n\}[\Sigma_{k=0}^{\infty}\mathbb{P}\{S_n = k\}z^k] &= \\
        &= \Sigma_{n=0}^{\infty}\mathbb{P}\{\tau = n\}\varphi_{S_n}(z)=\Sigma_{n=0}^{\infty}\PP\{\tau=n\}[\varphi(z)]^n=\varphi_{\tau}(\varphi(z)).
     \end{aligned}    
     \end{equation*}
     \end{proof}
\end{itemize}

\subsection{Ветвящийся процесс. Определение. Вероятность вырождения. Производящая функция ветвящегося процесса как итерация производящей функции числа непосредственных \ldots} 

(\hypertarget{n27}{\textcolor{magenta}{\textit{Описание ветявщегося процесса}}}). Мы последовательно строим дерево. В 0 уровне 1 вершина, из которой появляются потомки, которые составляют 1 уровень, из каждого появляются потомки, составляющие 2 уровень итд. $M_n$ - число вершин на $n$-ом уровне, $X$ - общая случайная величина количества потомков вершины, $\varphi$ - производящая функция $X$, $\varphi_n$ - производящая функция $M_n$. Заметим, что $M_{n+1} = \Sigma_{i=1}^{M_n}X_{n,i}$, где $X_{n,i}$ - количество потомков $i$-ой вершины на $n$-ом уровне. По последнему пункту 11 билета из этого следует $\varphi_{n+1}=\varphi_n(\varphi(z))$, таким образом $\varphi_n=\varphi^{n0}$, где $\varphi^{n0}$ - $n$-ая композиция $\varphi$. 

$q_n=\mathbb P \{M_n=0\}, q = \mathbb P \{\bigcup\{M_n=0\}\}. \{M_n=0\} \subset \{M_{n+1}=0\} \Rightarrow q_n \uparrow q.$ \\
    
\begin{theorem}
  $q$ совпадает с наименьшим корнем уравнения $\varphi(t) = t$.
\end{theorem}

\begin{proof}
  $q_n=\mathbb P \{M_n=0\} = \varphi_n(0) = \varphi^{n0}(0). q_{n+1} = \varphi(q_n) \Rightarrow q = \varphi(q)$, так как $\varphi$ -  непрерывная. То есть $q$ - корень $\varphi(t)=t$. Пусть $t^{*}$ - наименьший корень $\varphi(t) = t, q_0 = 0 \leq t^{*},$ если $q_n \leq t^{*}$, то $q_{n+1} = \varphi(q_n) \leq \varphi(t^{*}) = t^{*}$, так как $\varphi$ - монотонна, а значит $q \leq t^{*} \Rightarrow q = t^{*}$.
\end{proof}

В последующих рассуждениях мы будем использовать, что $\varphi(1)=1,\varphi(0)=p_0$ и $\varphi$ - неубывающая выпуклая функция \\ 
    
\begin{theorem}
  (\hypertarget{n28}{\textcolor{magenta}{\textit{Критерий невырожденности}}}).
    
    Следующие условия равносильны:
    \begin{itemize}
        \item $q < 1$ 
        \item $EX > 1$ или $\mathbb P \{X = 1\} = 1$
    \end{itemize}
  \end{theorem}

\begin{proof} \

        \textcolor{magenta}{($2 \Rightarrow$ 1)} 2 случай очевиден; если $EX>1,$ то $\varphi^{'}(1) > 1,$ а значит $\exists \delta$, такое что $\varphi(t) < t, \forall 1 - \delta < t < 1 \Rightarrow q = t^{*} < 1.$
        
        \textcolor{magenta}{($2 \Leftarrow$ 1)} Пусть ни то ни другое неверно, тогда $EX \leq 1 \Rightarrow \varphi^{'}(1) \leq 1 \Rightarrow$ либо $\varphi(t) > t \forall t < 1$, тогда $q = t^{*} = 1$, либо $\varphi(t) = t \forall t \in [a;1]$ и $\varphi(t) > t \forall t \in [0;a)$, тогда $\varphi^{'}(1) = 1, \varphi^{''}(1) = 0,$ а значит $EX = 1, DX = 0 \Rightarrow X = 1$, то есть $\mathbb P \{X = 1\} = 1$.
\end{proof}

\begin{defn} 
  \ 
    Если $EX < 1$, то процесс подкритический, \
    
    Если $EX = 1$, то процесс критический, \
    
    Если $EX > 1$, то процесс надкритический.
\end{defn}

\subsection{Цепи Маркова со счетным множеством состояний. Основные определения. Вероятность конкретной траектории цепи. Вероятности перехода за n шагов. Инвариантные (стационарные) и предельные распределения цепи. Предельное распределение как инвариантное. Примеры несуществования (простое симметричное случайное блуждание).}

\begin{defn}
Пусть $(\Omega, F, \mathbb{P})$ - вероятностное пространство. Последовательность случайных величин $(X_n)_{n=0, 1...}$ (с не более чем счётным множеством состояний $L$) называется \hypertarget{n29}{\textcolor{magenta}{\textit{цепью Маркова}}}, если $\mathbb{P}(X_{n+1}=l_{i_{n+1}} | X_n=l_{i_n}, X_{n-1}=l_{i_{n-1}}, ... X_0=l_{i_0})= \mathbb{P}(X_{n+1}=l_{i_{n+1}} | X_n=l_{i_n})$ для любых $l_{i_0}, ... l_{i_{n+1}} \in L$, т.е., неформально говоря, если каждая случайная величина зависит только от предыдущей.
\end{defn} 

Далее везде мы состояние цепи Маркова будем просто обозначать числами, писать $i$ вместо $l_i$.

\begin{defn}
Если $\mathbb{P}(X_{n+1}=j | X_n=i)$ не зависит от $n$, то цепь Маркова называется \hypertarget{n30}{\textcolor{magenta}{\textit{однородной}}}. Отныне считаем, что все рассматриваемые цепи однородны.
\end{defn}

\begin{defn}
  \hypertarget{n31}{\textcolor{magenta}{\textit{Начальное распределение}}} $\pi_0(x)=\mathbb{P}(X_0=x)$. Можно записать в виде вектора: $\overline{\pi_0}=(\pi_0(x_i))_{i=0, 1...}$
\end{defn}

\begin{defn}
  \hypertarget{n32}{\textcolor{magenta}{\textit{Вероятность перехода}}} из $i$ в $j$ - $p_{i, j}=\mathbb{P}(X_{n+1}=j | X_n=i)$. \textit{матрица перехода} $P=(p_{i, j})_{i, j=0, 1...}$. 
\end{defn}

\begin{theorem}
  $\mathbb{P}(X_0=x_0, ...X_n=x_n)=\pi_0(x_0)p_{x_0, x_1}...p_{x_{n-1}, x_n}$
\end{theorem}

\begin{proof}
Индукция по $n$. База $n=0$ очевидна. Переход: $p_{x_{n-1}, x_n}=\mathbb{P}(X_{n}=X_n | X_{n-1}=x_{n-1})=\mathbb{P}(X_{n}=X_n | X_{n-1}=x_{n-1}, ... X_0=x_0)= \frac{\mathbb{P} (X_n=x_n, X_{n-1}=x_{n-1}, ... X_0=x_0)}{\mathbb{P}(X_{n-1}=x_{n-1}, ... X_0=x_0)}$.
\end{proof}

\begin{defn}
Определим \textit{вероятности перехода за $n$ шагов:} $p_{i, j}(n)=\mathbb{P}(X_{t+n}=j | X_t=i)$ Им соответствует матрица $P^{(n)}$. 
\end{defn}

Корректность данного определения интуитивно очевидна из однородности цепи Маркова, но докажем её строго:

\begin{stat}
  Это определение корректно:
\end{stat}

\begin{proof}
\begin{equation*}
  \begin{aligned}
    & \mathbb{P}(X_{t+n}=j | X_t=i) =\frac{\mathbb{P}(X_{t+n}=j, X_t=i)}{\mathbb{P}(X_t=i)}= \\ 
    & = \frac{\sum_{(i_1, ...i_{n-1})}\mathbb{P}(X_t=i, X_{t+1}=i_1, ...X_{t+n-1}=i_{n-1}, X_{t+n}=j)}{\mathbb{P}(X_t=i)} = \\ 
    & = \frac{\sum_{\ldots}\mathbb{P}(X_t=i)p_{i, i_1}p_{i_1, i_2}...p_{i_{n-1}, j}}{\mathbb{P}(X_t=i)}=\Const, 
  \end{aligned}
\end{equation*}
т.е. не зависит от $t$
\end{proof}


\begin{theorem} \
  \begin{enumerate}
    \item $p_{i, j}(n+m)=\sum_{k}p_{i, k}(n)p_{k, j}(m)$
    \item $P^{(n+m)}=P^{(n)}P^{(m)}$
    \item $P^{(n)}=P^n$
  \end{enumerate}
\end{theorem}

\begin{proof}
Докажем первый пункт, из которого сразу будут следовать остальные. $p_{i, j}(n+m)=\mathbb{P}(X_{n+m}=j | X_0=i)=\sum_k \mathbb{P}(X_n=k | X_0=i) \mathbb{P}(X_{n+m}=i | X_n=k, X_0=i)=\sum_{k}p_{i, k}(n)\mathbb{P}(X_{n+m}=i | X_n=k)=\sum_{k}p_{i, k}(n)p_{k, j}(m)$
\end{proof}

\begin{defn}
Распределение $\pi$ называется \hypertarget{n33}{\textcolor{magenta}{\textit{инвариантным (стационарным)}}} для переходной матрицы $P$, если $\pi \cdot P = \pi$
\end{defn}

\begin{cons}
$\pi^n \cdot P = \pi$
\end{cons}

\begin{stat}
У простого симметричного случайного блуждания нет стационарного распределения.
\end{stat}

\begin{proof}
Если бы стационарное распределение $\overline{\pi}$ существовало, то оно удовлетворяло бы функциональному уравнению $\pi(n)=\frac{\pi(n-1)+\pi(n+1)}{2}$, откуда $\pi(n+1)-\pi(n)=\pi(n)-\pi(n-1)$, и $\pi(n)=cn+ \pi(0)$. Но такое решение не удовлетворяет соотношению $\sum_{n \in \mathbb{Z}} \pi(n)=1$, противоречие.
\end{proof}

\begin{defn}
Предположим, что последовательность $(\overline{p(n)})=(\overline{\pi}P^n)_{n=0, 1...}$ сходится к некоторому распределению $\tau$ по метрике из теоремы Маркова (сумма модулей разностей координат) (для случая конечного пространства значений это равносильно покоординатной сходимости). Тогда $\tau$ называется \hypertarget{n34}{\textcolor{magenta}{\textit{предельным распределением}}} для начального состояния. $\pi$.
\end{defn}

\begin{theorem} \
  \begin{enumerate}
    \item $\tau$ - действительно распределение.
    \item $\tau$ стационарно.
  \end{enumerate}
\end{theorem}
  
\begin{proof}
  \begin{enumerate}
      \item $1-\epsilon< \sum_i |\tau_i-p_i(n)| - \sum_i p_i(n) \leq \sum_i \tau_i \leq \sum_i |\tau_i-p_i(n)| + \sum_i p_i(n) < \epsilon + 1$ для любого $\epsilon>0$ и $n> N(\epsilon)$. Неотрицательность же $\tau_i$ очевидна (предел неотрицательных величин неотрицателен).
      \item $d(\overline{\tau}P, \overline{\tau}) \leq d(\overline{\tau}P, \overline{p(n+1)})+d(\overline{p(n+1)}, \overline{p(n)})+d(\overline{p(n)}, \overline{\tau}) < 3\epsilon$ при $n>N(\epsilon)$. Здесь неочевидным является факт, что $d(\overline{x}P, \overline{y}P) \leq d(\overline{x}, \overline{y})$. Докажем его по аналогии с рассуждениями из теоремы Маркова: $d(\overline{x}P, \overline{y}P)=\sum_j|\underbrace{\sum_{i}x_ip_{i, j} - \sum_{i}y_ip_{i, j}}_{A_j}|=\sum_{j \in J_+} \sum_{i}(x_i-y_i)p_{i, j}-\sum_{j \in J_-} \sum_{i}(x_i-y_i)p_{i, j} \leq \sum_j \sum_{i}|x_i-y_i|p_{i, j} = \sum_i |x_i-y_i| \sum_{j} p_{i, j}=d(\overline{x}, \overline{y})$, что и требовалось (мы поменяли в выкладках знаки суммирования, потому что ряд сходится абсолютно).
  \end{enumerate}
\end{proof}

\subsection{Асимптотическое поведение вероятностей перехода – предельная теорема Маркова для конечной цепи с положительными вероятностями перехода и ее непосредственное обобщение.} 

\begin{theorem}
  (\hypertarget{n35}{\textcolor{magenta}{\textit{Теорема Маркова о финальных вероятностях}}}). Пусть $(X_n)$ - цепь Маркова, у которой $m<\infty$ состояний. Предположим, что $\forall i, j$ верно неравенство  $p_{i, j} \geq \delta>0$. Тогда существет единственное стационарное распределение $\overline{\pi}$, причём $\max_{i, j} |p_{i, j}(n)-\pi_j|  \leq C(\max\{0, 1-2\delta\})^n$, где $C>0$ - константа.
\end{theorem}

\begin{proof}
  Мы будем применять теорему о сжимающем отображении. Для этого определим на множестве $H=\{\overline{x} \in \RR^m | x_i \geq 0, \sum x_i=1\}$ метрику $d(\overline{x}, \overline{y})=\sum_{i=1}^m |x_i-y_i|$. Полученное метрическое пространство будет полным, так как метрика $d$ эквивалентна стандартной евклидовой метрике пространства $\RR^m$, которое полно. Также определим отображение $T\overline{x} := \overline{x}P$. Проверим, что оно сжимающее. $d(T\overline{x}, T\overline{y})=\sum_{j=1}^m|\underbrace{\sum_{i}x_ip_{i, j} - \sum_{i}y_ip_{i, j}}_{A_j}|=\sum_{j \in J_+} \sum_{i}(x_i-y_i)p_{i, j}-\sum_{j \in J_-} \sum_{i}(x_i-y_i)p_{i, j}$ $=\sum_{i}(x_i-y_i)(\sum_{j \in J_+}p_{i, j}- \sum_{j \in J_-}p_{i, j})$ (Здесь $J_+=\{s | A_s \geq 0\}$, $J_-=\{s | A_s < 0\}$). Возможны три случая:
  \begin{itemize}
      \item $J_-=\emptyset$. Тогда $d(T\overline(x), T\overline{y})=\sum_{i}(x_i-y_i) \sum_{j}p_{i, j}=0 \leq C(1-\delta)^n$
      \item $J_+=\emptyset$ - аналогичен предыдущему.
      \item В $J_-$ и $J_+$ есть хотя бы одно по одному состоянию. Тогда легко понять, что $ \delta \leq \sum_{j \in J_+} p_{i, j} \leq 1-\delta$ и аналогично с $J_-$, и $d(T\overline{x}, T\overline{y})=\sum_{i}(x_i-y_i)(\sum_{j \in J_+}p_{i, j}- \sum_{j \in J_-}p_{i, j}) \leq \sum_{i}|(x_i-y_i)|\cdot |(\sum_{j \in J_+}p_{i, j}- \sum_{j \in J_-}p_{i, j})| \leq (1-2\delta)\sum_{i}|x_i-y_i| =(1-2\delta)d(\overline{x}, \overline{y})$. (заметим, что если этот случай реализовался, то $\delta \leq \frac{1}{2}$)
  \end{itemize}
  
  Мы убедились, что отображение сжимающее. Тогда выполнены все условия теоремы о сжимающем отображении, и в нашем метрическом пространстве существует единственная неподвижная точка $\overline{\pi}$. По индукции получаем, что $d(T^n\overline{x}, \overline{\pi}) \leq (1-2\delta)^nd(\overline{x}, \overline{\pi}) \leq 2(1-2\delta)^n$, так как $d(\overline{x}, \overline{y})=\sum_{i=0}^m|x_i-y_i| \leq \sum_{i=0}^m|x_i|+|y_i|=2$.
  Зафиксируем теперь произвольное $i$ и рассмотрим вектор $\overline{x}=(p_{i, j})$. Получим, что $\max_{j} |p_{i, j}(n)-\pi_j| \leq  \sum_j |p_{i, j}(n)-\pi_j| \leq 2(1-2\delta)^n$ - равномерная оценка по $i$.
 \end{proof}
  
\begin{cons}
  Пусть $(X_n)$ - цепь Маркова, у которой $m<\infty$ состояний. Предположим, что для некоторого $N>0$ и $\forall i, j$ верно неравенство  $p_{i, j}(N) \geq \delta>0$. Тогда существет единственное стационарное распределение $\overline{\pi}$, причём $\max_{i, j} |p_{i, j}(n)-\pi_j|  \leq C\rho^n$, где $C>0$ и $0\leq \rho <1$ - некоторые константы.
\end{cons}

\begin{proof}
Будем использовать обозначения из теоремы Маркова и рассмотрим отображение $U=T^N$. По теореме Маркова оно сжимающее, существует единтвенное стационарное распределение $\pi$ и $d(U^{kN}\overline{x}, \overline{\pi}) \leq 2(\max\{0, 1-2\delta\})^k$. Так как всегда верно неравенство $d(T\overline{x}, T\overline{y}) \leq d(\overline{x}, \overline{y})$, то $\sup_{\overline{x}, \overline{y}} d(T\overline{x}, T\overline{y}) \leq \sup_{\overline{x}, \overline{y}} d(\overline{x}, \overline{y})$. Обозначим через $\Delta_n=\sup_{\overline{x}, \overline{y}} d(T^n\overline{x}, T^n\overline{y})$. Из вышесказанного следуют следующие свойства:
\begin{enumerate}
    \item $(\Delta_n)$  нестрого убывает.
    \item $\Delta_{kN} \leq 2(\max\{0, 1-2\delta)\}^k$. 
\end{enumerate}
Тогда легко показать, что эта последовательность убывает к нулю экспоненциально быстро всегда, для этого достаточно взять $\rho=\max\{0, 1-2\delta\}^{\frac{1}{N}}C=\frac{2}{\rho^{N-1}}$, тогда $\Delta_{kN+r} \leq \Delta_{kN} \leq 2(\max\{0, 1-2\delta\})^k=2\rho^{kN} \leq \frac{2}{\rho^{N-1}}\rho^{kN+r}=C\rho^{kN+r}$. В итоге получили оценку $d(T^n\overline{x}, T^n\overline{y}) \leq C\rho^n$, откуда требуемое неравенство выводится так же, как в оригинальной теореме. Для полного доказательства осталось лишь проверить, что $\overline{\pi}$ - стационарное распределение для $T$. Но $d(T\overline{\pi}, \overline{\pi}) = d(T(T^{Nk}\overline{\pi}), T^{Nk}\overline{\pi})=d(T^{Nk}(T\overline{\pi}), T^{Nk}\overline{\pi}) \leq \Delta_{Nk} \rightarrow 0$, и значит, $d(T\overline{\pi}, \overline{\pi})=0$.
\end{proof}

\subsection{Классификация состояний: существенные, несущественные состояния. Эргодические классы существенных состояний. Период состояния \ldots}

\begin{defn}
  Состояние $j$ называется \hypertarget{n36}{\textcolor{magenta}{\textit{достижимым}}} из $i$, если для некоторого натурального $n$ $p_{i, j}(n)>0$ (в таком случае мы буде писать $i \rightarrow j$)
\end{defn}

\begin{defn}
  Состояния $i$ и $j$ \hypertarget{n37}{\textcolor{magenta}{\textit{сообщаются}}}, если они достижимы друг из друга (обозначим это через $i \leftrightarrow j$)
\end{defn}

\begin{defn}
  Состояние $i$ \textit{существенно}, если оно сообщается с любым достижимым из него состоянием (т.е. $\forall j$ из $i \rightarrow j$ следует, что $j \rightarrow i$), и \textit{несущественно} в противном случае.
\end{defn}

\begin{stat}
  $\leftrightarrow$ - отношение эквивалентности на множестве существенных состояний $S$.
\end{stat}

\begin{defn}
  Классы эквивалентности на $S$ по $\leftrightarrow$ называются \hypertarget{n38}{\textcolor{magenta}{\textit{эргодическими классами}}}.
\end{defn}

\begin{defn}
  Для каждого состояния $i$ рассмотрим множество $L_i=\{n>0 | p_{i, i}(n)>0\}$. Если $L_i \neq \emptyset$, то можно определить \hypertarget{n39}{\textcolor{magenta}{\textit{период состояния}}} $i$ как $d(i)=\gcd(L_i)$.
\end{defn}

\begin{stat}
  Если $i \leftrightarrow j$, то $d(i)=d(j)$.
\end{stat}

\begin{proof}
  Из существенности этих состояний следует, что $\exists k, l$ такие, что $p_{i, j}(k)>0$ и $p_{j, i}(l)>0$. Тогда для $n=d(i) \in L_i $ $p_{j, j}(l+n+k) \geq p_{j, i}(l)p_{i, i}(n)p_{i, j}(k)>0$ и $p_{j, j}(l+k) \geq p_{j, i}(l)p_{i, j}(k)>0$, откуда получаем, что числа $n+k+l$ и $k+l$ лежат в $L_j$. Тогда $d(j) | n+k+l$, $d(j) | k+l$ $\implies d(j) | n=d(i)$. Аналогично, $d(i) | d(j)$.
\end{proof}

\begin{defn}
  Одинаковый период состояний в одном эргодическом классе называется \hypertarget{n40}{\textcolor{magenta}{\textit{периодом класса}}}.
\end{defn}

\begin{theorem}
  Пусть $E$ - эргодический класс с периодом $d>1$. Тогда $E=\bigsqcup_{j=0}^{d-1} C_j$, при этом если $x \in C_k$, и $p_{x, y}>0$, то $y \in C_{k+1 \mod d}$. Более того, это разбиение единственно с точностью до циклического сдвига индексов.
\end{theorem}

\begin{proof}
  Выберем произвольное состояние $i_0$ и определим $C_k=\{j | \exists n p_{i, j}(k+nd)>0\}$. Понятно, что $E= \bigcup_{k=0}^{d-1}C_k$. \ 
  
  Сначала докажем, что эти классы попарно дизъюнктны. Предположим противное: существуют состояние $x$ и различные числа $0 \leq k_1, k_2 <d$ такие, что $p_{x_0, x}(n_1d+k_1)>0$, $p_{x_0, x}(n_2d+k_2)>0$. Так как $x, x_0$ лежат в одном эргодическом классе, то для некоторого $r$ верно $p_{x, x_0}(r)>0$. Тогда из $x_0$ в себя же можно добраться как за $n_1d+k_1+r$ шаг, так за $n_2d+k_2+r$ шаг, а тогда $d | n_1d+k_1+r$, $d | n_2d+k_2+r$ $\implies d | k_1-k_2$, что невозможно. \
  
  Осталось доказать, что другого такого разбиения нет. Действительно, пусть $E=\bigsqcup_{k=0}^{d-1} D_k$ (переходы здесь так же из $i$-го множества в $i+1$-ое), и $D_0 \cap C_0 \supset i$ (так как мы можем циклически сдвигать индексы). Если для некоторого $m$ теперь найдётся элемент $j$ такой, что $j \in C_m$, $j \notin D_m$ (другой случай аналогичен), то рассмотрим путь из $i$ в $j$. По индукции легко показывается, что его $t$-ое звено (нумеруем с нуля) лежит и в $C_t$, и в $D_t$, противоречие.
\end{proof}

\begin{defn}
  Эти $C_i$ называются \hypertarget{n41}{\textcolor{magenta}{\textit{циклическими подклассами}}} данного эргодического класса.
\end{defn}

\subsection{Возвратные и невозвратные состояния, критерий возвратности. Возвратность простого случайного блуждания в $\ZZ^d$ (теорема Пойа). Простое случайное блуждание на $\ZZ$ \ldots}

Для данного состояния $j$ определим $f_{j, j}(k)=\mathbb{P}(\underbrace{X_k=j, X_{k-1} \neq j, ... X_1 \neq j}_{A_k} | X_0=j)$ - вероятность впервые вернуться обратно на $k$-ом шаге. Так как события $(A_k)$ попарно дизъюнктны, то $\mathbb{P}(\bigcup_k A_k | X_0=j)=\sum_{k=1}^{\infty} f_{j, j}(k) = f_j \leq 1$ - вероятность хотя бы раз вернуться обратно. Также пусть $p_{j, j}(n)$ - вероятность перехода из $j$ в $j$ за $n$ шагов.

\begin{defn}
  Если $f_j=1$, то состояние $j$ называется \hypertarget{n42}{\textcolor{magenta}{\textit{возвратным}}}.
\end{defn}

\begin{lemma}
  $p_{j, j}(n)= \sum_{k=1}^n f_{j, j}(k)p_{j, j}(n-k)$.
\end{lemma}

\begin{proof}
  \begin{equation*}
    \begin{aligned}
      p_{j, j}(n)& =\mathbb{P} (X_n=j | X_0=j) = \sum_{k-1}^n \mathbb{P}((X_n=j) \cap A_k | X_0=j) = \\ 
      & = \sum_{k=1}^n \mathbb{P}(A_k | X_0=j) \mathbb{P}(X_n=j | X_k=j, X_{k-1} \neq j, ... X_1 \neq j, X_0=j)=\\ 
      & = \sum_{k=1}^n f_{j, j}(k)\mathbb{P}(X_n=j | X_k=j)=\sum_{k=1}^n f_{j, j}(k)p_{j, j}(n-k)
    \end{aligned}
  \end{equation*}
\end{proof}

Доопределим $f_{j, j}(0)=0$, $p_{j, j}(0)=1$, и рассмотрим производящие функции $F$ и $G$ последовательностей $(f_{j, j}(n))$ и $(p_{j, j}(n))$ соответственно. Они определены при $|t|<1$. Из утверждения выше следует, что $G(t)-1=F(t)G(t) \iff G(t)=\frac{1}{1-F(t)}$. \\

\begin{lemma}
  Последовательность $(a_k)_{k=0}^{\infty}$ неотрицательна, ограничена сверху константой $C$ и имеет производящую функцию $A(t)$. Тогда $\lim_{t \nearrow 1} A(t)=A(1) = \sum_{k=0}^{\infty} a_k$.
\end{lemma}

\begin{proof}
  Во-первых, $A(t) \leq A(1)$ $\implies \limsup_{t \nearrow 1} A(t) \leq A(1)$. Во-вторых, для любого натурального $N$ верно, что $A(t) \geq \sum_{k=0}^{N} a_kt^k$ $\implies \liminf_{t \nearrow 1} A(t) \geq \liminf_{t \nearrow 1} (\sum_{k=0}^{N} a_kt^k)= \sum_{k=0}^{N} a_k$ $\implies \liminf_{t \nearrow 1} A(t) \geq A(1)$. Значит, $\lim_{t \nearrow 1} A(1)=A(1)$.
\end{proof}

Из леммы следует, что $\sum_{k=0}^{\infty} p_{j, j}(k)=G(1)=\frac{1}{1-F(1)}=\frac{1}{1-f_j}$. В итоге получаем следующий критерий возвратности состояния: \\

\begin{theorem}
  Состояние $j$ возвратно $\iff $ ряд $\sum_{k=0}^{\infty} p_{j, j}(k)$ расходится.
\end{theorem}

\begin{cons}
  Если $i$ возвратно, и $i \leftrightarrow j$, то $j$ тоже возвратно.
\end{cons}

\begin{proof}
  $\exists k, l \in \mathbb{N}$ такие, что $p_{i, j}(k)>0$, $p_{j, i}(l)>0$. Тогда $p_{j, j}(n+k+l) \geq p_{j, i}(l)p_{i, i}(n)p_{i, j}(k)=Cp_{i, i}(n)$, где $C>0$, Значит, ряд $\sum_{n=0}^{\infty} p_{j, j}(n+k+l)$ тоже расходится, а вместе с ним и ряд $\sum_{n=0}^{\infty} p_{j, j}(n)$
\end{proof}

\begin{theorem}
(\hypertarget{n43}{\textcolor{magenta}{\textit{Теорема Пойа}}}).: 
\begin{enumerate}
    \item Простое случайное блуждание на $\mathbb{Z}$ возвратно только при $p=q=\frac{1}{2}$
    \item Простое случайное симметричное блуждание на $\mathbb{Z}^2$ возвратно
    \item Простое случайное блуждание на $\mathbb{Z}^d$, $d>2$, невозвратно
\end{enumerate}
Во всех случаях мы выходим из начала координат.
\end{theorem}

\begin{proof} \
\begin{enumerate}
    \item $p(2k+1)=0$, $p(2k)= {2k \choose k}(pq)^k = \Big ( \frac{{2k \choose k}}{2^{2k}} \Big )(4pq)^k \sim \frac{1}{\sqrt{\pi k}}(4pq)^k$. если $p=q=\frac{1}{2}$, то ряд из $p_k$ расходится, и блуждание возвратно. Иначе $0 \leq 4pq<1$, и ряд сходится даже быстрее, чем геометрическая прогрессия.
    \item  $p(2k+1)=0$, $p(2k)=\sum_{m=0}^k \mathbb{P}(X_{2k}=0 \text{ и мы сделали ровно m шагов вправо} | X_0=0)=\sum_{m=0}^k \frac{1}{4^{2k}} {2k \choose m}{2k-m \choose m}{2k-2m \choose k-m}=\frac{1}{4^{2k}} \sum_{m=0}^k  \frac{(2k)!}{m!(2k-m)!} \frac{(2k-m)!}{m!(2k-2m)!} \frac{(2k-2m)!}{((k-m)!)(k-m)!}=\frac{1}{4^{2k}} \sum_{m=0}^k  \frac{(2k)!}{(m!)^2((k-m)!)^2}=\frac{1}{4^{2k}} {2k \choose k}\sum_{m=0}^k {k\choose m}^2=\Big (\frac{{2k \choose k}}{4^k}\Big)^2  \sim \frac{1}{\pi k} $, и ряд из $p_k$ расходится
    \item Не доказывали.
\end{enumerate}
\end{proof}

\begin{cons}
  Для любой точки $x \in \mathbb{Z}$ $\mathbb{P}(\text{хотя бы один раз прийти в 0} | X_0=x)=1$.
\end{cons}

\begin{proof}
  Обозначим $f(x)=\mathbb{P}(\text{хотя бы один раз прийти в 0} | X_0=x)$. По формуле полной вероятности, получаем $f(x)=\mathbb{P}(\text{хотя бы один раз прийти в 0} | X_0=x)$ $=\mathbb{P}(\text{хотя бы один раз прийти в 0} | X_0=x, X_1=x-1) \mathbb{P}(X_1=x-1)+\mathbb{P}(\text{хотя бы один раз прийти в 0} | X_0=x, X_1=x+1) \mathbb{P}(X_1=x+1)=\frac{1}{2}(f(x-1)+f(x+1))$. Легко понять, что решение данного функционального уравнения над $\mathbb{Z}$ - $f(x)=ax+b$, причём $0 \leq f(x) \leq 1$ для любого $x$, и $f(0)=1$ по теореме Пойа. из первого свойства получаем, что $a=0$, а из второго, что $b=1$. Значит, $f(x) \equiv 1$
\end{proof}

\begin{cons}
  Написав аналогичное функциональное уравнение и рассмотрев $(0, 0)$, его соседей, соседей соседей и т.д., можно доказать данное утверждение для блуждания на $\mathbb{Z}^2$.
\end{cons}

Определим $M_n=\max_{0 \leq k \leq n} (X_n)$. \\

\begin{theorem}
  При $n \rightarrow \infty$ и $j \geq 0$ $\mathbb{P}(M_n \geq j) \approx 2 \mathbb{P}(X_n \geq j)$.
\end{theorem}

\begin{proof}
  $\PP(M_n \geq j) = \PP(M_n \geq j, X_n \geq j)+\PP(M_n \geq j, X_n <j) = \PP(X_n \geq j)+\PP(X_n>j)=2\PP(X_n \geq j)-\PP(X_n)=j \approx 2\PP(X_n \geq j)$. В обосновании нуждается равенство $\PP(M_n \geq j, X_n <j)=\PP(S_n>j)$. Применим \textit{принцип отражения}: рассмотрим траекторию на $\ZZ^2$, попадающую под первое условие, отметим момент, когда она впервые пересекла прямую $y=j$, и отразим часть справа от неё. Получим траекторию, попадающую под второе условие. И наоборот, любая траектория, заканчивающаяся в точке с ординатой $> j$, где-то пересекает прямую $y=j$, и мы моожем по ней построить тракеторию такую, что $M_n \geq j, X_n <j$. Получили взаимооднозначное соответствие между данными двумя множествами, а значит, и вероятности тоже равны.
\end{proof}

\begin{theorem}
  (\hypertarget{n44}{\textcolor{magenta}{\textit{Задача о разорении игрока}}}). Есть два игрока, у одного из них $a$ монет, у другого $b$ ($a, b \in \ZZ_{\geq 0}$). За каждый ход либо первый игрок отдаёт одну моенту второму, либо наоборот, причём оба события имеют вероятность $\frac{1}{2}$. Проигрывает игрок, у которого не остаётся монет. Тогда вероятность выигрыша первого игрока равна $\frac{a}{a+b}$.
\end{theorem}

\begin{proof}
  Пусть в игре находится фиксированное число монет ($a+b$). Обозначим через $\epsilon_i$ последовательность ходов ($\epsilon_i=1$, если на $i$-ом ходе монету получил первый игрок и $-1$ иначе). Рассмотрим событие $A=\{\text{первый игрок проиграл}\}$. $\PP(A)=f(x)$. Тогда $f(0)=1$, $f(a+b)=0$, а в остальных случаях применим формулу полной вероятности и получим соотношение $f(a)=\PP(A)=\frac{1}{2}\PP(A | \epsilon_1=+1)+\frac{1}{2}\PP(A | \epsilon_1=-1)=\frac{1}{2}(f(a-1)+f(a+1))$. Решение данного функционального уравнения - $f(x)=px+q$, причём мы знаем, что $q=1$, $0=p(a+b)+1$. В итоге получаем $f(a)=\frac{b}{a+b}$, а требуемая вероятность выигрыша равна $\frac{a}{a+b}$.
\end{proof}

Пусть $(X_n)$ - простое симметричное случайное блуждание на $\ZZ$. $T_+(n)=\sum_{j=1}^n \mathbb{I}_{\{X_j \geq 0, X_{j-1} \geq 0\}}$ - время пребывания на положительной полуоси. Аналогично определяется $T_-(n)$. Понятно, что $T_+(n)+T_-(n)=n$ 

\begin{lemma}
  $\PP(T_+(2n)=2k)=p_kp_{n-k}$, где $p_k=\PP(X_{2k}=0)=\frac{{2k\choose k}}{4^k}$
\end{lemma}

\begin{proof}
  Давыдов ссылался на какую-то книжку.
\end{proof}

\begin{theorem}
  Для любых $1\geq b>a\geq 0$ при $n \rightarrow \infty$ $\PP(\frac{T_+(2n)}{2n} \in [a, b]) \rightarrow \frac{1}{\pi} \int_{a}^b \frac{1}{\sqrt{t(1-t)}} dt=\frac{2}{\pi} \Big ( \arcsin{\sqrt{b}} - \arcsin{\sqrt{a}} \Big )$
\end{theorem}

\begin{proof}
  $\PP(\frac{T_+(2n)}{2n} \in [a, b])=\sum_{2na \leq 2k \leq 2nb} \PP(T_+(2n)=2k) \approx \sum_{2na \leq 2k \leq 2nb} \frac{1}{\sqrt{\pi k}} \frac{1}{\sqrt{\pi (n-k)}}=\sum_{na \leq k \leq nb} \frac{1}{n \pi} \frac{1}{\sqrt{\frac{k}{n}(1-\frac{k}{n})}}=\sum_{a \leq \frac{k}{n} \leq b} \frac{1}{n} h(\frac{k}{n}) \approx \int_a^bh(x) dx=\frac{2}{\pi} \Big ( \arcsin{\sqrt{b}} - \arcsin{\sqrt{a}} \Big )$, где $h(t)=\frac{1}{\pi}\frac{1}{\sqrt{t(1-t)}}$
\end{proof}












\newpage

\section{Указатель}

\hypertarget{t2}{Начали спрашивать быстрые вопросы, и ты пришёл сюда? Ну ладно ебать, удачи}

\begin{multicols}{2}

\hyperlink{n1}{вероятностное пространство} \ 

\hyperlink{n32}{вероятность перехода} \ 

\hyperlink{n27}{ветвящийся процесс} \ 

\hyperlink{n42}{возвратное состояние} \

\hyperlink{n2}{дискретное вп} \ 

\hyperlink{n14}{дисперсия} \ 

\hyperlink{n36}{достижимое состояние} \ 

\hyperlink{n44}{задача о разорении игрока} \

\hyperlink{n22}{ЗБЧ Бернулли} \ 

\hyperlink{n21}{ЗБЧ Чебышева} \ 

\hyperlink{n33}{инвариантное распределение} \ 

\hyperlink{n25}{интегральная теорема Лапласа} \ 

\hyperlink{n12}{испытание Бернулли} \ 

\hyperlink{n19}{ковариация} \ 

\hyperlink{n20}{коэф корреляции} \ 

\hyperlink{n28}{критерий невырожденности} \ 

\hyperlink{n11}{критерий независимости св} \ 

\hyperlink{n24}{локальная теорема Лапласа} \ 

\hyperlink{n13}{матожидание} \ 

\hyperlink{n17}{моменты} \ 

\hyperlink{n31}{начальное распределение} \ 

\hyperlink{n10}{независимые св} \ 

\hyperlink{n7}{независимые события} \ 

\hyperlink{n15}{неравенство Маркова} \ 

\hyperlink{n16}{неравенство Чебышева} \ 

\hyperlink{n30}{однородная цепь} \ 

\hyperlink{n40}{период класса} \ 

\hyperlink{n39}{период состояния} \ 

\hyperlink{n34}{предельное распределение} \ 

\hyperlink{n26}{производящая функция } \ 

\hyperlink{n3}{равновероятные исходы} \ 

\hyperlink{n9}{распределение св} \ 

\hyperlink{n37}{сообщающиеся состояние} \ 

\hyperlink{n8}{случайная величина} \ 

\hyperlink{n18}{случайный вектор} \ 

\hyperlink{n23}{теорема Вейерштрасса} \ 

\hyperlink{n35}{теорема Маркова} \ 

\hyperlink{n43}{теорема Пойа} \

\hyperlink{n4}{условная вероятность} \ 

\hyperlink{n5}{формула Байеса} \ 

\hyperlink{n29}{цепь Маркова} \ 

\hyperlink{n41}{циклический подкласс} \ 

\hyperlink{n38}{эргодические классы} \ 

\end{multicols}

\end{document}