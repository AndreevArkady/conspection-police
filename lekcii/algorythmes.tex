\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[unicode, pdftex]{hyperref}
\usepackage{cmap}
\usepackage{mathtext}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools}
\usepackage{icomma}
\usepackage{euscript}
\usepackage{mathrsfs}
\usepackage{geometry}
\usepackage[usenames]{color}
\hypersetup{
     colorlinks=true,
     linkcolor=magenta,
     filecolor=magenta,
     citecolor=black,      
     urlcolor=cyan,
     }
\usepackage{fancyhdr}
\pagestyle{fancy} 
\fancyhead{} 
\fancyhead[CO]{\hyperlink{t2}{к списку объектов}}
\fancyhead[LO]{\hyperlink{t1}{к содержанию}} 
\fancyfoot{}
\newtheoremstyle{indented}{0 pt}{0 pt}{\itshape}{}{\bfseries}{. }{0 em}{ }

%\geometry{verbose,a4paper,tmargin=2cm,bmargin=2cm,lmargin=2.5cm,rmargin=1.5cm}

\title{Матосновы алгоритмов}
\author{Мастера конспектов \\ на основе лекций А. С. Охотина и А. В. Тискина}
\date{22 января 2020 г.}

\theoremstyle{indented}
\newtheorem{theorem}{Теорема}
\newtheorem{lemma}{Лемма}
\newtheorem{alg}{Алгоритм}

\theoremstyle{definition} 
\newtheorem{defn}{Определение}
\newtheorem{exl}{Пример(ы)}
\newtheorem{prob}{Задача}

\theoremstyle{remark} 
\newtheorem{remark}{Примечание}
\newtheorem{cons}{Следствие}
\newtheorem{exer}{Упражнение}
\newtheorem{stat}{Утверждение}

\DeclareMathOperator{\la}{\leftarrow}
\DeclareMathOperator{\ra}{\rightarrow}
\DeclareMathOperator{\lra}{\leftrightarrow}
\DeclareMathOperator{\La}{\Leftarrow}
\DeclareMathOperator{\Ra}{\Rightarrow}
\DeclareMathOperator{\Lra}{\Leftrightarrow}
\DeclareMathOperator{\Llra}{\Longleftrightarrow}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Imf}{Im}
\DeclareMathOperator{\cont}{cont}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\ev}{ev}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\chard}{char}
\DeclareMathOperator{\CC}{\mathbb{C}}
\DeclareMathOperator{\ZZ}{\mathbb{Z}}
\DeclareMathOperator{\RR}{\mathbb{R}}
\DeclareMathOperator{\NN}{\mathbb{N}}
\DeclareMathOperator{\codim}{codim}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\Prop}{Prop}
\DeclareMathOperator{\LL}{\mathscr{L}}
\DeclareMathOperator{\KK}{\mathscr{K}}
\DeclareMathOperator{\form}{Form}
\DeclareMathOperator{\Pred}{Pred}
\DeclareMathOperator{\Func}{Func}
\DeclareMathOperator{\Const}{Const}
\DeclareMathOperator{\arity}{arity}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Term}{Term}
\DeclareMathOperator{\sub}{sub}
\DeclareMathOperator{\Sub}{Sub}
\DeclareMathOperator{\Atom}{Atom}
\DeclareMathOperator{\FV}{FV}
\DeclareMathOperator{\Sent}{Sent}
\DeclareMathOperator{\Th}{Th}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\Eq}{Eq}
\DeclareMathOperator{\GA}{\mathfrak{A}}
\DeclareMathOperator{\GB}{\mathfrak{B}}
\DeclareMathOperator{\GC}{\mathfrak{C}}
\DeclareMathOperator{\GD}{\mathfrak{D}}

\begin{document}

\newcommand{\resetexlcounters}{%
  \setcounter{exl}{0}%
} 

\newcommand{\resetremarkcounters}{%
  \setcounter{remark}{0}%
} 

\newcommand{\reseconscounters}{%
  \setcounter{cons}{0}%
} 

\newcommand{\resetall}{%
    \resetexlcounters
    \resetremarkcounters
    \reseconscounters%
}

\maketitle 

\newpage

\hypertarget{t1}{Основные моменты}. 
\tableofcontents

\newpage

\section{Лекция 1.}

\subsection{Быстрая сортировка.}

\begin{alg}
    \textbf{Быстрая сортировка.} Выбираем \textbf{опорный элемент}, с которым сравниваем все остальные элементы (на это уходит линейное время). Затем рекурсивно работаем с тем, что справа от него и слева от него.
\end{alg} \ 

\begin{theorem}
    Если все элементы массива различны и опопрный элемент выбирается случайно, то среднее время работы алгоритма - $\Theta(n\log n)$.
\end{theorem}

\begin{proof}
    Время работы пропорционально числу сравнениий между элементами. Расматриваем два элемента $y_i$ и $y_j$, $i<j$, тогда они сравниваются только, если выбран один из них в качестве опорного. Если будет выбран какой-то $y_k$, $i<k<j$, то они никогда больше не будут сравнены, если что-то на отрезке не между ними - плевать, относительно отрезка между ними ничего не поменялось. Тогда среднее количество сравнений между этими элементами: 
    \[
        \frac{2}{j-i+1}. 
    \]
    Тогда всего среднее количество сравнений: 
    \[
        \sum_{i=1}^{n-1}\sum_{j=i+1}^n \frac{2}{j-i+1} = \sum_{i=1}^{n-1}\sum_{k=1}^{n-1} \frac{2}{k+1}= O(n\log n).
    \]
    Последняя оценка получается из
    \[
        \sum_{k=1}^n\frac{1}{k} \approx \int_1^n \frac{1}{x}dx = \ln n. 
    \]
\end{proof}

\subsection{Сортировка кучей.}

\begin{alg}
    \textbf{Сортировка кучей}. Для начала, мы строим дерево: записываем по порядочку все вершины так, что у вершины $x_i$ потомки - $x_{2i}$ и $x_{2i+1}$. Затем начинаем на все вершины, кроме висячих смотреть и делать вот что: если она меньше потомка, то поменяем с ним (если меньше обоих, то с меньшим). Так доведём её до куда сможем, и продолжим рпссмотрение для оставшихся невисячих вершин (в изначальном дереве). Так сверху окажется наименьшая вершина, вынесем её, затем - по индукции.
\end{alg}

\begin{stat}
    Работает за $O(n\log n)$ (построение дерева - $O(\log n)$, вынесение вершин - $O(n)$), можно разогнать оценку до $2n$. 
\end{stat}

\subsection{Скорость сортировки.} 
 
\begin{theorem}
    Всякий алгоритм сортировки, основанный на сравнении, требует $\Omega (n\log n)$ операций сравнения.
\end{theorem}

\begin{proof}
    Построим дерево того, как мы спускаемся к определению последовательности, его высота ограничивается $\log_2n!$, оценим факториал $\biggl(\frac{n}{e}\biggr)^n<n!<n^n$, а после - оценим через это логарифм $n\log_2n - O(n)$. 
\end{proof}

\begin{alg}
    \textbf{Сортировка подсчётом}. Если у нас есть массив из конечного обозримого количества типов элементов, можно сначала посчитать количество первого, затем количество второго, и так далее. Время работы - $O(n+k)$, где $k$ - количество типов, $n$ - количество переменных.
\end{alg} \ 

\begin{alg}
    \textbf{Поразрядная сортировка.} Сортируем числа сначала по первому разряду, затем по второму, и так далее\dots Время работы: $O(l(n+k))$, где сравниваются строки длины $l$, алфавит из $k$ символов.
\end{alg}

\subsection{Нахождение $i$-го по величине элемента массива.} 

\begin{alg}
    \textbf{Нахождение $i$-го элемента}. Делим массив на пятёрки подряд идущих элементов (возможно, последняя пятёрка будет неполной). Теперь в каждой пятёрке выделяем медианы, и смотрим на медиану медиан. Сделаем её опорным элементом и как в быстрой сортировке, раскидаем всё по сторонам. Если этот элемент под номером $i$, то мы его нашли, иначе - действуем рекурсивно с одной из сторон. Время работы - линейное.
\end{alg}

\subsection{Метод динамического программирования.}

\begin{prob}
    Имеется стержень длины $n$. Продав стержень длины $i$, можно выручить $p_i$ денежных единиц. Как выгоднее всего распилить имеющийся стержень?
\end{prob}

\begin{alg}
    Начинаем с первого, и делаем полный перебор. Говнище
\end{alg} \ 

\begin{alg}
    \textbf{Жадный алгоритм.} Отпиливаем самый дорогой кусок, затем опять самый дорогой из возможных, и так далее. Не самый оптимальный.
\end{alg} \ 

\begin{alg}
    \textbf{Метод динамического программрования.} Суть этого метода такова. Пусть на каждом шаге надо сделать выбор (принять решение). Известно, что какой-то выбор приводит к оптимальному результату. Этому выбору соответствует некий набор подзадач. Тогда сперва находятся ответы для всех подзадач данной задачи, возникающих при различном выборе, после чего, имея все эти ответы перед глазами, можно будет в каждом случае сделать наилучший выбор.
\end{alg}

\begin{exl}
    Пусть стержень длины 0 не стоит нисколько. Для $j$ от 1 до $n$ пока не найдено никаких способов продать стержень, для всякой длины отрезаемого куска, сложим его цену с выручкой за остаток. Если так можно выручить больше известного, то цена стержня длины $j$ улучшается, и так рекурсивно мы дойдём до получения цены за весь стержень. 
\end{exl}

\section{Лекция 2.}

\subsection{Продолжение динамического программирования.}

\begin{prob}
    Пусть нужно умножить $n$ матриц $M_1 \times \ldots \times M_n$. В силу ассоциативности, скобки можно расставить как угодно. От их расстановки зависит общее число операций, и, чтобы умножить матрицы быстрее, надо заранее определить наилучший порядок их умножения.
\end{prob}

\begin{exl}
    Строим верхнедиагональную матрицу $T$, в которой $T_{i, j}$ - наименьшее число действий, необходимых для вычисления $M_{i+1} \times \ldots \times M_n$. \ 

    Внешний цикл по длине куска $l=j-i$, второй - по $i$, во внутреннем перебируются все разбиения произведения на два, и вычисляется следующее значение:
    \[
        T_{i, j}=\min_{k=-+1}^{j-1}(T_{i, k}+T_{k, j}+m_im_km_j). 
    \]
    Разбираем так все по порядку и вычисляем наилучший способ. Время раюоты: $O(n^3)$ - строим таблицу, далее - $2n-1$ вызовов процедуры перемножить $(i, j)$, в каждом - $O(n)$ итераций цикла. И ещё само умножение матриц.
\end{exl}

\begin{remark}
    Для простого понимания - простой пример с кузнечиком, который прыгает на 1 или 2, и ему нужно пропрыгать $n$, сколькими способами это можно сделать? Мы заводим массив $dp[i]$ длины $n$ (кол-во способов добраться до $i$), тогда $dp[i]=dp[i-1]+dp[i-2]$, и так насчитываем все значения, находим ответ для $n$. 
\end{remark}

\subsection{Нахождение наибольшей общей подпоследовательности.}

\begin{defn}
    \textbf{Строкой над алфавитом} $\Sigma$ называется всякая конечная последовательность $w=a_1\ldots a_l$, где $l\geq 0$, и $a_1, \ldots, a_l \in \Sigma$ - символы.
\end{defn}

\begin{alg}
    \textbf{Народный алгоритм.} Динамический способ нахождения наибольшей общей подпоследовательности. Заводим таблицу $T$ и в ячейке $T_{i, j}$ записываем длину наибольшей общей подпоследовательности на префиксах длины $i$ и $j$ первого и второго слова соответственно. Заполняем таблицу последовательно от более коротких мар до самых длинных, и в итоге получим ответ в задаче. \ 

    Строим таблицу так: берём $T_{i, j}$. Если у них одинаковые последние элементы, то получим $T_{i-1, j-1}+1$. Если они разные, то $\max({T_{i-1, j}, T_{i, j-1}})$. \ 

    Саму последовательность элементов потом восстанавливаем с конца понятно как. Недостаток в том, что чтобы найти подпоследовательность, нужно хранить всю таблицу, а это $O(mn)$, и это много. Однако, если нужна только длина, то можно ограничиться лишь двумя столбцами (или двумя строчками).
\end{alg} \

\begin{alg}
    \textbf{Алгоритм Хиршенберга.} Построение наибольшей общей подпоследовательности за время $O(mn)$, используя память $O(\min(m, n))$. Пусть $u=u'u''$ - некоторое разбиение $u$. Тогда оптимальное совмещение $u$ и $v$ совмещает $u'$ с каким-то начальным куском $v$ - пусть это $v'$, и $u''$ - с остатком $v''$. Нужно найти это разбиение $v=v'v''$, чтобы потом отдельно запустить совмещение двух соответствующиих пар кусков. \ 

    Алгоритм делит $u$ на две подстроки примерно равной длины. Сперва динамическим программированием находится последняя строчка таблицы $T^{u', v}$, как в базовом алгоритме. Её $j$-ый элемент содержит длину наибольшей общей подпоследовательности $u'$ и $u_j$ - префикса длины $j$. Аналогично находится последняя строка таблицы $T^{(u'')^R, v^R}$ ($R$ - reverse). Дальше складываем таблицы поэлементно и ссмотрим, где достигается максимум - это и есть искомое разбиение $v=v'v''$. Для этого вычисления алгоритс использовал $O(|v|)$ ячеек памяти, которые теперь можно освободить. \ 

    Далее алгоритм вызывается рекурсивно, чтобы вычислить лучшее совмещение $u'$ и $v'$, и $u''$ и $v''$. Полученные совмещения последовательно приписываются друг к другу.
\end{alg} \

\begin{theorem}
    Алгоритм Хиршберга работает за время $O(mn)$. 
\end{theorem}

\begin{proof}
    Принимая за единицу времени время, затрачиваемое на вычисление значение одного элемента $T_{i, j}$ в ''народном'' алгоритме, утверждается, что в общей сложности будет выполнено не более, чем $2mn$ шагов. \ 

    Пусть $f(m, n)$ - время работы в наихудшем случае. Тогда индукцией по $m$ и $n$ доказывается неравенство $f(m, n)\leq 2mn$. При запуске на строках $u$ и $v$, где их мощности соответственно равны $m$ и $n$, вычисление таблицы $T_{u', v}$ займёт $\frac12 mn$ шагов, и за столько же шагов будет вычисляться таблица $T^{(u'')^R, v^R}$. После этого проводятся два рекурсивных вызова, один из которых занимает $f(\frac{m}{2}, k)$ шагов, а другой - $f(\frac{m}{2}, n-k)$ шагов, для некоторого $k$. Время раюоты рекурсивных вызовов оценивается по предположению индукции, откуда получается оценка того же вида для $f(m,n)$. 
    \[
        f(m, n)=2\cdot \frac12 mn+\max_k (f(\frac{m}{2}, k)+f(\frac{m}{2}, n-k))\leq mn+\max_k(mk+m(n-k))=2mn
    \]
\end{proof}

\subsection{Поиск в ориентированном графе.}

\begin{alg}
    \textbf{Поиск в ширину (BFS).} В каждый момент времени вершина графа может быть помечена или не помечена. Если вершина уже помечена, значит алгоритм нашёл путь из корня в неё. Кроме пометок на вершинах, алгоритм хранит очередь, в которой находятся все те помеченные вершины, для которых ещё не обработаны исходящие дуги. Таким образом, в каждый момент времени вершина может быть не помеченнной, помечанной и обработанной, и помечанной и необработанной. Идём из корня и последовательно отмечаем и заносим в очередь тех, к кому пришли.
\end{alg}

\begin{stat}
    В каждый момент времени очередь состоит из некоторых вершин, находящихся на расстоянии $l$ от $s$, вслед за которыми идут некоторые вершины, находящиеся на расстоянии $l+1$ от $s$. При этом все вершины на расстоянии, меньшем, чем $l$, уже обработаны, ровно как и все вершины на расстоянии $l$, не вошедшие в очередь. Из вершин на расстоянии $l+1$ в очереди есть ровно все потомки обработанных вершин.
\end{stat}

\begin{stat} \ 
    \begin{itemize}
        \item алгоритм помечает врешину $v$ тогда и только тогда, когда есть путь тз $s$ в $v$; 
        \item если алгоритм находит $v$ по дуге $(u, v)$, то один из кратчайших путей из $s$ в $v$ идёт через $u$; 
        \item все пройденные дуги $(u, v)$ образуют дерево.
    \end{itemize}
\end{stat}

\begin{alg}
    \textbf{Поиск в глубину (DFS).} Ижём в глубину до конца, отмечаем вершины в чёрный, если из них начали идти вниз, серым, если они нам просто встретились на пути. После того, как дошли до конца, идём наверх до первой вершины. Время работы: $O(|V|+|E|)$. 
\end{alg}

\begin{prob}
    \textbf{Топологическая сортировка.} Нужно найти остовные деревья в орграфе (естественно, он должен быть ациклическим). Решается через DFS из следующих утверждений. 
\end{prob}

\begin{stat}
    Граф ациклический тогда и только тогда, когда при поиске в глубину никогда не рассматривается дуга, ведущая в вершину, находящуюся в стеке возврата (дуга из серой в серую).
\end{stat}

\begin{stat}
    Если в ациклическом графе есть дуга $(u, v)$, то время завершения $v$ ментше, чем время завершения $u$. 
\end{stat}

\section{Лекция 3.}

\subsection{Окончание поисков в орграфе.}

\begin{prob}
    Найти в данном графе его компоненты сильной связности. 
\end{prob}

\begin{alg}
    \textbf{Алгоритм Косараджу-Шарира.} Спервая запускается поиск в глубину для $G$, а затем запускается поиск в глубину для обращённого графа $G^R$, в котором направления всех дуг изменены на обратные (однако, компоненты связности те же). При поиске в глубину в обращённом графе, во внешнем цикле вершины рассматриваются в порядке их завершения при первом поиске в глубину, от конца к началу. После этого оказывается, что каждый запуск процедуры DFS во внешнем цикле будет находить очередной сильно связный компонент исходного графа. Время работы: $O(|V|+|E|)$, корректность обосновывается следующим:
\end{alg}

\begin{stat}
    Пусть в графе $G$ есть сильно связные компоненты $C$ и $D$, и есть дуга $(u, v)\in E$ из $C$ в $D$. Тогда при поиске в глубину в графе $G$ самое позднее время завершения вершины в $C$ превосходит таковое в $D$. 
\end{stat}

\begin{proof}
    Рассматриваются два случая: самое ранне обнаружение в $C$ меньше, чем в $D$, тогда рассматриваем первую обнаруженную вершину $x\in C$, у всех вершин из $D$ время окончания меньше, чем у неё. Если же это не так, то рассмотрим самую раннюю $y\in D$. Все остальные из этой компоненты будут обнаружены на рекурсивных вызовах, а из $C$ на этом этапе не обнаружатся, поэтому время окончания всех вершин из $C$ больше. 
\end{proof}

\begin{theorem}
    Вершины каждого дерева, найденного алгоритмом Косадаржу-Шарира при втором поиске в глубину - это и есть сильно связные компоненты исходного графа. 
\end{theorem}

\begin{proof}
    Индукция по количеству найденных компонент связности. Надо доказать, что если первые $k$ найденных компонент связности действительно таковы, то и следующая также обладает этим свойством.
\end{proof}

\subsection{Поиск в алгоритме с весами.}

\begin{prob}
    Пусть в орграфе для каждой дуги задан вес. Нужно найти пуи наименьшего веса из данной вершины $s\in V$ во все вершины графа.
\end{prob}

\begin{alg}
    \textbf{Алгоритм Беллмана-Форда.} Для каждой вершины вычисляются значения $d_v$ - наименьший вес пути из $s$ в $v$ и $\pi_v$ - предыдущая вершина на пути наименьшего веса из $s$ в $v$. Изначально полагается, что $d_v=\infty$ и $\pi_v=\text{NULL}$ для всех вершин, и $d_s=0$. Далее алгоритм постепенно находит пути меньшего веса в другие вершины, запоминая веса лучших из найденных путей в этих переменных, Значения уменьшаются с помощью элементарной операции улучшения пути, используя некоторую дугу $(u, v)\in E$. Если $d_u+w_{u, v}<d_v$, то $d_v=d_u+w_{u, v}$, а $\pi_v=u$. Эта операция применяется, пока можно что-то улучшить. Как будет показано, для этого достаточно рассмотреть все дуги $|V|-1$ раз.
\end{alg}

\begin{stat}
    После $i$-ой итерации внешнего цикла алгоритм Беллмана-Форда находит все пути наименьшего веса длины не более чем $i$. 
\end{stat}

\begin{proof}
    Индукция по $i$. 
\end{proof}

\begin{theorem}
    Алгоритм Беллмана-Форда за $|V|\cdot|E|$ шагов или правильно вычисляет пути наименьшего веса из вершины $s$ во все вершины, или сообщает о наличии достижимого цикла отрицательного веса. 
\end{theorem}

\begin{proof}
    Рассмотрим систему после $|V|-1$ итераций, и согласно утв. 7, нейдены все пути наименьшего веса, состоящие не более чем из $|V|-1$ дуг. Если какой-то путь ещё можно улучшить, то в этом пути какая-то вершина встретилась дважды, следовательно, найден цикл отрицательного веса. Если же ничего нельзя улучшить, то любой достижимый цикл будет иметь неотрицательный вес, так как для последовательный верщин цикла можно записать не условие улучшения и сложить по все парам.
\end{proof}

\begin{alg}
    Алгоритм Дейкстры. Этот алгоритм решает ту же задачу, однако на каждом шаге находит очередную вершину $u$, путь наименьшего веса в которую уже известен. Тогда плгоритм рассматривает все дуги, исходящие из вершины $u$. Это позволяет ему рассматривать каждую дугу графа лишь однажды.
\end{alg} \

\begin{theorem}
    Алгоритм Дейкстры работает правильно.
\end{theorem}

\begin{proof}
    Индукцией по длине вычисления доказываем, что для всякой вершины $u\notin Q$, путь наименьшего пути уже построен. Для этого рассматриваются две вершины на кратчайшем пути - одна в среди рассмотренных, другая - среди не рассмотренных ($Q$), и для последней проводятся вычисления, связанные с длиной самого короткого пути для неё.
\end{proof}

\begin{remark}
    Для представления множества $Q$ алгоритм использует особую структуру данных: \textit{очередь с приоритетами}. Каждый элемент $Q$ находится там вместе со своим текущим значением $d_v$. Также заданы операции: 

    \begin{itemize}
        \item $insert(x)$ - вставить новый элемент; 
        \item $min()$ - выдать минимальный элемент; 
        \item $extract_{min}()$ - выдать минимальный и удалить; 
        \item $decrease(x, k)$ - изменить значение элемента $x\in Q$ на $k$, если $k$ меньше текущего значения $x_i$. 
    \end{itemize}

    Скорость работы алгоритма: $|V|$ раз $extract_{min}$ и $|E|$ раз $decrease$, поскольку каждая дуга обрабатывается лишь однажды. 
\end{remark}

\subsection{Окончание поиска с весами.}

Сложность алгоритма Дейкстры зависит от того, как реализвана очередь с приоритетами. Тупая реализация: хранить массив $x_v$, индекцированный по $v\in V$. Тогда $decrease$ работает за $O(1)$, но $extract_{min}$ требует время $|V|$. Отсюда общее время работы - $|V|^2+|E|=O(|V|^2)$. \\

\begin{alg}
    \textbf{Улучшение Дейкстры кучей.} Используется куча, в которой значение в каждой внутренней вершине не больше, чем значение в любом из её потомков (min-heap). Операции снатовятся следующими:

    \begin{itemize}
        \item $insert(x)$ - вставить новый элемент (он становится листом), после чего дать ему всплыть до его законного места; 
        \item $min()$ - выдать минимальный элемент (просто вернуть $x_1$); 
        \item $extract_{min}()$ - переместить $x_n$ в $x_1$, убрав его в конце, а затем запустить исправление кучи из корня, то есть, heapify(1); 
        \item $decrease(i, k)$ - изменить значение элемента $x_i$ на $k$, после чего дать элементу $x_i$ всплыть наверх, пока возможно. 
    \end{itemize}
\end{alg}

\begin{remark}
    \textit{Дать всплыть} - значит, если $x_i$ меньше своего родителя, то он обменивается так до тех пор, пока не займёт положенное место.
\end{remark}

\subsection{Нахождение минимального остовного дерева.}

\begin{prob}
    Дан неориентированный связный граф, рёбрам которого сопоставлены числа - веса. Нужно найти одно из остовных деревьев с наименьшим весом.
\end{prob}

\begin{alg}
    \textbf{Общий принцип действия алгоритмов.} Одно за другим присоединяются рёбра к поддереву какого-то минимального, чтобы опять получилось поддерево минимального.
\end{alg}

\begin{defn}
    \textit{Сечение} графа - разбиение множества вершин на два дизъюнктныхмножества. Ребро \textit{пересекает сечение}, если один из его концов лежит в одной части, а другой - во второй. 
\end{defn}

\begin{stat}
    Пусть $T$ - одно из минимальных остовных деревьев графа, а $F$ - его подмножество. Пусть также имеется какое-то сечение, что никакое ребро из $FF$ его не пересекает. Тогда ребро с наименьшим весом, пересекающее это сечение, принадлежит некоторому минимальному остовному дереву $T'$, которое также содержит $F$. 
\end{stat}

\begin{proof}
    Если $(u, v)$ - такое ребро, входит в $T$, то нам подойдёт $T$. Если его там нет, то рассмотрим цикл, который с нима полчуается и поменяем его на другое ребро из цикла, которое пересекает сечение.
\end{proof}

\begin{alg}
    \textbf{Алгоритм Прима.} Начинаем с произвольной вершины и на каждом шаге добавляем ребро из одной из уже имеющихся вершин в некоторую незадействованную (естественно, из всевозможных рёбер выбирается то, у которого минимальный вес). \ 
    
    Время работы: $|E|\log |V|$, так как выполняется $|V|$ операций внешнего цикла. Операции над очередью с приоритерами - $\log|V|$. Внутренний цикл по $v$: за всё время работы алгоритма каждое ребро рассматривается дважды: с одного конца и с другого. Поэтому тело цикла в общей сложности выполняется $2|E|$ раз, и всякий раз выполняется операция над очередью с приоритетами за время $O(\log |V|)$. 
\end{alg}

\begin{remark}
    Структура данных алгоритма - очередь с приотитетеми, в которой хранятся все вершины, ещё не попавшие в дерево. Значение $d_v$ каждойвершины $v$ - это наименьший вес ребра, соединяющий её с деревом. Также для $v$ запоминается вершина $\pi_v$, через которую $v$ соединена с деревом ребром наименьшего веса. \ 

    Всякий раз, когда в дерево добавляется новая вершина $u$, для любой вершины $v$ не из дерева моэет оказаться, что ребро $(u, v)$ легче, чем ранее известное ребро наименьшего веса $(\pi_v, v)$, соединяющее её с деревом, и это тка, если $w_{u, v}<d_v$. В этом случае значения $d_v$ и $\pi_v$ обновляются, переключая $v$ на соединение с деревом через $u$. 
\end{remark}

\begin{alg}
    \textbf{Алгоритм Крускала.} Текущее подмножество остовного дерева - лес, соединяем компоненты самыми лёгкими путями.
\end{alg}

\begin{theorem}
    На каждом шаге работы алгоритма Крускала переменная $T$ содержит подмножество одного из остовных деревьев минимального веса.
\end{theorem}

\begin{proof}
    Индукция по длине вычисления.
\end{proof}

\begin{stat}
    При использовании леса непересекающихся множеств алгоритм работает за время $|E|\log |E|$ - и, стало быть, $|E|\log |V|$. 
\end{stat}

\begin{proof}
    Сортировка займёт время $|E|\log |E|$. Далее алгоритм выполняет $3|E|$ операций над структурой данных, каждая из которых, при реализации через лес непересекающихся множеств, выполняется за время $O(\log n)$, и в общей сложности получается $|E|\log |V|$, что уже быстрее сортировки.
\end{proof}

\subsection{Структура данных для непересекающихся множеств.}

\begin{prob}
    Абстрактная структура данных для представителя разбиения множества на непересекающиеся подмножества. У каждого множества есть выжеленный элемент - \textit{представитель}. Заданы операции:

    \begin{itemize}
        \item $make\_set(x)$ - создать одноэлементное множество; 
        \item $find\_set(x)$ - найти представитель множества, содержащего данный элемент; 
        \item $set\_union(x, y)$ - объединение двух множеств.
    \end{itemize}

    Перед нами стоит задача: как эффективно реализовать эту абстрактную структуру данных?
\end{prob}

\begin{alg}
    \textbf{Лес непересекающихся множеств.} У нас есть лес, если одноэлементно - просто вершинка, если представитель - корень дерева, если объединяем, то корень одного будет указывать на корень другого.
\end{alg}

\begin{remark}
    Используются следующие улучшения: \ 
    
    В каждой вершине хранится её условная сложность - \textit{ранг}. Процедура $make\_set(x)$ устанавливает ранг в нуль. При объединении двух деревьев корень дерева меньшего ранга станет указывать на корень дерева большего ранга. Если оба корня имеют одинаковый ранг, то их объединение получит ранг, больший на единицу. \ 

    При выполнении каждой операции поиска все встреченные на пути вершины пренаправятся в корень для ускорения последующих операций цикла.
\end{remark}

\begin{stat}
    Пусь всего элементов - $n$, и к ним применяется $m$ операций. Тогда, с применением первого улучшения, они выполняются за время $O(m \log n)$. 
\end{stat}

\begin{proof}
    Смотрим на дерево, через логарифмы вычисляем.
\end{proof}

\begin{theorem}
    (\textbf{Тарьян.}) Пусть всего элементов - $n$, и над ними выполняется $m$ операций. Тогда, с применением первого и второго улучшения, эти операции выполняются за совокупное время $m\alpha (n)$, где $\alpha(n)$ - обратная функция к $A_n(n)$, а $A(k, n)=A_k(n)$ - \textit{функция Аккермана}. 
\end{theorem}

\begin{prob}
    Дан неориентированный граф - возможно, несвязный. Надо определить его компоненты связности и научиться быстро отвечать на вопрос о том, лежат ли две данные вершины в одной компоненте.
\end{prob}

\begin{alg}
    Алгоритм пишется через представление компонент связности в виде структуры данных для непересекающихся множеств.
\end{alg}

\end{document}