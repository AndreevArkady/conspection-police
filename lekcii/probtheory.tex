\documentclass[a4paper,100pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[unicode, pdftex]{hyperref}
\usepackage{cmap}
\usepackage{mathtext}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools}
\usepackage{icomma}
\usepackage{euscript}
\usepackage{mathrsfs}
\usepackage{geometry}
\usepackage[usenames]{color}
\hypersetup{
     colorlinks=true,
     linkcolor=magenta,
     filecolor=,
     citecolor=magenta,      
     urlcolor=magenta,
     }
\usepackage{fancyhdr}
\pagestyle{fancy} 
\fancyhead{} 
\fancyhead[LE,RO]{\thepage} 
\fancyhead[CO]{\hyperlink{t2}{к списку объектов}}
\fancyhead[LO]{\hyperlink{t1}{к содержанию}} 
\fancyhead[CE]{текст-центр-четные} 
\fancyfoot{}
\newtheoremstyle{indented}{0 pt}{0 pt}{\itshape}{}{\bfseries}{. }{0 em}{ }

%\geometry{verbose,a4paper,tmargin=2cm,bmargin=2cm,lmargin=2.5cm,rmargin=1.5cm}

\title{Теория вероятностей. Конспект 2 сем.}
\author{Кабашный Иван (@keba4ok)\\ \\ (по материалам лекций Давыдова Ю. А.,\\ а также других источников)}
\date{16 февраля 2021 г.}

\theoremstyle{indented}
\newtheorem{theorem}{Теорема}
\newtheorem{lemma}{Лемма}

\theoremstyle{definition} 
\newtheorem{defn}{Определение}
\newtheorem{exl}{Пример(ы)}

\theoremstyle{remark} 
\newtheorem{remark}{Примечание}
\newtheorem{cons}{Следствие}
\newtheorem{stat}{Утверждение}
\newtheorem{exer}{Упражнение}

\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Tors}{Tors}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Imf}{Im}
\DeclareMathOperator{\cont}{cont}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\ev}{ev}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\chard}{char}
\DeclareMathOperator{\CC}{\mathbb{C}}
\DeclareMathOperator{\ZZ}{\mathbb{Z}}
\DeclareMathOperator{\RR}{\mathbb{R}}
\DeclareMathOperator{\NN}{\mathbb{N}}
\DeclareMathOperator{\PP}{\mathbb{P}}
\DeclareMathOperator{\FF}{\mathcal{F}}
\DeclareMathOperator{\Rho}{\mathcal{P}}
\DeclareMathOperator{\codim}{codim}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\adj}{adj}

\begin{document}

\newcommand{\resetexlcounters}{%
  \setcounter{exl}{0}%
} 

\newcommand{\resetremarkcounters}{%
  \setcounter{remark}{0}%
} 

\newcommand{\reseconscounters}{%
  \setcounter{cons}{0}%
} 

\newcommand{\resetall}{%
    \resetexlcounters
    \resetremarkcounters
    \reseconscounters%
}

\maketitle 

\newpage

\hypertarget{t1}{Некоторые} записи по теории вероятностей.
\tableofcontents

\newpage


\section{Лекция 1.}

Начинаем мы с самого базового - аксиоматики и введения определений.

\begin{defn}
    $\Omega$ - \textit{пространство элементарных событий} или \textit{множество элементарных исходов}, есть множество, состоящее из $\omega_i$, \textit{элементарных событий}. Нам важно лишь, чтобы это множество было непустым. $\FF\subseteq \Rho(\Omega)$ - некоторая совокупность подмножеств $\Omega$, есть \textit{множество событий}, элементы которого есть $A_i$ - события.
\end{defn}

\begin{defn}
    $\PP$ - вероятность $A\Rightarrow \PP(A)$ - вероятность события $A$.
\end{defn}

\begin{defn}
    Вся же тройка $(\Omega, \FF, \PP)$ называется \hypertarget{n1}{\textcolor{magenta}{\textit{вероятностным пространством}}}.
\end{defn}

Для вероятностей существует несколько аксиом: 

\begin{itemize}
    \item $0\leq \PP(a\leq 1)$ для любого события, 
    \item $\PP(\Omega)=1$, 
    \item для любого счётного набора попарно непересекающихся события $\{A_i\}_{i\in N}\subseteq\FF$ выполнена \textit{счётная аддитивность}:
    \[
        \PP\biggl( \bigsqcup_{n\in N} A_n\biggr)=\sum_{n\in N}\PP(A_n).
    \]
\end{itemize}

Некоторые свойства вероятностей:

\begin{itemize}
    \item $A\subset B \Rightarrow \PP(A)\leq \PP(B)$;
    \item $\PP(A)=1-\PP(A^c)$;
    \item $\forall A, B \Rightarrow \PP(A\cup B)=\PP(A)+\PP(B)-\PP(A\cap B)$;
    \item $\PP(\bigcup_n A_n)\leq \sum_n \PP(A_n)$.
\end{itemize}

Теперь перейдём к некоторым примерам вероятностных пространств:

\begin{exl}

    Пространство $(\Omega, \FF, \PP)$ \hypertarget{n2}{\textcolor{magenta}{\textit{дискретно}}}, если $\Omega$ не более, чем счётно. $\FF=\Rho(\Omega)$, элементы $\{\omega\}$ также считаем событиями.
    \begin{stat}
        Несколько предложений:

        \begin{itemize}
            \item Пусть $\PP$ - вероятность в $(\Omega, \FF, \PP)$. Тогда $\PP(A)=\sum_{\omega\in A}p_\omega$, где $p_\omega=\PP\{\omega\}$. При этом $p_\omega\geq 0$, $\sum_\omega p_\omega = 1$. 
            \item Предположим, что $\{p_\omega\}_{\omega\in\Omega}$ такие, что выполнено последнее предложение предыдущего пункта, тогда $\PP(A)=\sum_{\omega\in A}p_\omega$ - вероятность.
        \end{itemize}
    \end{stat}
\end{exl}

Также, можно упомянуть про \hypertarget{n3}{\textcolor{magenta}{\textit{равновероятные исходы}}}, из названия понятно, что это. Если $\vert \Omega\vert <\infty$ и $p_\omega=p$ для любого $\omega$, тогда $\PP(A)=\frac{\vert A\vert}{\vert \omega \vert}$. \ 

Начнём теперь разбираться с понятием \textit{условная вероятность}.

\begin{exl}
    Начнём с такого примера. Пусть у нас есть события $A, B$, причём их пересечение в вероятностном пространстве пусть. Тогда если исполнится $B$, то $A$ уже исполнится не может.
\end{exl}

\begin{defn}
    \hypertarget{n4}{\textcolor{magenta}{\textit{Условная вероятность}}}: $\PP_B(A)=\frac{\PP(A\cap B)}{\PP(B)}$ (при $\PP(B)>0$).
\end{defn}

\begin{stat}
    Для условной вероятности выполнены аксиомы вероятности.
\end{stat}

А  теперь - несколько утверждений, которые касаютсся условной вероятности.

\begin{stat}
    $(B_n)$ - \textit{разбиение} $\Omega$ (дизъюнктный набор, который в объединении даёт всё множество). Тогда для любого $A$ $\PP(A)=\sum_k\PP(B_k)\PP_{B_k}(A)$. 
\end{stat}

\begin{proof}
    \[
        \PP(A)=\PP(A\cap \Omega)=\sum_n \PP(A\cap (\bigcup_n B_n)) = \PP(\bigcup_n (A\cap B_n))=\sum_n \PP(A\cap B_n)=\PP(B_n)\cdot \PP_{B_n}(A).
    \]
\end{proof}

\begin{stat}
    \hypertarget{n5}{\textcolor{magenta}{\textit{Формула Байеса}}}. Пусть мы знаем событие $A$, имеется разбиение $(B_n)$, тогда 
    \[
    \PP_A(B_k)=\frac{\PP(A\cap B_k)}{\PP(A)}=\frac{\PP(B_k)\PP_{B_k}(A)}{\sum_n\PP(B_n)\PP_{B_n}(A)}
    \]
\end{stat}

\begin{stat}
    \hypertarget{n6}{\textcolor{magenta}{\textit{Формула умножения}}}. 
    \[
        \PP(\bigcap_1^n A_k)=\PP(A_1)\cdot \PP_{A_1}(A_2)\cdot\PP_{A_1\cap A_2}(A_3)\cdot\ldots
    \]
\end{stat}

Перейдём к \textit{независимости событий}. Начнём рассуждения с двух событий: $A$ и $B$. Если $\PP(B)=\PP_A(B)$, $\PP(A)=\PP_B(A)$, или, что равносильно им обоим $\PP(A\cap B)=\PP(A)\PP(B)$, то события называются \textit{независимыми}.\ 

Пусть теперь имеется не два, а больше событий $\{A_q, \ldots, A_n\}$. Нельзя сказать, что нам хватает попарной независимости для независимости совокупной.

\begin{exl}
    (Пирамида Бернштейна). Рассмотрим тетраедр, у которого стороны покрашены таким образом: белый, синий, красный и флаг России. Рассматриваем события: $A_1$ - на выпавшем основании есть белый цвет, и так далее $A_2$ и $A_3$. Эти события попарно независмы, но не независимы в совокупности.
    \[
        \PP(A_i)=\frac{1}{2}, \: \PP(A_1\cap A_2)=\frac14=\frac12\cdot\frac12=\PP(A_1)\PP(A_2), 
    \]
    но тогда 
    \[
        \PP((A_1\cap A_2)\cap A_3)=\frac14\neq\frac18.
    \]
\end{exl}

Таким образом, нужно ввести корректное определение.

\begin{defn}
    События $A_1, \dots, A_n$ \hypertarget{n7}{\textcolor{magenta}{\textit{независимы}}}, если выполнено:
    \begin{align*}
        \PP(A_i\cap A_j)&=\PP(A_i)\PP(A_j), \: \forall i\neq j,  \\ 
        \PP(A_i\cap A_j\cap A_k)&=\PP(A_i)\PP(A_j)\PP(A_k), \: \forall i\neq j\neq k,  \\
        &\dots \\
        \PP(\bigcup_1^n A_i)&=\prod_1^n \PP(A_i).
    \end{align*}
\end{defn}

\begin{theorem}
    Пусть имеется $T_1, \ldots, T_m$ - разбиение $\{1, \ldots, n\}$, независимые события $A_1, \ldots, A_n$, $\{B_j\}_m$ - комбинация (всякие действия между элементами) событий $\{A_s, s\in T_j\}$. Тогда $\{B_j\}$ - независимы.
\end{theorem}

\begin{proof}
    По индукции.
\end{proof}

\begin{defn}
    \hypertarget{n8}{\textcolor{magenta}{\textit{Случайная величина}}} - это функция $X:\Omega\rightarrow R$. 
\end{defn}

\begin{exl}
    Число выпавших решек на $n$ бросках.
\end{exl}

Теперь немного о \textit{распределении случайной величины}. Пусть имеется вероятностное пространство и случайная величина $X$. Нас интересует $\{\omega\vert X(\omega)\in B\subseteq \RR \}$, то есть, мы хотим исследовать попадания случайной величины в те или иные зоны на прямой. Такую вероятность можно рассматривать как вероятность от множества $B$, но это слишком сложно, поэтому продолжим на таких двух пунктах:

\begin{itemize}
    \item значения $X$, $X(\Omega)=\{a_1, \ldots\}$, $\{a_k\}$ - значение $X$, 
    \item $A_k=\{\omega\vert X(\omega)=a_k\}$; $p_k=\PP(A_k)$, причём каждая $p_k\geq0$, а их сумма равна единице.
\end{itemize}

Тогда мы можем сделать вывод, что $\PP\{X\in B\}=\sum_{k\vert a_k\in B}p_k$, так как левая часть есть $\PP\{\bigcup_{k\vert a_k\in B}\}$, что равно $\PP\{\bigcup_{k\vert a_k\in B}\{x=a_k\}\}=\sum_{k\vert a_k\in B}\PP\{x=a_k\}$, что уже и равно левой части.\

\begin{defn}
    Таки образом, совокупность последовательностей $\frac{\{a_k\}}{\{p_k\}}$ и называется \hypertarget{n9}{\textcolor{magenta}{\textit{распеределением случайной величины}}}. 
\end{defn}

\begin{exl}
    Приведём примеры распределений:

    \begin{itemize}
        \item \textit{вырожденное}: $X(\omega)=a$ для любого $\omega$.
        \item \textit{распределение Бернулли}: $B(1, p)$, $p\in[0,1]$, причём единица принимается с вероятностью $p$, $0$ - иначе.
        \item \hypertarget{n10}{\textcolor{magenta}{\textit{биномиальное}}}: $B(n, p)$, $p\in[0,1]$, $X\sim B(n, p)$, если принимаются значения от $0$ до $n$, причём $\PP\{X=k\}=\PP_n(k)$ (просто обозначение), и равно $C_n^kp^k(1-p)^{n-k}$.
    \end{itemize}

\end{exl}

\section{Лекция 2.}

Приведём ещё несколько примеров распределений: 

\begin{exl}
    \begin{itemize}
        \item \textit{геометрическое} $X = 1, 2, \ldots$, $p\in[0,1]$. $P\{X=k\}=(1-p)^{k-1}p$.
        \item \textit{пуассоновское} $X\sim \Rho(\alpha), \alpha>0$, $X=0, 1, \ldots$, $P\{X=k\}=\frac{\alpha^k}{k!}e^{-\alpha}$. 
    \end{itemize}
\end{exl}

Независимость случайных величин.

\begin{defn}
    $X$ и $Y$ - \textit{независимые случайные величины}, если $\forall A, B\subset \RR^1$ события $\{X\in A\}$, $\{Y\in B\}$ независимы.
\end{defn}

Чуть позже бужет критерий независимости, потому что по определению проверить зачастую слишком проблематично. 

\begin{defn}
    $X_1, X_2, \ldots, X_n$ - назависимые случайные величины, если $\forall A_1, \ldots, A_n \subset \RR^1$, $\{X_i\in A_i\}$ независимы.
\end{defn}

\begin{theorem}
    (Критерий независимости случайных величин). Предположим, что $X_k$ имеет распределение $(a_{kj})_j$, $(p_{kj})$, $k=1, \ldots, n$. Тогда $X_i$ назависимы тогда и только тогда, когда 
    \[
        \PP\{X_1=a_{1j_1}, X_2=a_{2j_2}, \ldots, X_n=a_{nj_n} = \prod_{k=1}^n p_{kj_k}
    \]
\end{theorem}

\begin{proof}
    Из первого во второе - очевидно. В обратную сторону для начала докажем такой факт: если $A_1, \ldots, A_n \subset \RR^1$, то тогда
    \[
        \PP\{X_1\in A_1, X_2\in A_2, \ldots, X_n \in A_n = \prod_{k=1}^n \PP \{X_k \in A_k\}. 
    \]
    Докажем все факты для двух, обобщается это всё не сложно. 
    \[
        \PP\{X_1\in A_1, X_2\in A_2\}=\PP\biggl( \bigcup_{j, s|a_{1j}\in A_1, a_{2s}\in A_2} \bigcap \{X_1=a_{1j}, X_2=a_{2s} \biggr), 
    \]
    Но вероятность объединения можно заменить на сумму вероятностей: 
    \[
        \sum_{-//-}\PP\{X_1=a_{1j}, X_2=a_{2s}\} = \sum_{-//-}p_{1j}p_{2s} = \biggl( \sum_{j|a_{1j}\in A_1} p_{1j}\biggr)\biggl( \sum_{s|a_{2s}\in A_2} p_{2s}\biggr), 
    \]
    что равно 
    \[
        \PP\{X_1\in A_1\} \PP\{X_2 \in A_2\}. 
    \]
    Это как раз и даёт нам независимость через немного хитрую вещь. Нам же нужна независимость для любого количества элементов, но казалось бы, у нас есть только для всех $X_i$. Однако, в лемме можно заменить некоторые $A_l$ на $\RR^1$, и тогда выражение как раз показывает нам необходимые соотношения на оставшиеся величины. 
\end{proof}

\begin{exl}
    Пусть $X\sim \Rho(\alpha)$, $Y\sim \Rho(\beta)$ - независимы (пуассоновские распределения). Найдём тогда распределение $X+Y$, $X+Y=0, 1, 2, \ldots$. 
   
    \begin{equation*}
        \begin{aligned}
            \PP\{X+Y=n\} & =\PP\{\sqcup_{k=0}^n\{X+Y=n, X=k\}\} =\sum_{k=0}^n\PP\{X+Y=n, X=k\}= \\ 
             & = \sum_{k=0}^n\{X=k, Y=n-k\} =\sum_{k=0}^n\PP\{X=K\}\PP\{Y=n-k\}= \\ 
             & = \sum_{k=0}^n\frac{\alpha^k}{k!}e^{-\alpha}\cdot \frac{\beta^{n-k}}{k(n-))!}e^{-\beta} = e^{-(\alpha+\beta)}\frac{1}{n!}\sum_{k=0}^n\frac{n!}{k!(n-k)!}\alpha^k\beta^{n-k}= \\ 
             & = e^{-(\alpha+\beta)}\frac{1}{n!}(\alpha+\beta)^n =\frac{(\alpha+\beta)^n}{n!}(\alpha+\beta)^n=\frac{(\alpha+\beta)^n}{n!}e^{-(\alpha+\beta)}. 
        \end{aligned}
    \end{equation*}
        

    Таким образом, получаем вывод: $X+Y\sim\Rho(\alpha+\beta)$ - пуассоновское распределение.
\end{exl}

Испытание Бернулли. 

\begin{defn}
    Рассмотрим последовательность $\varepsilon_k$ - независимых бернуллиевских величин (два исхода), $\varepsilon_k\sim B(1, p)$, 
    \begin{equation*}
        \varepsilon_k=
        \begin{cases}
            1, \: p \\ 
            0, \: q=1-p
        \end{cases}
    \end{equation*}
    $\{\varepsilon_k=1\}$ означает успех в каком-то испытании. То есть, \textit{испытание Бернулли} - последовательность из однотипных испытаний.
\end{defn}

$\nu_n$ - число успехов в $n$ испытаниях., что равно $\sum_{k=1}^n\varepsilon_k$. Покажем, что распределение биномиально. $\nu_n=0, 1, \ldots, n$.

\begin{equation*} 
    \begin{aligned}
        C_n^kp^kq^{n-k} & =^?\PP\{\nu_n=l\}=\PP\{\omega\vert \text{ в цепочке }\varepsilon_1(\omega), \ldots, \varepsilon_n(\omega)\text{ в точности } k \text{единиц}\}= \\ 
        & = \PP\{\sum_1^n\varepsilon_j=k\}=\sum_{\{i_1, \ldots, i_n\}| \text{ в } \bar{i} \: k \text{ единиц }}\PP\{\varepsilon_1= i_1, \ldots, \varepsilon_n=i_n\}= \\ 
        & = \sum_{-//-}p^kq^{n-k}=C_n^k p^kq^{n-k}.
    \end{aligned}
\end{equation*} 

Теперь встаёт вопрос: существуют ли независимые бернуллиевские случайные величины. Пусть $\Omega=\{(i_1, i_2, \ldots, i_n)|i_k=0 \text{ или }1\}$; $|\Omega|=2^k$. $p_{\omega}= p^k(1-p)^{n-k}$ для $\omega=(i_1, \ldots, i_n)$, в которой ровно $k$ единиц. $\sum p_n=1$, $\varepsilon_k(\omega)=\varepsilon_k(i_1, \ldots, i_n)=i_k$ .\

$P_n(k)=\PP\{\nu_n=k\}=C_n^kp^kq^{n-k}$ - можем ли мы как-то упростить это? \\

\begin{theorem}
    $n$ испынаний $\text{Б}$ с веростностями успеха $p=p_n$, $n\cdot p_n\rightarrow_{n\rightarrow \infty} \alpha$, тогда $\forall k\in \NN$ $P_n(k)\rightarrow \pi_k=\frac{\alpha^k}{k!}e^{-\alpha}$. 
\end{theorem}

\begin{proof}
    \begin{equation*}
        \begin{split}
            P_n(k)=\frac{n!}{k!(n-k)!}p^kq^{n-k}=\frac{1}{k!}\frac{n(n-1)\ldots(n-k+1)}{n^k}(np^k)q^{n-k}= \\ 
            = \frac{1}{k!}{(1-\frac{1}{n})\ldots(1-\frac{k-1}{n})}(np)^kq^{n-k}\sim\frac{\alpha^k}{k!}q^{n-k}
        \end{split}
    \end{equation*}

    Если что, $k$ - константа. 

    \begin{equation*}
        \begin{split}
            q^{n-k}=(1-p)^{n-k}=(1-\frac{n p_n}{n})^n(1-\frac{n p_n}{n})^{-k} \\ 
            \sim (1-\frac{n p_n}{n})^n \sim e^{-n p_n} = e^{-\alpha}. 
        \end{split}
    \end{equation*}

    В итоге, $P_n(k)\sim\frac{\alpha^k}{k!}e^{-\alpha}$. 

\end{proof}

А теперь - несколько слов о точности аппроксимации. Оценим $|P_n(k)-\pi_k|$. $\pi_k=\frac{(np)^k}{k!}e^{-np}$. \\

\begin{theorem}
    $\sum_{k=0}^\infty|P_n(k)-\pi_n|\leq 2np^2$.
\end{theorem}

\section{Лекция 3.}

\begin{theorem}
    $S_n\sim B(n, p)$; $S\sim \Rho(np)$, тогда для любого $B\subset \RR^1$, $|\PP\{S_n\in B\} - \PP\{S\in B\}|\leq p^2n$. 
\end{theorem}

\begin{cons}
    Пусть $p_k=\PP\{S=k\}=\frac{(np)^k}{k!}e^{-np}$, тогда $\sum_{k=0}^\infty |P_n(k)-p_k|\leq 2p^2n$.
\end{cons}

\begin{proof}
    (Доказательство следствия). Искомая сумма равна $\sum_{k\in B_+}(P_n(k)-p_k)+\sum_{k\in B_-}(p_k-P_n(k))$, где $B_+=\{k|P_n(k)-p_k\geq 0\}$, а $B_-=B_+^C$ - его дополнение. Тогда, продолжая равенство, получаем $(\PP\{S_n\in B_+\}-\PP\{S\in B_+\})+(\PP\{S\in B_-\}-\PP\{S_n\in B_-\})\leq 2p^2 n$.
\end{proof}

\begin{proof}
    (Доказательство теоремы). Поговаривают, что это очень сложно. Начнём строить вероятностное пространство, возьмём носитель $\NN$, где натуральные числа соответствуют вероятностям $q_k=\pi_{k-2}$, $k\geq 3$, $q_1=1-p$, $q_2=\pi_0-(1-p)$, где $\pi_k=\frac{p^k}{k!}e^{-p}$. \ 

    Рассмотрим тогде $\varepsilon_1$ и $\eta_1$ такие, что $\varepsilon_1(1)=0$, $\varepsilon_1(k)=1$, $\forall k\geq 1$, а $\eta_1(1)=0$, $\eta_1(2)=0$, $\eta_1(k)=k-2$, $k\geq 3$. Причём $\PP\{\varepsilon_1=0\}=1-p$; $\PP\{varepsilon_1=1\}=p$, то есть, $\varepsilon_1 \sim B(1, p)$, а $\PP\{\eta_1=k\}=\pi_k$, то есть, $\eta_1\sim \Rho(p)$. Тогда $\PP\{\varepsilon_1=\eta_1\}=q_1+q_3=1-p+pe^{-1}$, а $\PP\{\varepsilon_1 \neq \eta_1\} = p-pe^{-1}=p(1-e^{-p})\leq p^2$. \ 

    Построим теперь $\Omega = \Omega_1 \times \ldots \times \Omega_n$, для каждого $\Omega_i$ будут свои $\varepsilon_i$ и $\eta_i$, а $\bar{\omega}=(\omega_1, \ldots, \omega_n)$, где $\omega_i\in \Omega_i$, причём $p_{\bar{\omega}}=\prod p_{\omega_i}$. Для получившегося пространства строим $\tilde{\varepsilon_k}: \Omega \rightarrow \RR^1$, $\tilde{\varepsilon_k}(\bar{\omega})=\varepsilon_k(\omega_k)$, и аналогично $\tilde{\eta}_k$. 

    \begin{exer}
        $(\tilde{\varepsilon}_k)$ незав., и аналогично для $\eta$. 
    \end{exer}

    Рассмотрим $S_n=\sum_{i=1}^n \tilde{\varepsilon}_i \longrightarrow B(n, p)$ и $S=\sum_{i=1}^n \tilde{\eta}_i \longrightarrow \Rho(np)$, то есть, как раз те распределения, которые нам нужны. Перейдём к $\PP_k\{\varepsilon_k\neq \eta_k\}\leq p^2$, но эта вероятность, как легко проверяется (проверять не будем), равна $\PP\{\tilde{\varepsilon}_k \neq \tilde{\eta}_k\}$, для любого $k$. \ 

    Тогда $\PP\{S_n \neq S\} \leq \PP\{\bigcup_{k=1}\{\tilde{\varepsilon}_k \neq \tilde{\eta}_k\}\}$ по вложенности соответствующих событий. Но мы можем продолжить цепочку $\leq \sum_1^n \PP\{\tilde{\varepsilon}_k \neq \tilde{\eta}_k\}\leq np^2$. Осталось лишь сделать последний шаг: $\PP\{S_n \in B\}=\PP\{S_n\in B, S_n=S\}+\PP\{S_n \in B, S_n \neq S\}\leq \PP\{S_n \neq S\}+\PP\{S\in B, S_n=S\}\leq np^2+\PP\{S\in B\}$. Однако, если бы мы начали с $\PP\{S\in B\}$, то получили бы точно так же, что оно не больше $np^2+\PP\{S_n\in B\}$, что мы и хотели.
\end{proof}

Переходим к небольшому параграфу про случайные векторы. Не думаю, что тут было что-то существенно важное, поэтому просто оставлю определение.

\begin{defn}
    $\bar{X}=(X_1, \ldots, X_n)$, где $X_k:\Omega \rightarrow \RR^1$ для $k=1, \ldots, n$, тогда $\bar{X}:\Omega \rightarrow \RR^n$, $\omega \rightarrow (X_1(\omega), \ldots, X_n(\omega))$. 
\end{defn}

Вот математическое ожидание - важная штука. 

\begin{defn}
    Пусть $X$ - случайная величина, тогда $EX = \sum_{\omega \in \Omega} X(\omega)p_\omega$, если ряд абсолютно сходится в бесконечном случае.
\end{defn}

Свойства: 

\begin{stat}
    Существование математического ожидания эквивалентно существованию математического ожидания $|X|$ (для краткости пишут $E|X|<\infty$). 
\end{stat}

\begin{stat}
    Математическое ожидание линейно.
\end{stat}

\begin{stat}
    Если $X\geq 0$, то $EX\geq 0$. 
\end{stat}

\begin{stat}
    $X\leq Y$, тогда $EX\leq EY$. 
\end{stat}

\begin{stat}
    $|EX|\leq E|X|$ (из $-|X|\leq X \leq |X|$). 
\end{stat}

А вот это уже можно обобщить до неравенства Йенсена: \\

\begin{theorem}
    Если $\varphi$ - выпуклая функция, тогда $\varphi(EX)\leq E\varphi(x)$. 
\end{theorem} \

Однако доказывать мы это не будем, а просто перейдём к следующей теореме: \\

\begin{theorem}
    Пусть $X$ - случайная величина $(a_k); (p_k)$, $f:\RR^\rightarrow \RR^1$. Тогда $Ef(x)=\sum_k f(a_k)p_k$ (существуют или не существуют они одновременно). 
\end{theorem}

\begin{proof}
    Скажем для начала, что $f\geq 0$ (просто возьмём модуль, если что). Тогда $E f(X)=\sum_{\omega \in \Omega} f(X(\omega))p_\omega = \sum_k \biggl( \sum_{\omega|X(\omega) = a_k} f(X(\omega)) p_\omega\biggr) = \sum_k f(a_k) \sum_{\omega | X(\omega)=a_k}p_\omega = \sum_k f(a_k)p_k$. 
\end{proof}

\begin{cons}
    $EX=\sum_k a_k p_k$, $f(x)=x$. 
\end{cons}

\begin{cons}
    Если $X$ и $Y$ имеют одинаковые распределения, то $EX=EY$. 
\end{cons}

\begin{cons}
    $EX$ - центр масс.
\end{cons}

\begin{theorem}
    Пусть $\bar{X}$ - случайный вектор; $(\bar{a}_k); (p_k)$; $f:\RR^n \rightarrow \RR^1$. Тогда $Ef(\bar{X}) = \sum_k f(\bar{a}_k)p_k$. 
\end{theorem} \

\begin{theorem}
    Если $X$ и $Y$ независимы, и их математические ожидания существуют, то у их произведения также существует матожидание, притом равно произведению матожиданий.
\end{theorem}

\begin{proof}
    Применим в предыдущей теореме $f: \RR^2 \rightarrow \RR$ по правилу $f(x, y)=xy$ и распишем $E(XY)$. 
\end{proof}

\section{Лекция 4.}

Начнём сегодня с примеров. 

\begin{exl}
    Пусть $X \sim B(n, p)$ имеет биномиальное распределение. Тогда $EX=\sum_0^n k\cdot C_n^kp^k(1-p)^{n-k}=np$. \ 

    К такому выводу можно прийти и другим способом. Мы знаем, что случайная величина $X$ имеет такое же распределение, как сумма бернуллиевских величин, одинаково распределённых: $X=^D\varepsilon_1+\ldots+\varepsilon_n$, $(\varepsilon_k)$ независимы, $\varepsilon_k\sim B(1, p)$. $EX=\sum_1^n E\varepsilon_k=n E\varepsilon_k = np$. 
\end{exl}

\begin{exl}
    Пусть $X\sim \Rho(\alpha)$, тогда 
    \[
        EX = \sum_0^\infty k\frac{\alpha^k}{k!}e^{-\alpha} = e^{-\alpha}\sum_0^\infty \frac{\alpha^k}{(k-1)!} = \alpha e^{-\alpha}\sum_1^\infty \frac{\alpha^{k-1}}{(k-1)!}=\alpha.
    \] 
\end{exl}

\begin{theorem}  
    (Неравенство Маркова). Пусть $X\geq 0$. Тогда $\forall t>0$, $\PP\{X \geq t\}\leq \frac{EX}{t}$.
\end{theorem}

\begin{proof}
    Введём понятие \textit{индикатора}, то есть, функции $\mathbb{I}_A(\omega)$, которяа равна 1, если $\omega \in A$, и 0 иначе (в нашем случае собыние $A$ - $\geq t$). Эта случайная величина имеет Бернуллиевское распределение, 1 с вероятностью $p=\PP(A)$, и 0 с вероятностью $1-p$. Ясно, что левую часть можно записать как $E\mathbb{I}_A$. Посмотрим теперь на $\frac{X}{t}$. Эта вещь не меньше 1 при $\omega \in A$, тогда $\mathbb{I}_A\leq \frac{X}{t}$, а значит, $E \mathbb{I}_A\leq E\biggl(\frac{X}{t}\biggr)=\frac{EX}{t}$. 
\end{proof}

Это неравенство имеет кучу следствий, рассмотрим некоторые из них.

\begin{cons}
    Пусть $f\uparrow$, $f(x)\geq 0$. Тогда $\PP\{X\geq t\}=\PP\{f(X)\geq f(t)\}\leq \frac{Ef(X)}{f(t)}$. 
\end{cons}

\begin{cons}
    Если $E(X^2)\leq \infty$, и $f(x)=x^2$, то, как следствие, получим $\PP\{|X|\geq t\}\leq \frac{E(X^2)}{t^2}$, тогда при $t\rightarrow \infty$ получим более сильную оценку (на месте $X^2$ можно брать ещё большие степени). Также можно рассмотреть $f(x)=e^{ax}$, $a>0$, тогда получим $\PP\{x\geq t\}\leq \frac{E(e^{aX})}{e^{at}}$. 
\end{cons}

\begin{theorem}
    (Неравенство Йенсена). $X$ - случайная величина, и есть некоторая выпуклая функция $\varphi: \RR^1\rightarrow \RR^1$. Тогда $\varphi(EX)\leq E[\varphi(X)]$.  
\end{theorem}

\begin{proof}
    Предположим, что $X$ принимает два значения: $a$ и $b$ с вероятностями $p$ и $1-p$ соответственно. Тогда $EX=ap+b(1-p)$, это - какая-то линейная комбинацие, то есть, лежит между точками. Рассмотрим тогда неравенсто $\varphi(ap+b(1-p))$ - с одной стороны, $\varphi(ap)+\varphi(b(1-p))$. Первое меньше второго из выпуклости, а для большего количества точек просто рассмотрим по индукции. 
\end{proof}

Теперь перейдём к \textit{дисперсии}. 

\begin{defn}
    $DX = E[(X-EX)^2]$. Нужно, чтобы $E(X^2)$ было меньше бесконечности, тогда $DX$ определена.
\end{defn}

\begin{remark}
    Дисперсия характеризует меру разброса случайной величины от математического ожидания.
\end{remark}

И рассмотрим её свойства. 

\begin{stat}
    Дисперсия неотрицательная.
\end{stat}

\begin{stat}
    $D(X+c)=DX$
\end{stat}

\begin{stat}
    $D(X\cdot c)=c^2 DX$
\end{stat}

\begin{stat}
    $DX = E(X^2) - (EX)^2$
\end{stat}

\begin{stat}
    $DX=\sum_k(a_k- EX)^2p_k$, где $(a_k), (p_k)$ - распределение $X$. 
\end{stat}

\begin{theorem}
    Если $X$, $Y$ - независимые случайные величины, то $D(X+Y)=DX+DY$. 
\end{theorem}

\begin{proof}
    Для начала рассмотрим случай $EX=EY=0$, он достаточно очевиден, а теперь начнём сводить все остальные случаи к этому. Введём $\tilde{X}=X-EX$; $\tilde{Y}=Y-EY$. Тогда $D(X+Y)=D(\tilde{X}+\tilde{Y})=DX+DY$, что и требовалось.
\end{proof}

Рассмотрим теперь несколько примеров дисперсий.

\begin{exl}
    Пусть $X\sim B(n, p)$, тогда $DX=np(1-p)$. 
\end{exl}

\begin{exl}
    Пусть $X\sim \Rho(\alpha)$, тогда $DX = \alpha$. 
\end{exl}

\begin{theorem}
    (Неравенство Чебышёва). Пусть $X$ - случайная величина, $EX^2<\infty$ ($DX$ определена). Тогда $\forall t >0$, 
    \[
        \PP\{|Y|\geq t\}\leq \frac{E(Y^2)}{t^2}
    \]
\end{theorem}

\begin{proof}
    Из следствия 6, при подстановке $(X-EX)$. 
\end{proof}

\begin{defn}
    \textit{Моменты} - матожидания следующего вида. Пусть $X$ - случайная величина. Мы можем рассмотреть $E(X^n)$, $E(X-EX)^n$, $n\in \NN$, $E|X|^p$, $E|X-EX|^p$, $p\in \RR$. Все эти матожидания называются моментами, первые два называются моментами моментами $n$-го порядка, вторые два - \textit{абсолютными моментами}, моменты с разностями называются \textit{центрированными}.  
\end{defn}

\begin{defn}
    Если случайных величин несколько, то вводятся \textit{смешанные моменты}, моменты вида $E(X^n\cdot Y^m)$, или $E[(X-EX)(Y-EY)]=\text{cov}(X, Y)$ - частный случай, \textit{ковариация}. Можем также через него определить \textit{коэффициент корреляции} - $\rho(X, Y)=\frac{\text{cov}(X, Y)}{\sqrt{DX\cdot DY}}$, который является мерой линейной зависимости между $X$ и $Y$. 
\end{defn}

\begin{theorem}
    (Закон больших чисел (в немного ослабленном смысле)). Пусть $(X_k)$ - независимые, одинаково распределённые случацные величины, $EX_k=a$, $DX_k=\sigma^2<\infty$, $S_n= X_1+\ldots+X_n$. Тогда $\forall \varepsilon>0$, $\PP\{|\frac{S_n}{n}-a|\geq \varepsilon\}\rightarrow$, $n\rightarrow \infty$.  
\end{theorem}

\begin{defn}
    \textit{Сходимость по вероятности}: $Y_n \rightarrow^{\PP} Y$, если $\forall \varepsilon>0$, $\PP\{|Y_n-Y|\geq \varepsilon\}\rightarrow 0$, $n\rightarrow \infty$. 
\end{defn}

\begin{proof}
    Рассмотрим эту вероятность, и заметим, что $E\frac{S_n}{n}=a$, тогда по Чебышёву, искомая нами вероятность, ограничивается сверху $\frac{D(\frac{S_n}{n})}{\varepsilon^2} = \frac{1}{\varepsilon^2}\cdot \frac{1}{n^2}D(S_n)= \frac{1}{\varepsilon^2}\sigma^2\frac{1}{n}\rightarrow 0 $, $n\rightarrow 0$. 
\end{proof}

Сформулируем также несколько усложнений (второе даже записывать не буду, оно всё равно не в курсе). \\

\begin{theorem}
    (Теорема Хинчина). Пусть $X_k$ - н.о.р.с.в., тогда если $E|X_1|<\infty$, $EX_k=a$, тогда $\frac{S_n}{n}\rightarrow^{\PP}a$. 
\end{theorem}


\newpage

\hypertarget{t2}{И в заключение...}

\section{Пофамильный указатель всех важных предметов}

\begin{multicols}{2}
    [
    Быстрый список для особо ленивого поиска.
    ]

    \hyperlink{n1}{биномиальное распределение}\
    
    \hyperlink{n1}{вероятностное пространство}\
    
    \hyperlink{n2}{дискретное пространство}\

    \hyperlink{n7}{независимые события}\

    \hyperlink{n3}{равновероятные исходы}\

    \hyperlink{n1}{распределение случайной величины}\

    \hyperlink{n8}{случайная величина}\

    \hyperlink{n4}{условная вероятность}\

    \hyperlink{n5}{формула Байеса}\

    \hyperlink{n6}{формула умножения}\



\end{multicols}

\end{document}