\documentclass[a4paper,100pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[unicode, pdftex]{hyperref}
\usepackage{cmap}
\usepackage{mathtext}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools}
\usepackage{icomma}
\usepackage{euscript}
\usepackage{mathrsfs}
\usepackage{geometry}
\usepackage[usenames]{color}
\hypersetup{
     colorlinks=true,
     linkcolor=magenta,
     filecolor=green,
     citecolor=black,      
     urlcolor=cyan,
     }
\usepackage{fancyhdr}
\pagestyle{fancy} 
\fancyhead{} 
\fancyhead[LE,RO]{\thepage} 
\fancyhead[CO]{\hyperlink{t2}{к списку объектов}}
\fancyhead[LO]{\hyperlink{t1}{к содержанию}} 
\fancyhead[CE]{текст-центр-четные} 
\fancyfoot{}
\newtheoremstyle{indented}{0 pt}{0 pt}{\itshape}{}{\bfseries}{. }{0 em}{ }

%\geometry{verbose,a4paper,tmargin=2cm,bmargin=2cm,lmargin=2.5cm,rmargin=1.5cm}

\title{Матанализ. Конспект 2 сем.}
\author{Мастера Конспектов\\ \\ (по материалам лекций Белова Ю. С.,\\ а также других источников)}
\date{16 февраля 2021 г.}

\theoremstyle{indented}
\newtheorem{theorem}{Теорема}
\newtheorem{lemma}{Лемма}

\theoremstyle{definition} 
\newtheorem{defn}{Определение}
\newtheorem{exl}{Пример(ы)}

\theoremstyle{remark} 
\newtheorem{remark}{Примечание}
\newtheorem{cons}{Следствие}
\newtheorem{stat}{Утверждение}

\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Tors}{Tors}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Imf}{Im}
\DeclareMathOperator{\Real}{Re}
\DeclareMathOperator{\cont}{cont}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\ev}{ev}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\chard}{char}
\DeclareMathOperator{\CC}{\mathbb{C}}
\DeclareMathOperator{\ZZ}{\mathbb{Z}}
\DeclareMathOperator{\RR}{\mathbb{R}}
\DeclareMathOperator{\NN}{\mathbb{N}}
\DeclareMathOperator{\PP}{\mathbb{P}}
\DeclareMathOperator{\FF}{\mathcal{F}}
\DeclareMathOperator{\Rho}{\mathcal{P}}
\DeclareMathOperator{\codim}{codim}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\const}{const}
\DeclareMathOperator{\grad}{grad}

\begin{document}

\newcommand{\resetexlcounters}{%
  \setcounter{exl}{0}%
} 

\newcommand{\resetremarkcounters}{%
  \setcounter{remark}{0}%
} 

\newcommand{\reseconscounters}{%
  \setcounter{cons}{0}%
} 

\newcommand{\resetall}{%
    \resetexlcounters
    \resetremarkcounters
    \reseconscounters%
}

\maketitle 

\newpage

\hypertarget{t1}{Некоторые} записи по матанализу.
\tableofcontents

\newpage


\section{Лекция 1.}

В этом чеместре мы будем занимать анализом функций от многих переменных, то есть,  $f:\RR^n\rightarrow \RR^m$,  и если $m=1$, то такая функция называется функцией многих переменных. \ 

\begin{defn}
    \textit{Кривые в $\RR^n$} - непрерывное отображение $f:[a, b]\rightarrow \RR^n$.
\end{defn}

Основная проблема состоит в том, что образ может выглядеть очень и очень сложно, потому нам хотелось бы более точно понять, как всё это устроено. Потому начнём рассматривать \textit{спрямляемые кривые}, то есть, кривые с конечной длиной. Введём следующее определение: 

\begin{defn}
    \textit{Вариация функции} - $V_f([a, b])=\sup_{a=x_0\leq x_2\leq \ldots\leq x_n=b} \sum_{k=0}\vert f(x_{k+1})-f(x_k)\vert$. 
\end{defn}

$(x-y)$ - евклидово расстояние.

\begin{stat}
    Если $f:\RR\rightarrow \RR$ монотонна, то $V_f([a, b])=\vert f(a)-f(b)\vert $.
\end{stat}

\begin{stat}
    $V_f([a, b])=0 \: \Leftrightarrow \: f=\const$.
\end{stat}

\begin{stat}
    $V_{f+g}\leq V_f+V_g$.
\end{stat}

\begin{stat}
    $V_f$ аддитивна на промежутке: $a\leq b\leq c$, тогда $V_f([a, c])=V_f([a, b])+V_f([b, c])$. 
\end{stat}

\begin{defn}
    Вариация ограничена, если $V_f<\infty $ на $[a, b]$.
\end{defn}

\begin{lemma}\
    
    \begin{itemize} 
        \item $\RR\rightarrow \RR$, $f_1$ и $f_2$ монотонны, тогда $f_1-f_2$ имеют ограниченную вариацию.
        \item $f$ имеет ограниченную вариацию тогда и только тогда, когда $f=f_1-f_2$ на отрезке $[a, b]$, причём эти две функции монотонно возрастают.
    \end{itemize}
\end{lemma}

\begin{proof}
    Пусть у нас есть $f$, а также $V_f([a, b])<\infty$. Рассмотрим $\varphi(x)=V_f([a, x])$. $\varphi$ определа корректно, причём возрастает. $f=\varphi-(\varphi-f)$, скажем, что $(\varphi-f)=h$, тогда $h(x)\leq h(y)$ при $x\leq y$. Но это нетрудно показать, $\varphi(x)-f(x)\leq \varphi(y)-f(y)$ равносильно $f(y)-f(x)\leq \varphi(y-\varphi(x))=V_f([x, y])$.
\end{proof}

По сути, если понимать определение вариации геометрически, то это просто длина кривой на отрезке. Перейдём теперь к способам обхода кривой.\\

\begin{lemma}
    Пусть $g:[a, b]\rightarrow [c, d]$ - непрерывная биекция (тогда и монотонная). Тогда $V_f[c, d]=V_{f\circ g}([a,b])$.
\end{lemma}

\begin{proof}
    Левая и правая части равны соответственно $\sup \sum_{k=0}^{n-1}\vert f(x_{k+1})-f(x_k)\vert$ и $\sup \sum_{k=0}^{n-1}\vert f(g(y_{k+1}))-f(g(y_k))\vert$. Это, очевидно, одно и то же.
\end{proof}

Теперь стоит задаться вопросом: а когда же это $V_f$ (или же, длину кривой) можно посчитать. Если $f$ - гладкая функция (гладкая покоординатно $f_k$). $f:=[a, b]\rightarrow \RR^n$, $f=(f_1, \ldots, f_n)$, $f_k:[a, b]\rightarrow \RR$. Тогда
\[
    V_f([a, b])=\int_a^b\sqrt{(f_1')^2(x)+\ldots+(f_n')^2(x)}\: dx.
\]
Рассмотрим
\begin{eqnarray*}
    \sup_{a=x_0, \ldots, x_n=b}\sum_{k=0}^{n-1}\sqrt{(f_1(x_{k+1})-f_1(x_k))^2+\ldots+f_n(x_{k+1})-f_n(x_k))^2} = \\ 
    = \sum_{k=0}^{n-1}(x_k+1-x_k)\sqrt{f_1'^2(\xi_{1, k})+\ldots+f_n'^2(\xi_{n, k}))}
\end{eqnarray*}

Если $f_i$ непрерывна, то $f_i^2$ равномерно непрерывна. $f_i'^2(\xi_{i, k})\leq \min_{[x_k, x_{k+1}]}f_i'^2+\varepsilon^2$ (для достаточно мелких разбиений и любого эпсилон, большего нуля). Тогда можно получить верхнюю оценку: $\leq \sum_{k=0}^{n-1}(x_{k+1}-x_k)\sqrt{\sum_{l=1}^n \min_{[x_k]}(f_l'^2)}+\varepsilon \sqrt{n}(b-a)\leq \int_a^b\sqrt{\dots}+\varepsilon \sqrt{n}(b-a)$ (устремляем разбиение к бесконечно малому). А затем делаем аналогично снизу и получаем требуемое равенство.

\section{Лекция 2.}

Пусть $\varphi$ - функция, которая определялась на прошлой лекции, а $\psi$ - обратная ей. $\psi$ - биекция, рассматриваем $f\circ \psi$. Посмотрим на $\psi([0, \beta])=[a,b]$, тогда для любых $c, d\in [0, b]$ $V_{f\circ\psi}([c, d])=d-c$.



Естественная параметризация гладкого пути практически не отличается от того, что мы уже рассматривали за одним небольшим исключением. 
\[
    \varphi(x)=V_f([a, x])=\int_a^x\vert f'(s)\vert ds=\int_a^x\sqrt{f_1'^2+\ldots+f_n'^2}ds,
\]
причём предпоследнее вырежение равно $\vert (f_1', \ldots, f_n')\vert$, а под корнем все функции от $s$. Рассмотрим опять $\psi$, и как выглядит вектор $f(\psi(x))=(f_1(\psi(x)), \ldots, f_n(\psi(x)))$, рассмотрим его производную, берём покоординатно: $f'(\psi(x))=(f_1'(\psi(x)), \ldots, f_n'(\psi(x)))$. Но $\psi'(x)=\frac{1}{\varphi(\psi(x))}$, тогда $\varphi(s)=\vert f'(s)\vert$, а также $\vert f'(\psi(x))\vert=1$.

\begin{remark}
    Если $f$ - гладкая на $[a, b)$ и существует $\int_a^b|f'(s)|ds$, тогда выполнено то же самое, просто $\varphi(x)=\int_a^x|f'(s)|ds$.
\end{remark}

Перейдём теперь к тригонометрии. Рассмотрим окружность $x^2+y^2=1$, мы планируем её обходить (то есть, через каждую точку по разу, с одинаковой скоростью, и так далее). Введём попутно также комплексное обозначение (мы не будем заниматься комплексным анализом, просто это удобно). Отождествим $\RR^2$ с $\CC$ понятно каким образом. Тогда какое вращение мы хотим? Мы хотим найти функцию $\Gamma:\RR\rightarrow \mathbb{T}=\{z:|z|=1 \text{ или } x^2+y^2=1, z=x+iy\}$, а хотим потребовать также следующее:

\begin{itemize}
    \item $\Gamma\in C^1$ (гладкая),
    \item $\Gamma(0)=1, \: \Gamma'(0)=i$ (место старта и начальная скорость, с которой мы идём), 
    \item $|\Gamma'(t)|=1$ для любого $t$ (постоянная скорость 1).
\end{itemize}

Сформулируем теорему:\\

\begin{theorem}
    Функция с данными свойствами существует и единственна.
\end{theorem}

\begin{proof}
    $\Gamma(t)\in\mathbb{T}$ тогда и только тогда, когда $\Gamma(t)\overline{\Gamma(t)}=1$. Продифференцируем последнее, получим
    \[
        \Gamma'(t)\overline{\Gamma(t)}+\Gamma(t)\overline{\Gamma'(t)}=0, 
    \]
    что также равно 
    \[
        2\Real(\overline{\Gamma'(t)}\Gamma(t))=0.
    \]
    То есть, мы получили, что $\Gamma(t)\overline{\Gamma'(t)}=ih(t)$, $h(t)\in\RR$. Применим теперь оставшееся неиспользованное условие: $|\Gamma(t)|=1$, а чтобы параметризация была естественна, $|\Gamma(t|$ должно быть равно 1. То есть, $h(t)=\pm1$. Подставим теперь нуль и получим, что функция в этой точке должна быть равна единице, а производная - $i$. Тогда остаётся один вариант: $ h(t)\equiv 1$. \ 

    Посмотрим теперь ещё раз на начальные уравнение: $\Gamma'(t)\overline{\Gamma(t)}\equiv i$, то есть, 
    
    \begin{equation}
        \Gamma'(t)=i\Gamma(t).
    \end{equation}
    
    Таким образом, мы уже пришли к тому, что если вращение существует, то оно должно удовлетворять последнему уравнению, а также $\Gamma(0)=1$. Это означает, что вращение, которое мы получаем, будет дифференцируемо бесконечно много раз. \ 

    Пока что, казалось бы, ни единственности, ни существования, однако из последних утверждений легко получается единственность. Пусть у нас есть $\Gamma_{1,2}$ - два простых вращения. Дначит, они оба удовлетворяют (1). Тогда завайте запишем их частное через сопряжённые и возьмём производную: $ \biggl(\Gamma_1(t)\overline{\Gamma_2(t)}\biggr)'=\Gamma_1'(t)\overline{\Gamma_2(t)}+\Gamma_1(1)\overline{\Gamma_2'(t)}$, что равно $i\Gamma_1\overline{\Gamma_2}+\Gamma_1\overline{i\Gamma_2}=0$. \ 

    Таким образом, мы получили, что $\Gamma_1\Gamma_2=\const$, но поскольку $\Gamma(0)=1$, то эта константа и равна единице. То есть, $\Gamma_1\overline{\Gamma_2}=1$, следовательно, эти функции равны, единственность доказана. \ 

    Докажем теперь существование. Предъявим сначала произвольную параметрицацию окружности, а затем постараемся сделать в ней замену переменной, чтобы получить хорошую функцию (которая должна быть, конечно, гладкой). Давайте параметризуем верхнюю половину $\mathbb{T}$ самым естественным образом: примем $x=t, \: y=\sqrt{1-t^2}, \ -1\leq t\leq 1$ (двигаемся по часовой стрелке). Теперь нам нужно отпараметризовать нижнюю половину, возьмём для этого $x=-t, \: y=-\sqrt{1-t^2}, \: -1\leq t\leq 1$, двигаться мы теперь будем по нижней половине, но в другом направлении, то есть, одну из половин нужно перевернутьт и ''склеить'' в один целостный проход. Тогда в нижней половине ''сдвинем'' рассмотрение на $1\leq t\leq 3$, и преобразуем: $y=-\sqrt{1-(2-t)^2}$. \ 

    Осталось проверить, что полученная функция гладкая. Вообще, это почти везде очевидно, кроме $\pm 1$, это и проверим. $f(t)=(t, \sqrt{1-t^2})$, а вектор $f'(t)=(1, \frac{-t}{\sqrt{1-t^2}})$. Функция $\varphi(x)$ на $(-1, 1)$ выглядит как
    \[
        \int_{-1}^x|f'(s)|ds=\int_{-1}^x\sqrt{1+\frac{t^2}{1-t^2}}dt=\int_-1^x\frac{dt}{\sqrt{1-t^2}}.
    \]
    Функция $\varphi(x)$ - возрастающая биекция, значит, мы можем посмотреть на обратную функцию $\psi(x)=\varphi^-1(x)$. Рассмотрим теперь для $x\in(-1, 1)$,
    \[
         (f^{-1}(\psi(x)))'=(f_1'(\psi(x))\psi'(x), f_2'(\psi(x))\psi'(x)).
    \]
    Тогда, так как $\psi'(x)=\frac{1}{\varphi'(\varphi(x))}$, это также и равно $\sqrt{1-\psi^2(x)}$, что также равно 
    \[
    (\psi'(x), \frac{-\psi(x)}{\sqrt{1-\psi(x)}}\sqrt{1-\psi^2(x)}).
    \]
    В последнем также можно сократить числитель и знаменатель. Итого, $f(\psi(x))$ - гладкая на $(-1, 1)$, и более того, если $x\rightarrow\pm 1$, производная имеет конечный предел. Получается, дифференцируема на интервале, и производная имеет предел в крайних точках, тогда она в них также дифференцируема. Таким образом, для верхней половины мы всё показали, для нижней - аналогично, всего лишь с линейной заменой. \ 


\end{proof}

После доказательства теоремы, можно, наконец, ввести определения:

\begin{defn}
    \[
        \cos(x)=\Real(\Gamma(x)), 
    \]
    \[
        \sin(x)=\Imf(\Gamma(x)).
    \]
\end{defn}

Далее уже можно поговорить о бесконечной дифференцируемомти и формуле Муавра, этим, вместе с доказательством, что мы нашли привычные функции, мы, кажется, и планируем заниматься далее.

\section{Лекция 3.}

Для начала, закончим с тригонометрией. Мы научились строить синус и косинус через вращение окружности. Немного не помню, обговаривали ли мы это на прошлой лекции, но Юрий Сергеевич кратуо цпомянул, что мы можем разложить $\Gamma(x)$ в ряд Тэйлора в $\sum_{n=0}^\infty\frac{(ix)^n}{n!}$ в силу свойства $\Gamma'(x)=i\Gamma(x)$ и того, что остаточный член в форме Лагранжа будет стремиться к нулю при стремлении $n$ к бесконечности. \ 

Тогда 
\[
    \cos x = \Real \Gamma(x) \Rightarrow \sum_{n=0}^\infty\frac{x^{2n}}{(2n)!}(-1)^n
\]
и аналогично синус по нечётным степеням. \ 

Мнимая экспонента обладает свойствами, аналогичным обыкновенной экспоненте, поэтому покажем, что $\Gamma(x+y)=\Gamma(x)\Gamma(y)$. Рассмотрим $\Gamma(x+y)\overline{\Gamma(y)}$ - функцию от $x$, а $y$ - параметр. Это - некоторый обход окружности, который также удовлетворяет всем нормировочным условиям. $\varphi(0)=1$, $|\varphi'(x|=1$, и, наконец, $\varphi'(0)=\Gamma'(0)= i$. \ 

Теперь все прекрасные формулы косинуса и синуса суммы и разностей легко выводятся из доказанной формулы. Через мнимую экспоненту запишем: $e^{i(x+y)=e^{ix}\cdot e^{iy}}$, а там уже просто надо посмотреть на мнимые и действительные части. \ 

Из полученных свойств получим, что $\Gamma(x)\Gamma(-x)=\Gamma(0=1)$, тогда $\Gamma(-x)=\overline{\Gamma(x)}$, откуда мы получаем чётность косинуса и нечётность синуса. \ 

Можно упомянуть и формулу муавра. Распишем 
\[
    \cos(x)=\frac{e^{ix}+e^{-ix}}{2}, \: \sin(x)=\frac{e^{ix}-e^{-ix}}{2i}, 
\]
это формулы Муавра. Также можно получить и периодичность, это, вообщем-то очевидно и завершает наш разговор об элементарных функциях. \\

Перейдём теперь к многочерному анализу. Мы бы хотели точно также уметь анализировать функции и делать всё то, что мы уже умеем делать для одномерных функций, в том числе, решать экстремальные задачи. Нас интересуют функции $f:\RR^m\rightarrow \RR^n$. \ 

Начнём с того, что в евклидовом пространстве $\RR^m$ расстояние задаётся как 
\[
    d(x, y)=\sqrt{\sum_{k=1}^m(x_k-y_k)^2}=||x-y||.
\]
И если у нас имеется точка $x=(x_1, \ldots, x_m)$, то её норма есть $||x||=\sqrt{\sum_{k=1}^mx_k^2}$. Вообще, норму можно задать как угодно, если она удовлетворяет таким свойствам: 

\begin{itemize}
    \item норма - функция $\RR^m\rightarrow \RR_{+, 0}$, 
    \item $||x||=0 \: \Leftrightarrow \: x\equiv (0,\ldots, 0)$, 
    \item $||\alpha x||=|\alpha|\cdot||x||$, $\alpha\in \RR$, 
    \item $||x+y||\leq ||x||+||y||$. 
\end{itemize}

Разберёмся с понятием \textit{гладкости}. Для начала, алгебраически. Пусть у нас есть функция нескольких переменных $f:\RR^m\rightarrow \RR$, $f(x_1, \ldots, x_m)$. 

\begin{defn}
    $f$ \textit{дифференцируема} в точке $(x_1, \ldots, x_m)$, если $f(y)=f(x)+L(y-x)+o(||x-y||)$, где $L$ - линейное отображение $\RR^m\rightarrow \RR$, причём однородное, то есть, $L(0)=0$. 
\end{defn}

\begin{defn}
    Это линейное отображение $L$ называется \textit{дифференциалом} в точке $x$.
\end{defn}

На топологии мы доказывали, что в конечномерном пространстве различные норма липшицево-эквивалентны, потому мы просто во всех рассуждениях будем испоьзовать именно евклидовы нормы, потому что они удобные. А теперь перейдём к базовым свойствам. 

\begin{remark}
    $L$ - единственно.
\end{remark}

\begin{remark}
    Если у нас есть две функции: $f$ и $g$, то дифференциал $\alpha f+\beta g$, $\alpha, \: \beta \in \RR$ есть $\alpha L_1+\beta L_2$, где $L_1$ и $L_2$ - дифференциалы $f$ и $g$. 
\end{remark}

Рассмотрим теперь отображение общего вида: $f:\RR^m\rightarrow \RR^n$. Тогда 
\begin{defn}
    (Гладкость). $f(y)=f(x)+L(y-x)+o(||x-y||)$, где $L$ - линейное отображение $\RR^m\rightarrow \RR^n$, $L(x+y)=L(x)+L(y)$. $o$-малое в данном случае можно понять как 
    \[
        \frac{f(y)-f(x)-L(y-x)}{||y-x||}\rightarrow 0,
    \]
    то есть, элемент $\RR^n$ стремится у нулю, но для удобства можно взять евклидову норму этого выражения.
\end{defn}

Какой вид имеет общее линейное отображение из $\RR^m\rightarrow \RR^n$? Естественно, это - матрица, это мы знаем из алгебры и умеем расписывать переход в тривиальном базисе. \ 

Перейдём к свойствам линейных отображений. Мы умеем их складывать, умножать, а также, совершать композиции в случае согласованности размерностей, которая соответствует перемножению матриц. \ 

Пусть теперь, опять же, у нас есть отображение $L: \RR^m\rightarrow \RR^n$, то $L(\RR^m)\subset \RR^n$ - подпространство, которое имеет размерность от $0$ до $n$, эту размерность мы понимаем как \textit{ранг} линейного отображения. Если же мы берём композицию линейных отображений, то ранг не может вырасти (куда растягивать-то). Также, легоко видеть, что если $m<n$, то $\dim(L(\RR^m))\leq m<n$. \ 

Зададимся теперь вопросом, какая существует естественная метрика на линейных отображениях $\RR^m\rightarrow \RR^n$. По сути, эти линейные отображения представляют собой евклидово пространство размерности $m\cdot n$. Задать на нём мы можем евклидову метрику: под корнем будут квадраты всех матричных элементов. Эта норма вычисляется проще, но зато гораздо менее естественна, чем следующая (например, относительно вопроса о композиции). $||L||=\sup_{||x||<1}||Lx||$, $x\in \RR^m$, $LX\in \RR^n$. Эта вещь конечна, так как она не превосходит $\sum_{k=1}^m ||Le_k||$, а также выполняются все свойства нормы. \ 

Геометрический смысл у данной нормы очень простой: мы смотрим, насколько сильно она растягивает расстояние в зависимости от направления. \ 

Завершаем лекцию несколькими переопределениями нормы: 
\begin{itemize}
    \item $\sup_{||x||<1}||Lx||$, 
    \item $\sup_{||x||\leq 1}||Lx||$, 
    \item $\sup_{||x||\neq 0}\frac{||Lx||}{||x||}$, 
    \item $\sup_{||x||<=}||Lx||$.
\end{itemize}

\section{Лекция 4.}

Продолжаем с операторами, пусть $A: \RR^n\rightarrow \RR^n$ - линейный, $||A||=\sup_{||x||\leq 1}||Ax||$ - норма, где $||x||$ - Евклидово. $A\cong \RR^{nm}$, так как можно выносить константу, не меньше нуля (притом равна тогда и только тогда, когда сам оператор - нуль), а также, норма суммы не превосходит сумму норм. 

\begin{defn}
    $||A||$ - \textit{операторная норма}, притом супремум всегда достигается. 
\end{defn}

Операторная норма есть самое большое по модулю собственное число. Предположим, что у $A$ есть $n$ различных $\lambda_i$ собственных чисел, у которых есть соответственные $x^i$ собственные векторы. Запишем тогда $x=\sum_{k=1}^n a_kx^k$, $Ax=\sum_{k=1}^n \lambda_k a_kx^k$, тогда $||Ax||\leq\max_k|\lambda_k|\cdot||x||$, но это мы объяснить не смогли. \ 

Однако разговор сейчас шёл о различных собственных числах, бывают же \textit{кратные} собственные числа. Что происходит? \ 

Важный момент, почему важна операторная норма. Пусть $A:\RR^n\rightarrow \RR^m$, $B:\RR^m\rightarrow \RR^k$, тогда $||BA||\leq ||B||\cdot||A||$, так как левая часть по определению равна $\sup_{||x||\leq 1 (в \RR^n)}\leq \sup_{||y||\leq||A||}||By||\leq ||B||\cdot||A||$. Заметим также две следующие вещи для линейного $A:\RR^n\rightarrow \RR^m$ равносильны: \ 

\begin{itemize}
    \item $\ker A=\{0\}$
    \item $||Ax||\geq \varepsilon ||x||, \exists \varepsilon >0$. 
\end{itemize}

\begin{proof}
    $\{x:||x||=1\}$ - единичная сфера в $\RR^n$. Пусть $f(x):x\rightarrow ||Ax||$, $f$ - непрерывная (?), $f\neq 0$ на единичной сфере, тогда $f\geq \varepsilon >0$, $||Ax||\geq \varepsilon||x||$, $||x||=1$. 
\end{proof}

Вообще, нам все эти операторы нужны для рассуждений о гладкости, сформулируем теорему: \\ 

\begin{theorem}
    $f: G\rightarrow \RR^m$, $G\subset \RR^n$ - открытое, $f$ - гладкая в окрестности $x^0$ (верхние индексы), $y^0=f(x^0)$, $g:V_{f(x^0)}\rightarrow \RR^k$, гладкая в $f(x^0)$, для $f$ и $g$ существуют линейные операторы $A$ ($x_00)$ и $B$ ($f(x_0)$). Тогда $g(f(x))$ - гладкое (?) отображение в $x_0$ с линейным оператором (?) $BA:\RR^n\rightarrow \RR^k$. 
\end{theorem}

\begin{proof}
    Мы знаем, что существует представление $f(x)=f(x^0)+A(x-x^0)+o(||x-x^0||)$. Применим $g$, получим 
    \begin{equation}
        g(f(x))=g(y^0+A(x-x^0)+o(||x-x^0||)).
    \end{equation}
        
    Также мы знаем, что $g$ гладкая, то есть, также представима в виде $g(y)=g(y^0)+B(y-y^0)+o(||y-y^0||)$, тогда приняв аргумент правой части $(1)$ за $y$, получим продолжение тождества: 
    \begin{equation}
        \begin{split}
            g(y^0)+B(A(x-x^0)+o(||x-x^0||))+o(A(x-x^0)+o(||x-x^0||)) = \\ 
            g(y^0)+BA(x-x^0)+o(||x-x^0||).
        \end{split}
\end{equation}
\end{proof}

Нам много чего хочется от анализа многих переменных, но тут всё, конечно, гораздо сложнее. Перейдём к \textit{частным производным}.

\begin{remark}
    $f:\RR^n\rightarrow \RR^m$ - гладкая в  $x^0$ тогда и только тогда, когда  при записи $(f_1(x_1, \ldots, x_n), \ldots, f_m(x_1, \ldots, x_n))$ $f_k$ - гладкая $\RR^n\rightarrow \RR$ для всех $k$ (можно написать доказательство). 
\end{remark}  

\begin{defn}
    \textit{Частная производная}. Пусть имеется $f:\RR\rightarrow \RR$, $f(x_1, \ldots, x_n)$, $x^0=(x_1^0, \ldots, x_n^0)$. Тогда частная производная по $x_k $, $f(x_1^0, \ldots, x_{k-1}^0, x, x_{k+1}^0, \ldots, x_m^0)=g(x), g'(x_k^0)$. $\frac{\partial f}{\partial x_k}\bigg|_{x^0}:=g'(x_k^0)=\lim_{\varepsilon\rightarrow 0}\frac{f(\ldots, x_k^0+\varepsilon, \ldots)-f(\ldots)}{\varepsilon}$. 
\end{defn}

Рассмотрим теперь \textit{производную по направлению}. Пусть направление задаётся $e\in\RR^n$, $||e||=1$, $f$ - дифференцируема по направлению $e$, если $g(t)=f(x^0+te)$, $t\in\RR$ и существует $g'(0)$, то производная по направлению $e$ - $g'(0)=\lim_{t\rightarrow 0}\frac{f(x^0+te)-f(x^0)}{t}$.  

\section{Лекция 5.}

Введём несколько дополнительных терминологий. Пусть у нас есть отображение $f:\RR^n\rightarrow \RR^m$, $f=(f_1, \ldots, f_m)$, $\frac{\partial f_k}{\partial x_l}$, $1\leq k\leq m$, $1\leq l\leq n$, тогда \textit{матрица Якоби} выглядит как

\begin{equation*}
    \begin{matrix}
    \end{matrix}
\end{equation*}

\begin{theorem}
    Пусть у нас есть отображение $f:\RR^n\rightarrow \RR^m$, $V_{x_0}\rightarrow \RR^m$, причём существуют все частные производные в $V_{x^0}$ и они непрерывные в $x^0$. Тогда $f$ дифференцируема в точке $x^0$. 
\end{theorem}

\begin{proof}
    Для начала, мы можем полагать, что $m=1$, так как можно доказывать, по сути, покомпонентно. Пусть $x^0=(x_1^0, x_2^0, x_3^0)$ (докажем для 3, потом обсудим общий случай), ну а $x=(x_1, x_2, x_3)$. Нас интересует $f(x_1, x_2, x_3)-f(x_1^0, x_2^0, x_3^0)$. Действуем стандартным образом, будем двигать координаты по одной (так как все сразу двигать не можем). Меняя по одной координате, представим разности из частных производных. Разность равна 
    \[
        f(x_1, x_2, x_3)-f(x_1^0, x_2, x_3)+f(x_1^0, x_2, x_3)-f(x_1^0, x_2^0, x_3^0)
    \]
    Разбивается в две подряд идещие разности, достаточно удобные, но последняя всё равно ''не айс'':
    \[
        f(x_1, x_2, x_3)-f(x_1^0, x_2, x_3)+f(x_1^0, x_2, x_3)-f(x_1^0, x_2^0, x_3)+f(x_1^0, x_2^0, x_3)-f(x_1^0, x_2^0, x_3^0)
    \]
    Теперь уже три удобные разности, так и запишем равенство далее:
    \begin{equation*}
        \begin{aligned}
            &= \frac{\partial f}{\partial x_1}\bigg|_{(\xi_1, x_2, x_3)_{\xi\in [x_1^0, x_1]}}(x_1-x_1^0)+\frac{\partial f}{\partial x_2}\bigg|_{(x_1, \xi_2, x_3)}(x_2-x_2^0)+\frac{\partial f}{\partial x_3}\bigg|_{(x_1, x_2, \xi_3)}(x_3-x_3^0) = \\
            &= \frac{\partial f}{\partial x_1}\bigg|_{(x_1^0, x_2^0, x_3^0)}(x_1-x_1^0)+\frac{\partial f}{\partial x_2}\bigg|_{(x_1^0, x_2^0, x_3^0)}(x_2-x_2^0)+\frac{\partial f}{\partial x_3}\bigg|_{(x_1^0, x_2^0, x_3^0)}(x_3-x_3^0) + \\
            &+ \biggl(\frac{\partial f}{\partial x_1}\bigg| - \frac{\partial f}{\partial x_1}\biggr)(x_1-x_1^0)+\biggl(\frac{\partial f}{\partial x_2}\bigg| - \frac{\partial f}{\partial x_2}\biggr)(x_2-x_2^0)+\biggl(\frac{\partial f}{\partial x_3}\bigg| - \frac{\partial f}{\partial x_3}\biggr)(x_3-x_3^0)
        \end{aligned}
    \end{equation*}

    Последние три слагаемых - остаток, $R(x)$, тогда  $\forall \varepsilon >0$, $\exists \delta$ $||x-x^0||<\delta$, $|R(x)|<\varepsilon ||x-x^0||$. 


\end{proof}

\begin{theorem}
    Пусть $f:\RR^n\rightarrow \RR$, $f$ - гладкая на $G$ - открытое(???). Я нихуя не могу прочитать, что тут написано.
\end{theorem}

\begin{proof}
    $\grad f = (\frac{\partial f}{\partial x_1} ,\ldots, \frac{\partial f}{\partial x_n})$, $f$ - локальный максимум $f$, $x^0$, $\frac{\partial f}{\partial x_k}\bigg|_{x_0}\neq 0$. 
    \begin{equation*}
        \begin{split}
            (x_1^0, \ldots, x_{k-1}^0, x, x_{k+1}^0, \ldots, x_n^0)- (x_1^0,\ldots, x_m^0)= \\
            \frac{\partial f}{\partial x_k}\bigg|_{x^0}(x_k-x_k^0)+o(|x_k-x_k^0|),
        \end{split}
    \end{equation*}
    причём первое слагаемое не нуль.
\end{proof} 
 
Нам бы ещё хотелось иметь теорему об обратном отображении. \\

\begin{theorem}
    (Об обратном отображении). Пусть $f: G\rightarrow \RR^n$, $G$ - открыто в $\RR^n$, у $f$ есть гладкие частные производные (???), $f$ - в точке $x^0$ дифференцируема $A$, $A$ - (сука??????????). Тогда $V_{x^0}$ $\exists g $ - гладкая, (?????) $f(x^0)$, $g(f(x))=x$, $g$ - дифференцируема в $f(x^0)$ $\Rightarrow$ $A^{-1}$. 
\end{theorem}

\begin{proof}
    $(f^{-1}(x))' = \frac{1}{f'(f^{-1}(x))}$ - вспомнили, а теперь - к доказательству. \ 

    \textbf{Утв. 1.} $f$ - гладкая в окрестности точки $x^0$ с непрерывными частными производными, тогда $f$ липшицева, то есть, $|f(x)-f(y)|\leq C||x-y||$. Если мы зафиксируем точку $x$, то $|f(x)-f(y)|\leq(||A||+\varepsilon)||x-y||$ $\forall \varepsilon >0$, $A=A_x$. $||A_x||\leq\sum_{k=1}^n\bigg|\frac{\partial f}{\partial x_k}\bigg|_x\bigg|$. \ 

    \textbf{Утв. 2.} Если к тому же $\Ker (A)=\{0\}$, то $f$ - билипшицево (в окрестности $x^0$), $C_2||x-y||\leq |f(x)-f(y)|\leq C_1||x-y||$. Докажем и его. $f(y)= f(x)+A_x(y-x)+o(||x-y||)$, тогда $||A_{x^0}z||\geq \varepsilon ||z||$, $\forall z\in \RR^n$, $||A_xz||$ - $A_xz= A_{x^0}z+(A_x-A_{x^0})z$. Первый элемент не меньше $\varepsilon ||z||$, а $||A_x-A_{x^0}||$ стремится к 0 в окрестности этой точки, тогда 
    \[
        |f(y)-f(x)|=|A_x(y-x)+o(||x-y||),
    \]
    но каждый из них можно ограничить снизу $\frac{\varepsilon}{2}||x-y||$. \ 

    Тогда $f:\RR^n\rightarrow \RR^m$, $\Ker A= \{0\}$, тогда $n\leq m$. \ 

    Итого, у нас есть отображение $f:f(x)=f(x^0)+A(x-x^0)+o(||x-x^0||)$. Рассмотрим шарик $B_r(x^0)=\{x:||x-x^0||<r\}$, $f(B_r(x^0))$, $f$ - биективна. Проверим, что он содержится в каком-то $B_{r'}(f(x^0))$. \ 

    \textbf{Утв. 3.} В условиях теоремы для любого $r$ существует $r'$, $f(\overline{B_r(x^0)})\supset \overline{B_{r'}(f(x^0))}$. Для любого $y\in B_{r'}(f(x^0))$ $f(x)=y$, хотим найти $x$. $F(x)= ||f(x)-y||^2$, гладкая в окрестности $x^0$. Минимум этой функции где-то достигается (непрерывная на компакте). $F(x^0)= ||f(x^0)-y||^2\leq r'^2$, тогда минимум не может достигаться на границе, так как иначе $||x-x^0||=r$. Тогда с одной стороны $||f(x)-y||^2=||f(x)-f(x^0)+f(x^0)-y||^2$. $f$ билипшицева, поэтому разность первых двух можно оценить чнизу $\varepsilon||x-x^0||$, а разность последних двух можно ограничить сверху $r'^2$, то есть, вся эта вещь как минимум $r'^2$. \ 

    Пусть $w$ - минимум $F(x)$ на $B_r(x^0)$, тогда $\grad F(w)=0$,  $=||f(x)-y||^2 = \sum_{k=1}^n(f_k(x)-y_k)^2$, 
    \[
        \frac{\partial F}{\partial x_l}\bigg|_w = \sum_{k=1}^n\frac{\partial f_k}{\partial x_l}\bigg|_w 2(f_k(x)-y_k), 
    \]
    Ну под конец не успел, слишком долго расшифровывать.
\end{proof}

\section{Лекция 6.}

(пропущено продолжения доказательства с прошлой лекции)\ 

Попытаемся обобщить Формулу Тейлора для многих переменных. Для начала, разберёмся с тем, как дифференцировать композицию функций многих переменных. Пусть $f:\RR^n\rightarrow \RR^m$, $g:\RR^m\rightarrow \RR^k$, $f$ - гладкая в $x^0$, $g$ - гладкая в $f(x^0)$, тогда $g(f(x^0))$ - гладкая в $x^0$, дифференциал - $BA$. 

\begin{exl}
    $f:\RR^n\rightarrow \RR$, $f(x_1, \ldots, x_n)$, $g_k= g_k(x_1, \ldots, x_n)$ $(1\leq k\leq n)$, $g=(g_1, \ldots, g_n)$. Тогда $f(g_1(x_1, \ldots, x_n), \ldots, g_n(x_1, \ldots, x_n))=F(x_1, \ldots, x_n)$, и 
    
\begin{equation*}
    \begin{aligned}
            \frac{\partial F}{\partial x_1}\bigg|_{\tilde{x}} & = \lim_{\varepsilon \rightarrow 0}\frac{f(g_1(x_1+\varepsilon, \ldots), \ldots, g_n(x_1+\varepsilon, \ldots))- f(\ldots)}{\varepsilon} = \\
            & = \lim_{\varepsilon\rightarrow 0}\frac{f(g_1(x_1, \ldots, m_n)+\varepsilon\frac{\partial g}{\partial x_1}+o(\varepsilon), \ldots)-f(g(\ldots), \ldots)}{\varepsilon} = \\ 
            & = \lim\frac{\varepsilon\frac{\partial f}{\partial x_1}\bigg|_{g_1(x_1, \ldots, x_n)}\cdot\frac{\partial g}{\partial x_1}+\varepsilon\frac{\partial f}{\partial x_2}\frac{\partial g_2}{\partial x_1}+\ldots+\varepsilon\frac{\partial f}{\partial x_n}\frac{\partial g_n}{\partial x_1}+o(\varepsilon)}{\varepsilon} = \\ 
            & = \sum_i \frac{\partial f}{\partial x_i}\frac{\partial g_i}{\partial x_1} =^? \sum_i \frac{\partial f}{\partial g_i}\frac{\partial g_i}{\partial x_1}
    \end{aligned}
\end{equation*}
    $f=(\frac{\partial f}{\partial x_1}, \ldots, \frac{\partial f}{\partial x_n})$, $BA=\biggl(\sum_{k=1^n}^n\biggr)$
\end{exl}

\begin{exl}
    $f(e^{x_1+x_2+x_3}, x_1-x_2+x_3, x_1x_3) = F(x_1, x_2, x_3)$. Тогда 
    \[
        \frac{\partial F}{\partial x_2}= \frac{\partial f}{\partial x_1}\cdot e^{x_1+x_2+x_3}+\frac{\partial f}{\partial x_2}(-1). 
    \]
\end{exl}

Формула Лагранжа. Пусть $f:\RR^n\rightarrow \RR$, $(x_1, \ldots, x_n)$, $(y_1, \ldots, y_n)$, $f(y_1, \ldots, y_n)- f(x_1, \ldots, x_n)$. \ 

Путь $x(t)= x+th$, $0\leq t\leq 1$, $h=y-x$ (покоординатно). Тогда $\varphi(t) := f(x+th)=f(x_1+t(y_1-x_1), \ldots, x_n+t(y_n-x_n))= f(x_1+th_1, \ldots, x_n+th_n)$, $f(y)-f(x)= \varphi(1)-\varphi(0)= \varphi'(\xi)$, $\xi\in\in[0, 1]$, 
\[
    \varphi'(t)= \frac{\partial f}{\partial x_1}\bigg|_{x(t)}(y_1-x_1)+\ldots+\frac{\partial f}{\partial x_n}\bigg|_{x(t)}(y_n-x_n)= (\grad f, y-x). 
\]
Таким образом, формула Лагранжа: $f(y)-f(x)=(\grad f|_\xi, y-x)$, $\xi\in[x, y]$. \ 

Получим ещё одно крутое обобщение:
\[
    \varphi'(0)=\frac{\partial f}{\partial x_1}\bigg| (y_1-x_1)+\ldots +\frac{\partial f}{\partial x_n}\bigg|(y_n-x_n), 
\]

А теперь возьмём производную ещё раз. 
\[
    \varphi''(t)= (\varphi'(t))'= \sum_{k=1}^n\frac{\partial f}{\partial x_1 \partial x_k}(y_k-x_k)(?)=?
\]

(не закончено и плохо составлено)




\end{document}