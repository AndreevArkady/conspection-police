\documentclass[a4paper,100pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[unicode, pdftex]{hyperref}
\usepackage{cmap}
\usepackage{mathtext}
\usepackage{multicol}
\setlength{\columnsep}{1cm}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools}
\usepackage{icomma}
\usepackage{euscript}
\usepackage{mathrsfs}
\usepackage{geometry}
\usepackage[usenames]{color}
\hypersetup{
     colorlinks=true,
     linkcolor=magenta,
     filecolor=green,
     citecolor=black,      
     urlcolor=cyan,
     }
\usepackage{fancyhdr}
\pagestyle{fancy} 
\fancyhead{} 
\fancyhead[LE,RO]{\thepage} 
\fancyhead[CO]{\hyperlink{t2}{к списку объектов}}
\fancyhead[LO]{\hyperlink{t1}{к содержанию}} 
\fancyhead[CE]{текст-центр-четные} 
\fancyfoot{}
\newtheoremstyle{indented}{0 pt}{0 pt}{\itshape}{}{\bfseries}{. }{0 em}{ }

%\geometry{verbose,a4paper,tmargin=2cm,bmargin=2cm,lmargin=2.5cm,rmargin=1.5cm}

\title{Матанализ. Конспект 2 сем.}
\author{Мастера Конспектов\\ \\ (по материалам лекций Белова Ю. С.,\\ а также других источников)}
\date{16 февраля 2021 г.}

\theoremstyle{indented}
\newtheorem{theorem}{Теорема}
\newtheorem{lemma}{Лемма}

\theoremstyle{definition} 
\newtheorem{defn}{Определение}
\newtheorem{exl}{Пример(ы)}

\theoremstyle{remark} 
\newtheorem{remark}{Примечание}
\newtheorem{cons}{Следствие}
\newtheorem{stat}{Утверждение}

\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Tors}{Tors}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Imf}{Im}
\DeclareMathOperator{\Real}{Re}
\DeclareMathOperator{\cont}{cont}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\ev}{ev}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\chard}{char}
\DeclareMathOperator{\CC}{\mathbb{C}}
\DeclareMathOperator{\ZZ}{\mathbb{Z}}
\DeclareMathOperator{\RR}{\mathbb{R}}
\DeclareMathOperator{\NN}{\mathbb{N}}
\DeclareMathOperator{\PP}{\mathbb{P}}
\DeclareMathOperator{\FF}{\mathcal{F}}
\DeclareMathOperator{\Rho}{\mathcal{P}}
\DeclareMathOperator{\codim}{codim}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\const}{const}
\begin{document}

\newcommand{\resetexlcounters}{%
  \setcounter{exl}{0}%
} 

\newcommand{\resetremarkcounters}{%
  \setcounter{remark}{0}%
} 

\newcommand{\reseconscounters}{%
  \setcounter{cons}{0}%
} 

\newcommand{\resetall}{%
    \resetexlcounters
    \resetremarkcounters
    \reseconscounters%
}

\maketitle 

\newpage

\hypertarget{t1}{Некоторые} записи по матанализу.
\tableofcontents

\newpage


\section{Лекция 1.}

В этом чеместре мы будем занимать анализом функций от многих переменных, то есть,  $f:\RR^n\rightarrow \RR^m$,  и если $m=1$, то такая функция называется функцией многих переменных. \ 

\begin{defn}
    \textit{Кривые в $\RR^n$} - непрерывное отображение $f:[a, b]\rightarrow \RR^n$.
\end{defn}

Основная проблема состоит в том, что образ может выглядеть очень и очень сложно, потому нам хотелось бы более точно понять, как всё это устроено. Потому начнём рассматривать \textit{спрямляемые кривые}, то есть, кривые с конечной длиной. Введём следующее определение: 

\begin{defn}
    \textit{Вариация функции} - $V_f([a, b])=\sup_{a=x_0\leq x_2\leq \ldots\leq x_n=b} \sum_{k=0}\vert f(x_{k+1})-f(x_k)\vert$. 
\end{defn}

$(x-y)$ - евклидово расстояние.

\begin{stat}
    Если $f:\RR\rightarrow \RR$ монотонна, то $V_f([a, b])=\vert f(a)-f(b)\vert $.
\end{stat}

\begin{stat}
    $V_f([a, b])=0 \: \Leftrightarrow \: f=\const$.
\end{stat}

\begin{stat}
    $V_{f+g}\leq V_f+V_g$.
\end{stat}

\begin{stat}
    $V_f$ аддитивна на промежутке: $a\leq b\leq c$, тогда $V_f([a, c])=V_f([a, b])+V_f([b, c])$. 
\end{stat}

\begin{defn}
    Вариация ограничена, если $V_f<\infty $ на $[a, b]$.
\end{defn}

\begin{lemma}\
    
    \begin{itemize} 
        \item $\RR\rightarrow \RR$, $f_1$ и $f_2$ монотонны, тогда $f_1-f_2$ имеют ограниченную вариацию.
        \item $f$ имеет ограниченную вариацию тогда и только тогда, когда $f=f_1-f_2$ на отрезке $[a, b]$, причём эти две функции монотонно возрастают.
    \end{itemize}
\end{lemma}

\begin{proof}
    Пусть у нас есть $f$, а также $V_f([a, b])<\infty$. Рассмотрим $\varphi(x)=V_f([a, x])$. $\varphi$ определа корректно, причём возрастает. $f=\varphi-(\varphi-f)$, скажем, что $(\varphi-f)=h$, тогда $h(x)\leq h(y)$ при $x\leq y$. Но это нетрудно показать, $\varphi(x)-f(x)\leq \varphi(y)-f(y)$ равносильно $f(y)-f(x)\leq \varphi(y-\varphi(x))=V_f([x, y])$.
\end{proof}

По сути, если понимать определение вариации геометрически, то это просто длина кривой на отрезке. Перейдём теперь к способам обхода кривой.\\

\begin{lemma}
    Пусть $g:[a, b]\rightarrow [c, d]$ - непрерывная биекция (тогда и монотонная). Тогда $V_f[c, d]=V_{f\circ g}([a,b])$.
\end{lemma}

\begin{proof}
    Левая и правая части равны соответственно $\sup \sum_{k=0}^{n-1}\vert f(x_{k+1})-f(x_k)\vert$ и $\sup \sum_{k=0}^{n-1}\vert f(g(y_{k+1}))-f(g(y_k))\vert$. Это, очевидно, одно и то же.
\end{proof}

Теперь стоит задаться вопросом: а когда же это $V_f$ (или же, длину кривой) можно посчитать. Если $f$ - гладкая функция (гладкая покоординатно $f_k$). $f:=[a, b]\rightarrow \RR^n$, $f=(f_1, \ldots, f_n)$, $f_k:[a, b]\rightarrow \RR$. Тогда
\[
    V_f([a, b])=\int_a^b\sqrt{(f_1')^2(x)+\ldots+(f_n')^2(x)}\: dx.
\]
Рассмотрим
\begin{eqnarray*}
    \sup_{a=x_0, \ldots, x_n=b}\sum_{k=0}^{n-1}\sqrt{(f_1(x_{k+1})-f_1(x_k))^2+\ldots+f_n(x_{k+1})-f_n(x_k))^2} = \\ 
    = \sum_{k=0}^{n-1}(x_k+1-x_k)\sqrt{f_1'^2(\xi_{1, k})+\ldots+f_n'^2(\xi_{n, k}))}
\end{eqnarray*}

Если $f_i$ непрерывна, то $f_i^2$ равномерно непрерывна. $f_i'^2(\xi_{i, k})\leq \min_{[x_k, x_{k+1}]}f_i'^2+\varepsilon^2$ (для достаточно мелких разбиений и любого эпсилон, большего нуля). Тогда можно получить верхнюю оценку: $\leq \sum_{k=0}^{n-1}(x_{k+1}-x_k)\sqrt{\sum_{l=1}^n \min_{[x_k]}(f_l'^2)}+\varepsilon \sqrt{n}(b-a)\leq \int_a^b\sqrt{\dots}+\varepsilon \sqrt{n}(b-a)$ (устремляем разбиение к бесконечно малому). А затем делаем аналогично снизу и получаем требуемое равенство.

\section{Лекция 2.}

Пусть $\varphi$ - функция, которая определялась на прошлой лекции, а $\psi$ - обратная ей. $\psi$ - биекция, рассматриваем $f\circ \psi$. Посмотрим на $\psi([0, \beta])=[a,b]$, тогда для любых $c, d\in [0, b]$ $V_{f\circ\psi}([c, d])=d-c$.



Естественная параметризация гладкого пути практически не отличается от того, что мы уже рассматривали за одним небольшим исключением. 
\[
    \varphi(x)=V_f([a, x])=\int_a^x\vert f'(s)\vert ds=\int_a^x\sqrt{f_1'^2+\ldots+f_n'^2}ds,
\]
причём предпоследнее вырежение равно $\vert (f_1', \ldots, f_n')\vert$, а под корнем все функции от $s$. Рассмотрим опять $\psi$, и как выглядит вектор $f(\psi(x))=(f_1(\psi(x)), \ldots, f_n(\psi(x)))$, рассмотрим его производную, берём покоординатно: $f'(\psi(x))=(f_1'(\psi(x)), \ldots, f_n'(\psi(x)))$. Но $\psi'(x)=\frac{1}{\varphi(\psi(x))}$, тогда $\varphi(s)=\vert f'(s)\vert$, а также $\vert f'(\psi(x))\vert=1$.

\begin{remark}
    Если $f$ - гладкая на $[a, b)$ и существует $\int_a^b|f'(s)|ds$, тогда выполнено то же самое, просто $\varphi(x)=\int_a^x|f'(s)|ds$.
\end{remark}

Перейдём теперь к тригонометрии. Рассмотрим окружность $x^2+y^2=1$, мы планируем её обходить (то есть, через каждую точку по разу, с одинаковой скоростью, и так далее). Введём попутно также комплексное обозначение (мы не будем заниматься комплексным анализом, просто это удобно). Отождествим $\RR^2$ с $\CC$ понятно каким образом. Тогда какое вращение мы хотим? Мы хотим найти функцию $\Gamma:\RR\rightarrow \mathbb{T}=\{z:|z|=1 \text{ или } x^2+y^2=1, z=x+iy\}$, а хотим потребовать также следующее:

\begin{itemize}
    \item $\Gamma\in C^1$ (гладкая),
    \item $\Gamma(0)=1, \: \Gamma'(0)=i$ (место старта и начальная скорость, с которой мы идём), 
    \item $|\Gamma'(t)|=1$ для любого $t$ (постоянная скорость 1).
\end{itemize}

Сформулируем теорему:\\

\begin{theorem}
    Функция с данными свойствами существует и единственна.
\end{theorem}

\begin{proof}
    $\Gamma(t)\in\mathbb{T}$ тогда и только тогда, когда $\Gamma(t)\overline{\Gamma(t)}=1$. Продифференцируем последнее, получим
    \[
        \Gamma'(t)\overline{\Gamma(t)}+\Gamma(t)\overline{\Gamma'(t)}=0, 
    \]
    что также равно 
    \[
        2\Real(\overline{\Gamma'(t)}\Gamma(t))=0.
    \]
    То есть, мы получили, что $\Gamma(t)\overline{\Gamma'(t)}=ih(t)$, $h(t)\in\RR$. Применим теперь оставшееся неиспользованное условие: $|\Gamma(t)|=1$, а чтобы параметризация была естественна, $|\Gamma(t|$ должно быть равно 1. То есть, $h(t)=\pm1$. Подставим теперь нуль и получим, что функция в этой точке должна быть равна единице, а производная - $i$. Тогда остаётся один вариант: $ h(t)\equiv 1$. \ 

    Посмотрим теперь ещё раз на начальные уравнение: $\Gamma'(t)\overline{\Gamma(t)}\equiv i$, то есть, 
    
    \begin{equation}
        \Gamma'(t)=i\Gamma(t).
    \end{equation}
    
    Таким образом, мы уже пришли к тому, что если вращение существует, то оно должно удовлетворять последнему уравнению, а также $\Gamma(0)=1$. Это означает, что вращение, которое мы получаем, будет дифференцируемо бесконечно много раз. \ 

    Пока что, казалось бы, ни единственности, ни существования, однако из последних утверждений легко получается единственность. Пусть у нас есть $\Gamma_{1,2}$ - два простых вращения. Дначит, они оба удовлетворяют (1). Тогда завайте запишем их частное через сопряжённые и возьмём производную: $ \biggl(\Gamma_1(t)\overline{\Gamma_2(t)}\biggr)'=\Gamma_1'(t)\overline{\Gamma_2(t)}+\Gamma_1(1)\overline{\Gamma_2'(t)}$, что равно $i\Gamma_1\overline{\Gamma_2}+\Gamma_1\overline{i\Gamma_2}=0$. \ 

    Таким образом, мы получили, что $\Gamma_1\Gamma_2=\const$, но поскольку $\Gamma(0)=1$, то эта константа и равна единице. То есть, $\Gamma_1\overline{\Gamma_2}=1$, следовательно, эти функции равны, единственность доказана. \ 

    Докажем теперь существование. Предъявим сначала произвольную параметрицацию окружности, а затем постараемся сделать в ней замену переменной, чтобы получить хорошую функцию (которая должна быть, конечно, гладкой). Давайте параметризуем верхнюю половину $\mathbb{T}$ самым естественным образом: примем $x=t, \: y=\sqrt{1-t^2}, \ -1\leq t\leq 1$ (двигаемся по часовой стрелке). Теперь нам нужно отпараметризовать нижнюю половину, возьмём для этого $x=-t, \: y=-\sqrt{1-t^2}, \: -1\leq t\leq 1$, двигаться мы теперь будем по нижней половине, но в другом направлении, то есть, одну из половин нужно перевернутьт и ''склеить'' в один целостный проход. Тогда в нижней половине ''сдвинем'' рассмотрение на $1\leq t\leq 3$, и преобразуем: $y=-\sqrt{1-(2-t)^2}$. \ 

    Осталось проверить, что полученная функция гладкая. Вообще, это почти везде очевидно, кроме $\pm 1$, это и проверим. $f(t)=(t, \sqrt{1-t^2})$, а вектор $f'(t)=(1, \frac{-t}{\sqrt{1-t^2}})$. Функция $\varphi(x)$ на $(-1, 1)$ выглядит как
    \[
        \int_{-1}^x|f'(s)|ds=\int_{-1}^x\sqrt{1+\frac{t^2}{1-t^2}}dt=\int_-1^x\frac{dt}{\sqrt{1-t^2}}.
    \]
    Функция $\varphi(x)$ - возрастающая биекция, значит, мы можем посмотреть на обратную функцию $\psi(x)=\varphi^-1(x)$. Рассмотрим теперь для $x\in(-1, 1)$,
    \[
         (f^{-1}(\psi(x)))'=(f_1'(\psi(x))\psi'(x), f_2'(\psi(x))\psi'(x)).
    \]
    Тогда, так как $\psi'(x)=\frac{1}{\varphi'(\varphi(x))}$, это также и равно $\sqrt{1-\psi^2(x)}$, что также равно 
    \[
    (\psi'(x), \frac{-\psi(x)}{\sqrt{1-\psi(x)}}\sqrt{1-\psi^2(x)}).
    \]
    В последнем также можно сократить числитель и знаменатель. Итого, $f(\psi(x))$ - гладкая на $(-1, 1)$, и более того, если $x\rightarrow\pm 1$, производная имеет конечный предел. Получается, дифференцируема на интервале, и производная имеет предел в крайних точках, тогда она в них также дифференцируема. Таким образом, для верхней половины мы всё показали, для нижней - аналогично, всего лишь с линейной заменой. \ 


\end{proof}

После доказательства теоремы, можно, наконец, ввести определения:

\begin{defn}
    \[
        \cos(x)=\Real(\Gamma(x)), 
    \]
    \[
        \sin(x)=\Imf(\Gamma(x)).
    \]
\end{defn}

Далее уже можно поговорить о бесконечной дифференцируемомти и формуле Муавра, этим, вместе с доказательством, что мы нашли привычные функции, мы, кажется, и планируем заниматься далее.

\section{Лекция 3.}

Для начала, закончим с тригонометрией. Мы научились строить синус и косинус через вращение окружности. Немного не помню, обговаривали ли мы это на прошлой лекции, но Юрий Сергеевич кратуо цпомянул, что мы можем разложить $\Gamma(x)$ в ряд Тэйлора в $\sum_{n=0}^\infty\frac{(ix)^n}{n!}$ в силу свойства $\Gamma'(x)=i\Gamma(x)$ и того, что остаточный член в форме Лагранжа будет стремиться к нулю при стремлении $n$ к бесконечности. \ 

Тогда 
\[
    \cos x = \Real \Gamma(x) \Rightarrow \sum_{n=0}^\infty\frac{x^{2n}}{(2n)!}(-1)^n
\]
и аналогично синус по нечётным степеням. \ 

Мнимая экспонента обладает свойствами, аналогичным обыкновенной экспоненте, поэтому покажем, что $\Gamma(x+y)=\Gamma(x)\Gamma(y)$. Рассмотрим $\Gamma(x+y)\overline{\Gamma(y)}$ - функцию от $x$, а $y$ - параметр. Это - некоторый обход окружности, который также удовлетворяет всем нормировочным условиям. $\varphi(0)=1$, $|\varphi'(x|=1$, и, наконец, $\varphi'(0)=\Gamma'(0)= i$. \ 

Теперь все прекрасные формулы косинуса и синуса суммы и разностей легко выводятся из доказанной формулы. Через мнимую экспоненту запишем: $e^{i(x+y)=e^{ix}\cdot e^{iy}}$, а там уже просто надо посмотреть на мнимые и действительные части. \ 

Из полученных свойств получим, что $\Gamma(x)\Gamma(-x)=\Gamma(0=1)$, тогда $\Gamma(-x)=\overline{\Gamma(x)}$, откуда мы получаем чётность косинуса и нечётность синуса. \ 

Можно упомянуть и формулу муавра. Распишем 
\[
    \cos(x)=\frac{e^{ix}+e^{-ix}}{2}, \: \sin(x)=\frac{e^{ix}-e^{-ix}}{2i}, 
\]
это формулы Муавра. Также можно получить и периодичность, это, вообщем-то очевидно и завершает наш разговор об элементарных функциях. \\

Перейдём теперь к многочерному анализу. Мы бы хотели точно также уметь анализировать функции и делать всё то, что мы уже умеем делать для одномерных функций, в том числе, решать экстремальные задачи. Нас интересуют функции $f:\RR^m\rightarrow \RR^n$. \ 

Начнём с того, что в евклидовом пространстве $\RR^m$ расстояние задаётся как 
\[
    d(x, y)=\sqrt{\sum_{k=1}^m(x_k-y_k)^2}=||x-y||.
\]
И если у нас имеется точка $x=(x_1, \ldots, x_m)$, то её норма есть $||x||=\sqrt{\sum_{k=1}^mx_k^2}$. Вообще, норму можно задать как угодно, если она удовлетворяет таким свойствам: 

\begin{itemize}
    \item норма - функция $\RR^m\rightarrow \RR_{+, 0}$, 
    \item $||x||=0 \: \Leftrightarrow \: x\equiv (0,\ldots, 0)$, 
    \item $||\alpha x||=|\alpha|\cdot||x||$, $\alpha\in \RR$, 
    \item $||x+y||\leq ||x||+||y||$. 
\end{itemize}

Разберёмся с понятием \textit{гладкости}. Для начала, алгебраически. Пусть у нас есть функция нескольких переменных $f:\RR^m\rightarrow \RR$, $f(x_1, \ldots, x_m)$. 

\begin{defn}
    $f$ \textit{дифференцируема} в точке $(x_1, \ldots, x_m)$, если $f(y)=f(x)+L(y-x)+o(||x-y||)$, где $L$ - линейное отображение $\RR^m\rightarrow \RR$, причём однородное, то есть, $L(0)=0$. 
\end{defn}

\begin{defn}
    Это линейное отображение $L$ называется \textit{дифференциалом} в точке $x$.
\end{defn}

На топологии мы доказывали, что в конечномерном пространстве различные норма липшицево-эквивалентны, потому мы просто во всех рассуждениях будем испоьзовать именно евклидовы нормы, потому что они удобные. А теперь перейдём к базовым свойствам. 

\begin{remark}
    $L$ - единственно.
\end{remark}

\begin{remark}
    Если у нас есть две функции: $f$ и $g$, то дифференциал $\alpha f+\beta g$, $\alpha, \: \beta \in \RR$ есть $\alpha L_1+\beta L_2$, где $L_1$ и $L_2$ - дифференциалы $f$ и $g$. 
\end{remark}

Рассмотрим теперь отображение общего вида: $f:\RR^m\rightarrow \RR^n$. Тогда 
\begin{defn}
    (Гладкость). $f(y)=f(x)+L(y-x)+o(||x-y||)$, где $L$ - линейное отображение $\RR^m\rightarrow \RR^n$, $L(x+y)=L(x)+L(y)$. $o$-малое в данном случае можно понять как 
    \[
        \frac{f(y)-f(x)-L(y-x)}{||y-x||}\rightarrow 0,
    \]
    то есть, элемент $\RR^n$ стремится у нулю, но для удобства можно взять евклидову норму этого выражения.
\end{defn}

Какой вид имеет общее линейное отображение из $\RR^m\rightarrow \RR^n$? Естественно, это - матрица, это мы знаем из алгебры и умеем расписывать переход в тривиальном базисе. \ 

Перейдём к свойствам линейных отображений. Мы умеем их складывать, умножать, а также, совершать композиции в случае согласованности размерностей, которая соответствует перемножению матриц. \ 

Пусть теперь, опять же, у нас есть отображение $L: \RR^m\rightarrow \RR^n$, то $L(\RR^m)\subset \RR^n$ - подпространство, которое имеет размерность от $0$ до $n$, эту размерность мы понимаем как \textit{ранг} линейного отображения. Если же мы берём композицию линейных отображений, то ранг не может вырасти (куда растягивать-то). Также, легоко видеть, что если $m<n$, то $\dim(L(\RR^m))\leq m<n$. \ 

Зададимся теперь вопросом, какая существует естественная метрика на линейных отображениях $\RR^m\rightarrow \RR^n$. По сути, эти линейные отображения представляют собой евклидово пространство размерности $m\cdot n$. Задать на нём мы можем евклидову метрику: под корнем будут квадраты всех матричных элементов. Эта норма вычисляется проще, но зато гораздо менее естественна, чем следующая (например, относительно вопроса о композиции). $||L||=\sup_{||x||<1}||Lx||$, $x\in \RR^m$, $LX\in \RR^n$. Эта вещь конечна, так как она не превосходит $\sum_{k=1}^m ||Le_k||$, а также выполняются все свойства нормы. \ 

Геометрический смысл у данной нормы очень простой: мы смотрим, насколько сильно она растягивает расстояние в зависимости от направления. \ 

Завершаем лекцию несколькими переопределениями нормы: 
\begin{itemize}
    \item $\sup_{||x||<1}||Lx||$, 
    \item $\sup_{||x||\leq 1}||Lx||$, 
    \item $\sup_{||x||\neq 0}\frac{||Lx||}{||x||}$, 
    \item $\sup_{||x||<=}||Lx||$.
\end{itemize}

\section{Лекция 4.}

Продолжаем с операторами, пусть $A: \RR^n\rightarrow \RR^n$ - линейный, $||A||=\sup_{||x||\leq 1}||Ax||$ - норма, где $||x||$ - Евклидово. $A\cong \RR^{nm}$, так как можно выносить константу, не меньше нуля (притом равна тогда и только тогда, когда сам оператор - нуль), а также, норма суммы не превосходит сумму норм. 

\begin{defn}
    $||A||$ - \textit{операторная норма}, притом супремум всегда достигается. 
\end{defn}

Операторная норма есть самое большое по модулю собственное число. Предположим, что у $A$ есть $n$ различных $\lambda_i$ собственных чисел, у которых есть соответственные $x^i$ собственные векторы. Запишем тогда $x=\sum_{k=1}^n a_kx^k$, $Ax=\sum_{k=1}^n \lambda_k a_kx^k$, тогда $||Ax||\leq\max_k|\lambda_k|\cdot||x||$, но это мы объяснить не смогли. \ 

Однако разговор сейчас шёл о различных собственных числах, бывают же \textit{кратные} собственные числа. Что происходит? \ 

Важный момент, почему важна операторная норма. Пусть $A:\RR^n\rightarrow \RR^m$, $B:\RR^m\rightarrow \RR^k$, тогда $||BA||\leq ||B||\cdot||A||$, так как левая часть по определению равна $\sup_{||x||\leq 1 (в \RR^n)}\leq \sup_{||y||\leq||A||}||By||\leq ||B||\cdot||A||$. Заметим также две следующие вещи для линейного $A:\RR^n\rightarrow \RR^m$ равносильны: \ 

\begin{itemize}
    \item $\ker A=\{0\}$
    \item $||Ax||\geq \varepsilon ||x||, \exists \varepsilon >0$. 
\end{itemize}

\begin{proof}
    $\{x:||x||=1\}$ - единичная сфера в $\RR^n$. Пусть $f(x):x\rightarrow ||Ax||$, $f$ - непрерывная (?), $f\neq 0$ на единичной сфере, тогда $f\geq \varepsilon >0$, $||Ax||\geq \varepsilon||x||$, $||x||=1$. 
\end{proof}

Вообще, нам все эти операторы нужны для рассуждений о гладкости, сформулируем теорему: \\ 

\begin{theorem}
    $f: G\rightarrow \RR^m$, $G\subset \RR^n$ - открытое, $f$ - гладкая в окрестности $x^0$ (верхние индексы), $y^0=f(x^0)$, $g:V_{f(x^0)}\rightarrow \RR^k$, гладкая в $f(x^0)$, для $f$ и $g$ существуют линейные операторы $A$ ($x_00)$ и $B$ ($f(x_0)$). Тогда $g(f(x))$ - гладкое (?) отображение в $x_0$ с линейным оператором (?) $BA:\RR^n\rightarrow \RR^k$. 
\end{theorem}

\begin{proof}
    Мы знаем, что существует представление $f(x)=f(x^0)+A(x-x^0)+o(||x-x^0||)$. Применим $g$, получим 
    \begin{equation}
        g(f(x))=g(y^0+A(x-x^0)+o(||x-x^0||)).
    \end{equation}
        
    Также мы знаем, что $g$ гладкая, то есть, также представима в виде $g(y)=g(y^0)+B(y-y^0)+o(||y-y^0)$, тогда приняв аргумент правой части $(1)$ за $y$, получим продолжение тождества: 
    \begin{equation}
        \begin{split}
            g(y^0)+B(A(x-x^0)+o(||x-x^0||))+o(A(x-x^0)+o(||x-x^0||)) = \\ 
            g(y^0)+BA(x-x^0)+o(||x-x^0||).
        \end{split}
\end{equation}
\end{proof}

\end{document}